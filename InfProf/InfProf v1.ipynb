{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from Bio import Entrez\n",
    "import re\n",
    "import math \n",
    "import warnings\n",
    "import configparser\n",
    "import json\n",
    "import datetime\n",
    "from functools import reduce\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching PubMed data...\n",
      "\n",
      "Query - (gene therapy[TIAB]) & \"2021\"[DP]\n"
     ]
    }
   ],
   "source": [
    "#keyword:\n",
    "def get_keywords(json_key):\n",
    "    len_keyList = len(json_key)\n",
    "    keyword = []\n",
    "\n",
    "    if len_keyList > 0:\n",
    "        for key in json_key[0]:\n",
    "            keyword.append(key)\n",
    "        keyword='; '.join(keyword)\n",
    "    else:\n",
    "        keyword ='none'\n",
    "    return keyword\n",
    "\n",
    "# Function to parse the author list\n",
    "def get_first_last_email(json_name):    \n",
    "    firstname =[]\n",
    "    lastname=[]\n",
    "    email=[]\n",
    "\n",
    "    for author in json_name:\n",
    "\n",
    "        #email\n",
    "        try:\n",
    "            firstname.append(author['ForeName'])\n",
    "            lastname.append(author['LastName'])\n",
    "            s = author['AffiliationInfo'][0]['Affiliation']\n",
    "            email_list = re.findall('\\S+@\\S+', s)\n",
    "            if len(email_list)>0:\n",
    "                #email = ''.join(email_list)\n",
    "                t_email = ''.join(email_list)\n",
    "                email.append(t_email)\n",
    "            else:\n",
    "                email.append('none')\n",
    "        except IndexError:\n",
    "            email.append('none')\n",
    "\n",
    "        except KeyError:\n",
    "            firstname.append('none')\n",
    "            lastname.append('none')\n",
    "\n",
    "    return firstname, lastname, email\n",
    "\n",
    "def fetch_pubs(year,query_arg):\n",
    "    # Create output df\n",
    "    id_df = pd.DataFrame()\n",
    "    \n",
    "    print('fetching PubMed data...\\n')\n",
    "    \n",
    "    # For each year loop generate queries and append IDs to output df\n",
    "    for i in year:\n",
    "        query = query_arg+i+'\"[DP]'\n",
    "        print('Query -',query)\n",
    "        Entrez.email = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "        handle = Entrez.esearch(db='pubmed', \n",
    "                                sort='relevance', \n",
    "                                retmax='1',\n",
    "                                retmode='xml', \n",
    "                                term=query)\n",
    "        result = Entrez.read(handle)\n",
    "    \n",
    "        id_list = result['IdList']\n",
    "        id_df = id_df.append(id_list)\n",
    "\n",
    "    id_df.drop_duplicates(inplace=True) \n",
    "    id_list=list(id_df[0])\n",
    "    \n",
    "    # Convert IDs to list\n",
    "    ids = ','.join(id_list)\n",
    "    \n",
    "    # Set the Entrez email parameter\n",
    "    Entrez.email = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    \n",
    "    handle = Entrez.efetch(db='pubmed',\n",
    "                           retmode='xml',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    \n",
    "    rows = []\n",
    "    for i, key in enumerate(id_list):\n",
    "        temp=[]\n",
    "        temp2=[]\n",
    "        \n",
    "        try:\n",
    "            title = results['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleTitle']  \n",
    "            jabbrv = results['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['ISOAbbreviation']\n",
    "            journal = results['PubmedArticle'][i]['MedlineCitation']['Article']['Journal']['Title']\n",
    "            pmid = results['PubmedArticle'][i]['MedlineCitation']['PMID'][0:]\n",
    "            abstract = results['PubmedArticle'][i]['MedlineCitation']['Article']['Abstract']['AbstractText'][0][0:]\n",
    "            year = results['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleDate'][0]['Year']\n",
    "            month = results['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleDate'][0]['Month']\n",
    "            day = results['PubmedArticle'][i]['MedlineCitation']['Article']['ArticleDate'][0]['Day']\n",
    "            doi = results['PubmedArticle'][i]['MedlineCitation']['Article']['ELocationID'][0][0:]\n",
    "            add = results['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0]['AffiliationInfo'][0]['Affiliation']\n",
    "            address = re.sub('\\..*','',add)\n",
    "            \n",
    "            keywords = get_keywords(results['PubmedArticle'][i]['MedlineCitation']['KeywordList'])\n",
    "            \n",
    "            firstname, lastname, email = get_first_last_email(results['PubmedArticle'][i]['MedlineCitation']['Article']['AuthorList'][0:])\n",
    "        \n",
    "        except KeyError:\n",
    "            abstract = 'none'\n",
    "            keywords='none'\n",
    "            \n",
    "            \n",
    "        except IndexError:\n",
    "            title = 'none'\n",
    "            jabbrv ='none'\n",
    "            journal = 'none'\n",
    "            pmid ='none'\n",
    "            year = 'none'\n",
    "            month= 'none'\n",
    "            day= 'none'\n",
    "            doi='none'\n",
    "            address='none'\n",
    "            keywords='none'\n",
    "            firstname, lastname, email = 'none', 'none', 'none'\n",
    "        \n",
    "        temp.extend((pmid,doi,title, abstract, year, month, day, jabbrv, journal,keywords))\n",
    "        \n",
    "        temp2.extend((pmid,doi,title, abstract, year, month, day, jabbrv, journal,keywords, lastname, firstname, address, email))\n",
    "        \n",
    "        if not lastname=='none':\n",
    "            for last, first, em in zip(lastname, firstname, email):\n",
    "                temp1=temp.copy()\n",
    "                temp1.extend((last, first, address, em))\n",
    "                rows.append(temp1)\n",
    "        else:\n",
    "            rows.append(temp2)\n",
    "            \n",
    "        pubmed_df =pd.DataFrame(rows, columns=['pmid', 'doi', 'title', 'abstract', 'year', 'month', 'day','jabbrv', 'journal',\n",
    "                                               'keywords', 'lastname', 'firstname', 'address', 'email'])\n",
    "    \n",
    "    pubmed_df_HCP_List = pubmed_df[['pmid','firstname','lastname']][pubmed_df['pmid']!='none']\n",
    "    pubmed_df_HCP_List['fullName'] = pubmed_df_HCP_List['firstname']+' '+pubmed_df_HCP_List['lastname']\n",
    "    pubmed_df_HCP_List['fullName'] = pubmed_df_HCP_List['fullName'].str.strip()\n",
    "    pubmed_df_HCP_List['name'] = pubmed_df_HCP_List['firstname'].str.replace('( ).*','')+' '+pubmed_df_HCP_List['lastname']\n",
    "    pubmed_df_HCP_List.drop_duplicates(inplace=True)\n",
    "    pubmed_df_HCP_List.head(10)\n",
    " \n",
    "    return pubmed_df,pubmed_df_HCP_List\n",
    "\n",
    "\n",
    "year = ['2021']\n",
    "# mesh_terms = '(vasomotor symptoms[TIAB] | menopausal symptom[TIAB] | hot flashes[TIAB] | hot flushes[TIAB]) & \"'\n",
    "mesh_terms = '(gene therapy[TIAB]) & \"'\n",
    "\n",
    "pubs=fetch_pubs(year, mesh_terms)\n",
    "pubs[0].to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\MA\\influencer_profiling\\influencer_profiling_v1.0\\outputs\\pubs.csv\")\n",
    "pubs[1].to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\MA\\influencer_profiling\\influencer_profiling_v1.0\\outputs\\pub_authors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmid</th>\n",
       "      <th>doi</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>jabbrv</th>\n",
       "      <th>journal</th>\n",
       "      <th>keywords</th>\n",
       "      <th>lastname</th>\n",
       "      <th>firstname</th>\n",
       "      <th>address</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34629464</td>\n",
       "      <td>10.1038/s41434-021-00299-x</td>\n",
       "      <td>A PCR-amplified transgene fragment flanked by ...</td>\n",
       "      <td>The application of recombinant adeno-associate...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Gene Ther</td>\n",
       "      <td>Gene therapy</td>\n",
       "      <td>none</td>\n",
       "      <td>Adachi</td>\n",
       "      <td>Kumi</td>\n",
       "      <td>Department of Biochemistry and Molecular Biolo...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34629464</td>\n",
       "      <td>10.1038/s41434-021-00299-x</td>\n",
       "      <td>A PCR-amplified transgene fragment flanked by ...</td>\n",
       "      <td>The application of recombinant adeno-associate...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Gene Ther</td>\n",
       "      <td>Gene therapy</td>\n",
       "      <td>none</td>\n",
       "      <td>Tomono</td>\n",
       "      <td>Taro</td>\n",
       "      <td>Department of Biochemistry and Molecular Biolo...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34629464</td>\n",
       "      <td>10.1038/s41434-021-00299-x</td>\n",
       "      <td>A PCR-amplified transgene fragment flanked by ...</td>\n",
       "      <td>The application of recombinant adeno-associate...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Gene Ther</td>\n",
       "      <td>Gene therapy</td>\n",
       "      <td>none</td>\n",
       "      <td>Okada</td>\n",
       "      <td>Hironori</td>\n",
       "      <td>Department of Biochemistry and Molecular Biolo...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34629464</td>\n",
       "      <td>10.1038/s41434-021-00299-x</td>\n",
       "      <td>A PCR-amplified transgene fragment flanked by ...</td>\n",
       "      <td>The application of recombinant adeno-associate...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Gene Ther</td>\n",
       "      <td>Gene therapy</td>\n",
       "      <td>none</td>\n",
       "      <td>Shiozawa</td>\n",
       "      <td>Yusuke</td>\n",
       "      <td>Department of Biochemistry and Molecular Biolo...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34629464</td>\n",
       "      <td>10.1038/s41434-021-00299-x</td>\n",
       "      <td>A PCR-amplified transgene fragment flanked by ...</td>\n",
       "      <td>The application of recombinant adeno-associate...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Gene Ther</td>\n",
       "      <td>Gene therapy</td>\n",
       "      <td>none</td>\n",
       "      <td>Yamamoto</td>\n",
       "      <td>Motoko</td>\n",
       "      <td>Department of Biochemistry and Molecular Biolo...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34629464</td>\n",
       "      <td>10.1038/s41434-021-00299-x</td>\n",
       "      <td>A PCR-amplified transgene fragment flanked by ...</td>\n",
       "      <td>The application of recombinant adeno-associate...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Gene Ther</td>\n",
       "      <td>Gene therapy</td>\n",
       "      <td>none</td>\n",
       "      <td>Miyagawa</td>\n",
       "      <td>Yoshitaka</td>\n",
       "      <td>Department of Biochemistry and Molecular Biolo...</td>\n",
       "      <td>yoshitaka-miyagawa@nms.ac.jp.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>34629464</td>\n",
       "      <td>10.1038/s41434-021-00299-x</td>\n",
       "      <td>A PCR-amplified transgene fragment flanked by ...</td>\n",
       "      <td>The application of recombinant adeno-associate...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Gene Ther</td>\n",
       "      <td>Gene therapy</td>\n",
       "      <td>none</td>\n",
       "      <td>Okada</td>\n",
       "      <td>Takashi</td>\n",
       "      <td>Department of Biochemistry and Molecular Biolo...</td>\n",
       "      <td>t-okada@ims.u-tokyo.ac.jp.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pmid                         doi  \\\n",
       "0  34629464  10.1038/s41434-021-00299-x   \n",
       "1  34629464  10.1038/s41434-021-00299-x   \n",
       "2  34629464  10.1038/s41434-021-00299-x   \n",
       "3  34629464  10.1038/s41434-021-00299-x   \n",
       "4  34629464  10.1038/s41434-021-00299-x   \n",
       "5  34629464  10.1038/s41434-021-00299-x   \n",
       "6  34629464  10.1038/s41434-021-00299-x   \n",
       "\n",
       "                                               title  \\\n",
       "0  A PCR-amplified transgene fragment flanked by ...   \n",
       "1  A PCR-amplified transgene fragment flanked by ...   \n",
       "2  A PCR-amplified transgene fragment flanked by ...   \n",
       "3  A PCR-amplified transgene fragment flanked by ...   \n",
       "4  A PCR-amplified transgene fragment flanked by ...   \n",
       "5  A PCR-amplified transgene fragment flanked by ...   \n",
       "6  A PCR-amplified transgene fragment flanked by ...   \n",
       "\n",
       "                                            abstract  year month day  \\\n",
       "0  The application of recombinant adeno-associate...  2021    10  11   \n",
       "1  The application of recombinant adeno-associate...  2021    10  11   \n",
       "2  The application of recombinant adeno-associate...  2021    10  11   \n",
       "3  The application of recombinant adeno-associate...  2021    10  11   \n",
       "4  The application of recombinant adeno-associate...  2021    10  11   \n",
       "5  The application of recombinant adeno-associate...  2021    10  11   \n",
       "6  The application of recombinant adeno-associate...  2021    10  11   \n",
       "\n",
       "      jabbrv       journal keywords  lastname  firstname  \\\n",
       "0  Gene Ther  Gene therapy     none    Adachi       Kumi   \n",
       "1  Gene Ther  Gene therapy     none    Tomono       Taro   \n",
       "2  Gene Ther  Gene therapy     none     Okada   Hironori   \n",
       "3  Gene Ther  Gene therapy     none  Shiozawa     Yusuke   \n",
       "4  Gene Ther  Gene therapy     none  Yamamoto     Motoko   \n",
       "5  Gene Ther  Gene therapy     none  Miyagawa  Yoshitaka   \n",
       "6  Gene Ther  Gene therapy     none     Okada    Takashi   \n",
       "\n",
       "                                             address  \\\n",
       "0  Department of Biochemistry and Molecular Biolo...   \n",
       "1  Department of Biochemistry and Molecular Biolo...   \n",
       "2  Department of Biochemistry and Molecular Biolo...   \n",
       "3  Department of Biochemistry and Molecular Biolo...   \n",
       "4  Department of Biochemistry and Molecular Biolo...   \n",
       "5  Department of Biochemistry and Molecular Biolo...   \n",
       "6  Department of Biochemistry and Molecular Biolo...   \n",
       "\n",
       "                           email  \n",
       "0                           none  \n",
       "1                           none  \n",
       "2                           none  \n",
       "3                           none  \n",
       "4                           none  \n",
       "5  yoshitaka-miyagawa@nms.ac.jp.  \n",
       "6     t-okada@ims.u-tokyo.ac.jp.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pubs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pubmed_npi(arg):\n",
    "    # arg = pubmed_df_HCP_List.head(500)\n",
    "    df = arg.copy()\n",
    "    df.head(5)\n",
    "    \n",
    "    df['firstname_only'] = df['firstname'].str.replace('( ).*','')\n",
    "    df['list'] = df.apply(lambda x: (x['firstname_only'], x['lastname']), axis=1)\n",
    "    \n",
    "    df_new = pd.DataFrame()\n",
    "    \n",
    "    for x in df['list'].tolist():\n",
    "        try:\n",
    "            r = requests.get('https://npiregistry.cms.hhs.gov/api/?'+\n",
    "                             str('enumeration_type=NPI-1')+'&'+\n",
    "                             str('version=2.1')+'&'+ #+str(x['version'])+'&'+\n",
    "                             str('first_name=')+str(x[0])+'&'+\n",
    "                             str('last_name=')+str(x[1])+'&'+\n",
    "                             str('skip=')+str('')+'&'+str('limit=')+str(''))\n",
    "            data=r.json()\n",
    "            d = pd.DataFrame.from_dict(data['results'])  \n",
    "            df_new = df_new.append(d)\n",
    "        except:\n",
    "            pass\n",
    "        # d['Npi_Criteria'] = 'FN+LN'\n",
    "               \n",
    "    basic_col =['ein', 'organization_name', 'last_name', 'first_name', 'middle_name', 'name_prefix', 'name_suffix', 'credential',\n",
    "                'last_updated', 'deactivation_reason_code', 'deactivation_date', 'reactivation_date', 'gender',\n",
    "                'authorized_official_telephone_number']\n",
    "    \n",
    "    address_col = ['address_1', 'address_2', 'city', 'state', 'postal_code', 'country_code', 'telephone_number']\n",
    "    \n",
    "    taxo_col = ['license', 'state']\n",
    "    \n",
    "    d = df_new[['number', 'basic', 'addresses', 'taxonomies']]\n",
    "    \n",
    "    basic = d.basic.apply(pd.Series)\n",
    "    basic_df = pd.DataFrame(columns=basic_col)\n",
    "    basic_df = pd.concat([basic_df,basic]).fillna('none')\n",
    "    basic_df = basic_df[basic_col]\n",
    "    \n",
    "    d = pd.concat([d,basic_df], axis=1)\n",
    "    \n",
    "    d = d.explode('addresses')\n",
    "    \n",
    "    addresses = d.addresses.apply(pd.Series)\n",
    "    \n",
    "    address_df = pd.DataFrame(columns=address_col)\n",
    "    address_df = pd.concat([address_df,addresses]).fillna('none')\n",
    "    address_df = address_df[address_col]\n",
    "    address_df = address_df.rename(columns={'state':'address_state'})\n",
    "    \n",
    "    d = pd.concat([d,address_df], axis=1)\n",
    "    \n",
    "    d = d.explode('taxonomies')\n",
    "    taxonomies = d.taxonomies.apply(pd.Series)\n",
    "    \n",
    "    taxo_df = pd.DataFrame(columns=taxo_col)\n",
    "    taxo_df = pd.concat([taxo_df,taxonomies]).fillna('none')\n",
    "    taxo_df = taxo_df[taxo_col]\n",
    "    taxo_df = taxo_df.rename(columns={'state':'taxo_state'})\n",
    "    \n",
    "    d = pd.concat([d,taxo_df], axis=1) \n",
    "    d = d.drop(['basic', 'addresses','taxonomies'], axis=1)\n",
    "    d = d.drop_duplicates()\n",
    "    \n",
    "    d = d.rename(\n",
    "    columns={'number':'NPI', 'ein': 'Employer_Identification_Number_(EIN)', 'organization_name':'Provider_Organization_Name_(Legal_Business_Name)',\n",
    "             'last_name':'Provider_Last_Name_(Legal_Name)', 'first_name': 'Provider_First_Name', 'middle_name':'Provider_Middle_Name',\n",
    "             'name_prefix': 'Provider_Name_Prefix_Text', 'name_suffix': 'Provider_Name_Suffix_Text',\n",
    "             'credential': 'Provider_Credential_Text', 'last_updated': 'Last_Update_Date',\n",
    "             'deactivation_reason_code':'NPI_Deactivation_Reason_Code', 'deactivation_date': 'NPI_Deactivation_Date',\n",
    "             'reactivation_date': 'NPI_Reactivation_Date', 'gender':'Provider_Gender_Code',\n",
    "             'authorized_official_telephone_number':'Authorized_Official_Telephone_Number',\n",
    "             'address_1': 'Provider_First_Line_Business_Mailing_Address', 'address_2': 'Provider_Second_Line_Business_Mailing_Address',\n",
    "             'city': 'Provider_Business_Mailing_Address_City_Name',\n",
    "             'address_state': 'Provider_Business_Mailing_Address_State_Name',\n",
    "             'postal_code' : 'Provider_Business_Mailing_Address_Postal_Code', 'country_code' : 'Provider_Business_Mailing_Address_Country_Code_(If_outside_US)',\n",
    "             'telephone_number': 'Provider_Business_Mailing_Address_Telephone_Number', 'license': 'Provider_License_Number_1',\n",
    "             'taxo_state':'Provider_License_Number_State_Code_1'})\n",
    "    \n",
    "    npi_df = d.drop_duplicates('NPI', keep='first') \n",
    "      \n",
    "    df['joinkey'] = df['fullName']\n",
    "    df['joinkey'] = df['joinkey'].str.strip()\n",
    "    df['joinkey'] = df['joinkey'].str.upper()\n",
    "    df.head(10)\n",
    "    \n",
    "    npi_df['joinkey'] = npi_df['Provider_First_Name']+' '+npi_df['Provider_Middle_Name'].replace('none','-').str[0]+' '+npi_df['Provider_Last_Name_(Legal_Name)']\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.replace(' - ',' ')\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.strip()\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.upper()\n",
    "    \n",
    "    pubmed_HCP = df.merge(npi_df,how='left',on='joinkey')\n",
    "    \n",
    "    pubmed_HCP_Not_Joined = pubmed_HCP[pubmed_HCP['NPI'].isnull()].filter(df.columns)\n",
    "    pubmed_HCP = pubmed_HCP[np.logical_not(pubmed_HCP['NPI'].isnull())]\n",
    "    \n",
    "    pubmed_HCP['key'] = 1\n",
    "    duplicates = pubmed_HCP[['joinkey','key']].groupby(['joinkey']).sum()\n",
    "    pubmed_HCP.drop(['key'],inplace=True,axis=1)\n",
    "    pubmed_HCP = pubmed_HCP.merge(duplicates,on='joinkey',how='inner')\n",
    "    \n",
    "    npi_df['joinkey'] = npi_df['Provider_First_Name']+' '+npi_df['Provider_Last_Name_(Legal_Name)']\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.strip()\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.upper()\n",
    "    \n",
    "    \n",
    "    pubmed_HCP_Not_Joined['joinkey'] = pubmed_HCP_Not_Joined['name']\n",
    "    pubmed_HCP_Not_Joined['joinkey'] = pubmed_HCP_Not_Joined['joinkey'].str.strip()\n",
    "    pubmed_HCP_Not_Joined['joinkey'] = pubmed_HCP_Not_Joined['joinkey'].str.upper()\n",
    "    pubmed_HCP_Not_Joined.head(10)\n",
    "    \n",
    "    pubmed_HCP_1 = pubmed_HCP_Not_Joined.merge(npi_df,how='left',on='joinkey')\n",
    "    \n",
    "    pubmed_HCP_Not_Joined = pubmed_HCP_1[pubmed_HCP_1['NPI'].isnull()].filter(df.columns)\n",
    "    pubmed_HCP_1 = pubmed_HCP_1[np.logical_not(pubmed_HCP_1['NPI'].isnull())]\n",
    "    pubmed_HCP_Not_Joined.head(1)\n",
    "    \n",
    "    pubmed_HCP_1['key'] = 1\n",
    "    duplicates = pubmed_HCP_1[['joinkey','key']].groupby(['joinkey']).sum()\n",
    "    pubmed_HCP_1.drop(['key'],inplace=True,axis=1)\n",
    "    pubmed_HCP_1 = pubmed_HCP_1.merge(duplicates,on='joinkey',how='inner')\n",
    "    \n",
    "    pubmed_HCP = pubmed_HCP.append(pubmed_HCP_1)\n",
    "    \n",
    "    pubmed_HCP = pubmed_HCP.filter(['pmid','firstname','lastname','fullName','name','NPI','key'])\n",
    "    pubmed_HCP_Not_Joined = pubmed_HCP_Not_Joined.filter(['pmid','firstname','lastname','fullName','name'])\n",
    "    pubmed_HCP_Not_Joined['key'] = 0\n",
    "    \n",
    "    pubmed_HCP = pubmed_HCP.append(pubmed_HCP_Not_Joined)\n",
    "    pubmed_HCP.reset_index(drop=True,inplace=True)\n",
    "    del pubmed_HCP_1,pubmed_HCP_Not_Joined,d\n",
    "    return pubmed_HCP,npi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clinical_Trials(exp):    \n",
    "    def de_list(input_field):\n",
    "        if isinstance(input_field, list):\n",
    "            if len(input_field) == 0:\n",
    "                return None\n",
    "            elif len(input_field) == 1:\n",
    "                return input_field[0]\n",
    "            else:\n",
    "                return '; '.join(input_field)\n",
    "        else:\n",
    "            return input_field\n",
    "        \n",
    "    extract_fields = [\n",
    "        \"NCTId\",\n",
    "        \"BriefSummary\",\n",
    "        \"BriefTitle\",\n",
    "        \"CentralContactEMail\",\n",
    "        \"CentralContactName\",\n",
    "        \"CentralContactPhone\",\n",
    "        \"CentralContactPhoneExt\",\n",
    "        \"CentralContactRole\",\n",
    "        \"CollaboratorClass\",\n",
    "        \"CollaboratorName\",\n",
    "        \"CompletionDate\",\n",
    "        \"CompletionDateType\",\n",
    "        \"IsFDARegulatedDevice\",\n",
    "        \"IsFDARegulatedDrug\",\n",
    "        \"LeadSponsorClass\",\n",
    "        \"LeadSponsorName\",\n",
    "        \"LimitationsAndCaveatsDescription\",\n",
    "        \"LocationCity\",\n",
    "        \"LocationContactEMail\",\n",
    "        \"LocationContactName\"]\n",
    "    \n",
    "    extract_fields2 = [\n",
    "        \"NCTId\",\n",
    "        \"LocationContactPhone\",\n",
    "        \"LocationContactRole\",\n",
    "        \"LocationContactPhoneExt\",\n",
    "        \"LocationCountry\",\n",
    "        \"LocationFacility\",\n",
    "        \"LocationState\",\n",
    "        \"LocationStatus\",\n",
    "        \"LocationZip\",\n",
    "        \"NCTIdAlias\",\n",
    "        \"OfficialTitle\",\n",
    "        \"OrgClass\",\n",
    "        \"OrgFullName\",\n",
    "        \"OrgStudyId\",\n",
    "        \"OrgStudyIdDomain\",\n",
    "        \"OrgStudyIdLink\",\n",
    "        \"OrgStudyIdType\",\n",
    "        \"OversightHasDMC\",\n",
    "        ]\n",
    "    \n",
    "    extract_fields3 = [\n",
    "        \"NCTId\",\n",
    "        \"PatientRegistry\",\n",
    "        \"Phase\",\n",
    "        \"PointOfContactEMail\",\n",
    "        \"PointOfContactOrganization\",\n",
    "        \"PointOfContactPhone\",\n",
    "        \"PointOfContactPhoneExt\",\n",
    "        \"PointOfContactTitle\",\n",
    "        \"ReferencePMID\",\n",
    "        \"ResponsiblePartyInvestigatorAffiliation\",\n",
    "        \"ResponsiblePartyInvestigatorFullName\",\n",
    "        \"ResponsiblePartyInvestigatorTitle\",\n",
    "        \"OverallOfficialName\"\n",
    "        ]\n",
    "    \n",
    "    data=pd.DataFrame()\n",
    "    data1=pd.DataFrame()\n",
    "    data2=pd.DataFrame()\n",
    "    minrnk = 1\n",
    "    maxrnk = 1000\n",
    "    # exp = '(\"Vasomotor Symptoms\")OR(\"Menopausal Symptoms\")OR(\"Hot Flashes\")OR(\"Hot Flushes\")OR(Menopause)'\n",
    "    BASE_URL = 'https://clinicaltrials.gov/api/query/study_fields?expr='+str(exp)+'&min_rnk='+str(minrnk)+'&max_rnk='+str(maxrnk)+'&fmt=json'\n",
    "    \n",
    "    query_url = f'{BASE_URL}&fields={\",\".join(extract_fields)}'\n",
    "    #print(query_url)\n",
    "    print('fetching Clinical Trials data...\\n')\n",
    "    print('Query -',exp)\n",
    "    r = requests.get(query_url)\n",
    "    r.status_code\n",
    "    # query_url = f'{BASE_URL}'\n",
    "    # print(query_url)\n",
    "    while(r.status_code == 200):\n",
    "        BASE_URL = 'https://clinicaltrials.gov/api/query/study_fields?expr='+exp+'&min_rnk='+str(minrnk)+'&max_rnk='+str(maxrnk)+'&fmt=json'\n",
    "        query_url = f'{BASE_URL}&fields={\",\".join(extract_fields)}'\n",
    "        query_url2 = f'{BASE_URL}&fields={\",\".join(extract_fields2)}'\n",
    "        query_url3 = f'{BASE_URL}&fields={\",\".join(extract_fields3)}'\n",
    "        r = requests.get(query_url)   \n",
    "        r.status_code    \n",
    "        j = json.loads(r.content)\n",
    "        # df = pd.DataFrame(j['FullStudiesResponse']['FullStudies'])\n",
    "        df = pd.DataFrame(j['StudyFieldsResponse']['StudyFields'])   \n",
    "        for c in df.columns:\n",
    "            df[c] = df[c].apply(de_list)\n",
    "        df['CompletionDate'] = pd.to_datetime(df['CompletionDate'])\n",
    "        df = df.sort_values(by='CompletionDate', ascending=False)    \n",
    "        data = data.append(df)\n",
    "        \n",
    "        r = requests.get(query_url2)   \n",
    "        r.status_code    \n",
    "        j = json.loads(r.content)\n",
    "        # df = pd.DataFrame(j['FullStudiesResponse']['FullStudies'])\n",
    "        df = pd.DataFrame(j['StudyFieldsResponse']['StudyFields'])   \n",
    "        for c in df.columns:\n",
    "            df[c] = df[c].apply(de_list)\n",
    "           \n",
    "        data1 = data1.append(df)\n",
    "        \n",
    "        r = requests.get(query_url3)   \n",
    "        r.status_code    \n",
    "        j = json.loads(r.content)\n",
    "        # df = pd.DataFrame(j['FullStudiesResponse']['FullStudies'])\n",
    "        df = pd.DataFrame(j['StudyFieldsResponse']['StudyFields'])   \n",
    "        for c in df.columns:\n",
    "            df[c] = df[c].apply(de_list)\n",
    "         \n",
    "        data2 = data2.append(df)\n",
    "        \n",
    "        minrnk +=1000\n",
    "        maxrnk +=1000\n",
    "        #print(minrnk)\n",
    "        if(j['StudyFieldsResponse']['NStudiesFound'] < minrnk):\n",
    "            break\n",
    "    \n",
    "    final_data = data.merge(data1,on='NCTId').merge(data2,on='NCTId')\n",
    "    \n",
    "    del data,data1,data2\n",
    "    \n",
    "    final_data_NotNAN_US = final_data[(final_data['LocationCountry'].str.contains('United States') == True)&((final_data['CentralContactName'])+(final_data['LocationContactName'])+(final_data['OverallOfficialName']))].reset_index(drop=True).copy()\n",
    "    \n",
    "    #final_data_NotNAN_US.to_csv(\"C:\\\\Users\\\\majichkar\\\\Desktop\\\\final_data_NotNAN_US.csv\")\n",
    "    \n",
    "    \n",
    "    df_CentralContacts = final_data_NotNAN_US[['NCTId','CentralContactName']].reset_index(drop=True)\n",
    "    \n",
    "    df_CentralContacts['CentralContactName'] = df_CentralContacts['CentralContactName'].str.replace(\",\",\"/\")\n",
    "    df_CentralContacts = df_CentralContacts.assign(CentralContactName=df_CentralContacts['CentralContactName'].str.split(';')).explode('CentralContactName')\n",
    "    df_CentralContacts['CentralContactName'] = df_CentralContacts['CentralContactName'].str.replace(\"(/).*\",\"\")\n",
    "    df_CentralContacts['CentralContactName'] = df_CentralContacts['CentralContactName'].str.strip()\n",
    "    df_CentralContacts.reset_index(drop=True, inplace = True)\n",
    "    df_CentralContacts.drop_duplicates(inplace=True)\n",
    "    \n",
    "    df_LocationContacts = final_data_NotNAN_US[['NCTId','LocationContactName']].reset_index(drop=True)\n",
    "    \n",
    "    df_LocationContacts['LocationContactName'] = df_LocationContacts['LocationContactName'].str.replace(\",\",\"/\")\n",
    "    df_LocationContacts = df_LocationContacts.assign(LocationContactName=df_LocationContacts['LocationContactName'].str.split(';')).explode('LocationContactName')\n",
    "    df_LocationContacts['LocationContactName'] = df_LocationContacts['LocationContactName'].str.replace(\"(/).*\",\"\")\n",
    "    \n",
    "    df_LocationContacts['LocationContactName'] = df_LocationContacts['LocationContactName'].str.strip()\n",
    "    df_LocationContacts.drop_duplicates(inplace=True)\n",
    "    df_LocationContacts = df_LocationContacts.reset_index(drop=True)\n",
    "    \n",
    "    df_OtherInv = final_data_NotNAN_US[['NCTId','ResponsiblePartyInvestigatorFullName','OverallOfficialName']].reset_index(drop=True)\n",
    "    df_OtherInv = df_OtherInv.fillna('')\n",
    "    df_OtherInv['OtherInvName'] = df_OtherInv['ResponsiblePartyInvestigatorFullName'].str.cat(df_OtherInv[['OverallOfficialName']].values,sep=';')\n",
    "    df_OtherInv = df_OtherInv[['NCTId','OtherInvName']]\n",
    "    \n",
    "    df_OtherInv['OtherInvName'] = df_OtherInv['OtherInvName'].str.replace(\",\",\"/\")\n",
    "    df_OtherInv = df_OtherInv.assign(OtherInvName=df_OtherInv['OtherInvName'].str.split(';')).explode('OtherInvName')\n",
    "    df_OtherInv['OtherInvName'] = df_OtherInv['OtherInvName'].str.replace(\"(/).*\",\"\")\n",
    "    df_OtherInv['OtherInvName'] = df_OtherInv['OtherInvName'].str.strip()\n",
    "    df_OtherInv.drop_duplicates(inplace=True)\n",
    "    df_OtherInv = df_OtherInv[df_OtherInv['OtherInvName'] != ''].reset_index(drop=True)\n",
    "    \n",
    "    df_RefPMID = final_data_NotNAN_US[['NCTId','ReferencePMID']].reset_index(drop=True)\n",
    "    \n",
    "    df_RefPMID = df_RefPMID.assign(ReferencePMID=df_RefPMID['ReferencePMID'].str.split(';')).explode('ReferencePMID')\n",
    "    df_RefPMID['ReferencePMID'] = df_RefPMID['ReferencePMID'].str.strip()\n",
    "    df_RefPMID.drop_duplicates(inplace=True)\n",
    "    df_RefPMID = df_RefPMID[np.logical_not(df_RefPMID['ReferencePMID'].isnull())].reset_index(drop=True)\n",
    "    \n",
    "    return df_CentralContacts,df_LocationContacts,df_OtherInv,df_RefPMID\n",
    "\n",
    "\n",
    "\n",
    "def fetch_CT_npi(df_CentralContacts,df_LocationContacts,df_OtherInv):\n",
    "    df_CentralContacts.rename(columns = {'CentralContactName':'Name'}, inplace = True)\n",
    "    df_LocationContacts.rename(columns = {'LocationContactName':'Name'}, inplace = True)\n",
    "    df_OtherInv.rename(columns = {'OtherInvName':'Name'}, inplace = True)\n",
    "    \n",
    "    df_CT = df_CentralContacts.append(df_LocationContacts).append(df_OtherInv).reset_index(drop=True)\n",
    "    \n",
    "    df_CT['firstname'] = df_CT['Name'].str.split(' ',1).str[0]\n",
    "    df_CT['lastname'] = df_CT['Name'].str.split(' ').str[-1]\n",
    "    \n",
    "    df_CT_no_dup = df_CT[['firstname','lastname']].reset_index(drop=True)\n",
    "    df_CT_no_dup.drop_duplicates(['firstname','lastname'],inplace=True)\n",
    "\n",
    "    df = df_CT_no_dup.copy()\n",
    "    df.head(5)\n",
    "\n",
    "    df['list'] = df.apply(lambda x: (x['firstname'], x['lastname']), axis=1)\n",
    "    \n",
    "    df_new = pd.DataFrame()\n",
    "    \n",
    "    for x in df['list'].tolist():\n",
    "        try:\n",
    "            r = requests.get('https://npiregistry.cms.hhs.gov/api/?'+\n",
    "                             str('enumeration_type=NPI-1')+'&'+\n",
    "                             str('version=2.1')+'&'+ #+str(x['version'])+'&'+\n",
    "                             str('first_name=')+str(x[0])+'&'+\n",
    "                             str('last_name=')+str(x[1])+'&'+\n",
    "                             str('skip=')+str('')+'&'+str('limit=')+str(''))\n",
    "            data=r.json()\n",
    "            d = pd.DataFrame.from_dict(data['results'], dtype=np.object)  \n",
    "            df_new = df_new.append(d)\n",
    "        except:\n",
    "            pass\n",
    "        # d['Npi_Criteria'] = 'FN+LN'\n",
    "               \n",
    "    basic_col =['ein', 'organization_name', 'last_name', 'first_name', 'middle_name', 'name_prefix', 'name_suffix', 'credential',\n",
    "                'last_updated', 'deactivation_reason_code', 'deactivation_date', 'reactivation_date', 'gender',\n",
    "                'authorized_official_telephone_number']\n",
    "    \n",
    "    address_col = ['address_1', 'address_2', 'city', 'state', 'postal_code', 'country_code', 'telephone_number']\n",
    "    \n",
    "    taxo_col = ['license', 'state']\n",
    "    \n",
    "    d = df_new[['number', 'basic', 'addresses', 'taxonomies']]\n",
    "    \n",
    "    basic = d.basic.apply(pd.Series)\n",
    "    basic_df = pd.DataFrame(columns=basic_col)\n",
    "    basic_df = pd.concat([basic_df,basic]).fillna('none')\n",
    "    basic_df = basic_df[basic_col]\n",
    "    \n",
    "    d = pd.concat([d,basic_df], axis=1)\n",
    "    \n",
    "    d = d.explode('addresses')\n",
    "    \n",
    "    addresses = d.addresses.apply(pd.Series)\n",
    "    \n",
    "    address_df = pd.DataFrame(columns=address_col)\n",
    "    address_df = pd.concat([address_df,addresses]).fillna('none')\n",
    "    address_df = address_df[address_col]\n",
    "    address_df = address_df.rename(columns={'state':'address_state'})\n",
    "    \n",
    "    d = pd.concat([d,address_df], axis=1)\n",
    "    \n",
    "    d = d.explode('taxonomies')\n",
    "    taxonomies = d.taxonomies.apply(pd.Series)\n",
    "    \n",
    "    taxo_df = pd.DataFrame(columns=taxo_col)\n",
    "    taxo_df = pd.concat([taxo_df,taxonomies]).fillna('none')\n",
    "    taxo_df = taxo_df[taxo_col]\n",
    "    taxo_df = taxo_df.rename(columns={'state':'taxo_state'})\n",
    "    \n",
    "    d = pd.concat([d,taxo_df], axis=1) \n",
    "    d = d.drop(['basic', 'addresses','taxonomies'], axis=1)\n",
    "    d = d.drop_duplicates()\n",
    "    \n",
    "    d = d.rename(\n",
    "    columns={'number':'NPI', 'ein': 'Employer_Identification_Number_(EIN)', 'organization_name':'Provider_Organization_Name_(Legal_Business_Name)',\n",
    "             'last_name':'Provider_Last_Name_(Legal_Name)', 'first_name': 'Provider_First_Name', 'middle_name':'Provider_Middle_Name',\n",
    "             'name_prefix': 'Provider_Name_Prefix_Text', 'name_suffix': 'Provider_Name_Suffix_Text',\n",
    "             'credential': 'Provider_Credential_Text', 'last_updated': 'Last_Update_Date',\n",
    "             'deactivation_reason_code':'NPI_Deactivation_Reason_Code', 'deactivation_date': 'NPI_Deactivation_Date',\n",
    "             'reactivation_date': 'NPI_Reactivation_Date', 'gender':'Provider_Gender_Code',\n",
    "             'authorized_official_telephone_number':'Authorized_Official_Telephone_Number',\n",
    "             'address_1': 'Provider_First_Line_Business_Mailing_Address', 'address_2': 'Provider_Second_Line_Business_Mailing_Address',\n",
    "             'city': 'Provider_Business_Mailing_Address_City_Name',\n",
    "             'address_state': 'Provider_Business_Mailing_Address_State_Name',\n",
    "             'postal_code' : 'Provider_Business_Mailing_Address_Postal_Code', 'country_code' : 'Provider_Business_Mailing_Address_Country_Code_(If_outside_US)',\n",
    "             'telephone_number': 'Provider_Business_Mailing_Address_Telephone_Number', 'license': 'Provider_License_Number_1',\n",
    "             'taxo_state':'Provider_License_Number_State_Code_1'})\n",
    "    \n",
    "    npi_df = d.drop_duplicates('NPI', keep='first') \n",
    "\n",
    "    df = df_CT.copy()\n",
    "    df.drop_duplicates(['NCTId','firstname','lastname'],inplace=True)\n",
    "    df['fullName'] = df['firstname']+' '+df['lastname']\n",
    "    df['joinkey'] = df['Name']\n",
    "    df['joinkey'] = df['joinkey'].str.strip()\n",
    "    df['joinkey'] = df['joinkey'].str.upper()\n",
    "    df.head(10)\n",
    "    \n",
    "    npi_df['joinkey'] = npi_df['Provider_First_Name']+' '+npi_df['Provider_Middle_Name'].replace('none','-').str[0]+' '+npi_df['Provider_Last_Name_(Legal_Name)']\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.replace(' - ',' ')\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.strip()\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.upper()\n",
    "    \n",
    "    CT_HCP = df.merge(npi_df,how='left',on='joinkey')\n",
    "    \n",
    "    CT_HCP_Not_Joined = CT_HCP[CT_HCP['NPI'].isnull()].filter(df.columns)\n",
    "    CT_HCP = CT_HCP[np.logical_not(CT_HCP['NPI'].isnull())]\n",
    "    \n",
    "    CT_HCP['key'] = 1\n",
    "    duplicates = CT_HCP[['joinkey','key']].groupby(['joinkey']).sum()\n",
    "    CT_HCP.drop(['key'],inplace=True,axis=1)\n",
    "    CT_HCP = CT_HCP.merge(duplicates,on='joinkey',how='inner')\n",
    "    \n",
    "    npi_df['joinkey'] = npi_df['Provider_First_Name']+' '+npi_df['Provider_Last_Name_(Legal_Name)']\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.strip()\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.upper()\n",
    "    \n",
    "    \n",
    "    CT_HCP_Not_Joined['joinkey'] = CT_HCP_Not_Joined['fullName']\n",
    "    CT_HCP_Not_Joined['joinkey'] = CT_HCP_Not_Joined['joinkey'].str.strip()\n",
    "    CT_HCP_Not_Joined['joinkey'] = CT_HCP_Not_Joined['joinkey'].str.upper()\n",
    "    CT_HCP_Not_Joined.head(10)\n",
    "    \n",
    "    CT_HCP_1 = CT_HCP_Not_Joined.merge(npi_df,how='left',on='joinkey')\n",
    "    \n",
    "    CT_HCP_Not_Joined = CT_HCP_1[CT_HCP_1['NPI'].isnull()].filter(df.columns)\n",
    "    CT_HCP_1 = CT_HCP_1[np.logical_not(CT_HCP_1['NPI'].isnull())]\n",
    "    CT_HCP_Not_Joined.head(1)\n",
    "    \n",
    "    CT_HCP_1['key'] = 1\n",
    "    duplicates = CT_HCP_1[['joinkey','key']].groupby(['joinkey']).sum()\n",
    "    CT_HCP_1.drop(['key'],inplace=True,axis=1)\n",
    "    CT_HCP_1 = CT_HCP_1.merge(duplicates,on='joinkey',how='inner')\n",
    "    \n",
    "    CT_HCP = CT_HCP.append(CT_HCP_1)\n",
    "    \n",
    "    CT_HCP = CT_HCP.filter(['NCTId','firstname','lastname','fullName','Name','NPI','key'])\n",
    "    CT_HCP_Not_Joined = CT_HCP_Not_Joined.filter(['NCTId','firstname','lastname','fullName','Name'])\n",
    "    CT_HCP_Not_Joined['key'] = 0\n",
    "    \n",
    "    CT_HCP = CT_HCP.append(CT_HCP_Not_Joined)\n",
    "    CT_HCP.reset_index(drop=True,inplace=True)\n",
    "    del CT_HCP_1,CT_HCP_Not_Joined,d\n",
    "    \n",
    "    return CT_HCP,npi_df,df_CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_properties_file(file):\n",
    "    config = configparser.RawConfigParser()\n",
    "    config.read(file)\n",
    "    return config\n",
    "\n",
    "\n",
    "def initialize_vars(file,op_dir):      \n",
    "    config = parse_properties_file(file)\n",
    "    \n",
    "    y = config['Publication Filters']['years'].strip()\n",
    "    q = config['Publication Filters']['search Terms'].strip()\n",
    "    e = config['Clinical Filters']['search Terms'].strip()\n",
    "    \n",
    "    path = op_dir + '\\\\'    \n",
    "    # y = input(\"Enter Year(Seperated by comma) - \") \n",
    "    # q = input(\"Enter Keywords for PubMed data(Seperated by comma) - \")\n",
    "    # e = input(\"Enter Keywords for Clinical Trials data(Seperated by comma) - \")    \n",
    "    year = y.split(',')    \n",
    "    q1 = q.replace(',','[TIAB] | ')\n",
    "    query_arg = '('+q1+'[TIAB]) & \"'    \n",
    "    e1 = e.replace(',','\")OR(\"')\n",
    "    exp = '(\"'+e1+'\")'\n",
    "    # year = ['2021']\n",
    "    # query_arg = '(vasomotor symptoms[TIAB] | menopausal symptom[TIAB] | hot flashes[TIAB] | hot flushes[TIAB]) & \"'\n",
    "    # exp = '(\"Vasomotor Symptoms\")OR(\"Menopausal Symptoms\")OR(\"Hot Flashes\")OR(\"Hot Flushes\")OR(\"Menopause\")'\n",
    "    print('Initialized Variables')\n",
    "    return year,query_arg,exp,path\n",
    "\n",
    "\n",
    "def process_PM_CT(year,query_arg,exp,path):\n",
    "    #Fetching Data\n",
    "    pubmed_df,pubmed_df_HCP_List = pubmed(year,query_arg)\n",
    "    #pubmed_HCP,pubmed_npi_df = fetch_pubmed_npi(pubmed_df_HCP_List)\n",
    "    \n",
    "    pubmed_df_HCP_List1 = pubmed_df_HCP_List.copy()\n",
    "    pubmed_df_HCP_List1.columns = pubmed_df_HCP_List1.columns.str.upper()\n",
    "    \n",
    "    pubmed_df_HCP_List1.to_csv(path+\"intermediate/pubmed_hcp_list.csv\")\n",
    "    #pubmed_HCP.to_csv(\"Pubmed_HCP.csv\")\n",
    "    \n",
    "    pubmed_df1 = pubmed_df.copy()\n",
    "    pubmed_df1.columns = pubmed_df1.columns.str.upper()\n",
    "    \n",
    "    pubmed_df.to_csv(path+\"intermediate/pubmed_data.csv\")\n",
    "    print(\"\\n\")\n",
    "    #Fetching Data\n",
    "    df_CentralContacts,df_LocationContacts,df_OtherInv,df_RefPMID = Clinical_Trials(exp)\n",
    "    \n",
    "    df_CentralContacts.rename(columns = {'CentralContactName':'fullname'}, inplace = True)\n",
    "    df_LocationContacts.rename(columns = {'LocationContactName':'fullname'}, inplace = True)\n",
    "    df_OtherInv.rename(columns = {'OtherInvName':'fullname'}, inplace = True)\n",
    "    \n",
    "    df_CT = df_CentralContacts.append(df_LocationContacts).append(df_OtherInv).reset_index(drop=True)\n",
    "    print(\"\\n\")\n",
    "    df_CT['firstname'] = df_CT['fullname'].str.split(' ',1).str[0]\n",
    "    df_CT['lastname'] = df_CT['fullname'].str.split(' ').str[-1]\n",
    "    df_CT['name'] = df_CT['firstname'] +' '+ df_CT['lastname']\n",
    "    \n",
    "    df_CT['name'] = df_CT['name'].str.upper()\n",
    "    df_CT['name'] = df_CT['name'].str.strip()\n",
    "    \n",
    "    df_CT.drop_duplicates(['NCTId','name'],inplace=True)\n",
    "    \n",
    "    # CT_HCP,CT_npi_df,df_CT = fetch_CT_npi(df_CentralContacts,df_LocationContacts,df_OtherInv)\n",
    "    # CT_HCP.to_csv(\"CT_HCP.csv\")\n",
    "    \n",
    "    CT_HCP_List = df_CT.copy()\n",
    "    \n",
    "    CT_HCP_List.columns = CT_HCP_List.columns.str.upper()\n",
    "    \n",
    "    CT_HCP_List.to_csv(path+\"intermediate/clinicaltrials_hcp_list.csv\")\n",
    "    \n",
    "    #Master_npi = pubmed_npi_df.append(CT_npi_df)\n",
    "    \n",
    "    pubmed_df_HCP_List.rename(columns = {'fullName':'fullname'}, inplace = True)\n",
    "    CT = df_CT.filter(['NCTId','firstname','lastname','fullname','name']).drop_duplicates()\n",
    "    \n",
    "    pubmed_df_HCP_List['name'] = pubmed_df_HCP_List['name'].str.upper()\n",
    "    \n",
    "    PM_CT_data = pubmed_df_HCP_List.merge(CT,how='outer',on='name',suffixes=('_PM', '_CT'))\n",
    "    \n",
    "    PM_CT_agg = PM_CT_data[['pmid','NCTId','name','fullname_PM','fullname_CT']].groupby('name').agg({\"pmid\": pd.Series.nunique,\"NCTId\": pd.Series.nunique,\"fullname_PM\":np.max,\"fullname_CT\":np.max})\n",
    "    \n",
    "    PM_CT_agg.reset_index(inplace=True)\n",
    "    PM_CT_agg['fullname_PM'] = PM_CT_agg['fullname_PM'].str.upper()\n",
    "    PM_CT_agg['fullname_CT'] = PM_CT_agg['fullname_CT'].str.upper()\n",
    "    \n",
    "    PM_CT_agg_Final = PM_CT_agg.copy()\n",
    "    PM_CT_agg.rename(columns = {'name':'HCP_Name','pmid':'Count of Publications','NCTId':'Count of Clinical Trials','fullname_PM':'Name(PubMed)','fullname_CT':'Name(ClinicalTrials)'}, inplace = True)\n",
    "    \n",
    "    # PM_CT_agg.to_csv(\"PM_CT_agg.csv\")\n",
    "    \n",
    "    print(\"fetched \",len(PM_CT_agg_Final), \" HCPs\")\n",
    "    \n",
    "    #PM_CT_agg_Final.drop(columns = ['fullname_PM','fullname_CT'],inplace=True)\n",
    "    return PM_CT_agg_Final, CT_HCP_List, pubmed_df\n",
    "\n",
    "def fetch_npi(Final_df):\n",
    "    # Final_df = PM_CT_CMS_Final.head(500)\n",
    "    Final_df['firstname'] = Final_df['name'].str.split(' ',1).str[0]\n",
    "    Final_df['lastname'] = Final_df['name'].str.split(' ').str[-1]\n",
    "    \n",
    "    df = Final_df.copy()\n",
    "    df['list'] = df.apply(lambda x: (x['firstname'], x['lastname']), axis=1)\n",
    "    \n",
    "    df_new = pd.DataFrame()\n",
    "    \n",
    "    for x in df['list'].tolist():\n",
    "        try:\n",
    "            r = requests.get('https://npiregistry.cms.hhs.gov/api/?'+\n",
    "                             str('enumeration_type=NPI-1')+'&'+\n",
    "                             str('version=2.1')+'&'+ #+str(x['version'])+'&'+\n",
    "                             str('first_name=')+str(x[0])+'&'+\n",
    "                             str('last_name=')+str(x[1])+'&'+\n",
    "                             str('skip=')+str('')+'&'+str('limit=')+str(''))\n",
    "            data=r.json()\n",
    "            d = pd.DataFrame.from_dict(data['results'], dtype = np.object)  \n",
    "            df_new = df_new.append(d)\n",
    "        except:\n",
    "            pass\n",
    "        # d['Npi_Criteria'] = 'FN+LN'\n",
    "               \n",
    "    basic_col =['ein', 'organization_name', 'last_name', 'first_name', 'middle_name', 'name_prefix', 'name_suffix', 'credential',\n",
    "                'last_updated', 'deactivation_reason_code', 'deactivation_date', 'reactivation_date', 'gender',\n",
    "                'authorized_official_telephone_number']\n",
    "    \n",
    "    address_col = ['address_1', 'address_2', 'city', 'state', 'postal_code', 'country_code', 'telephone_number']\n",
    "    \n",
    "    taxo_col = ['license', 'state']\n",
    "    \n",
    "    d = df_new[['number', 'basic', 'addresses', 'taxonomies']]\n",
    "    \n",
    "    basic = d.basic.apply(pd.Series)\n",
    "    basic_df = pd.DataFrame(columns=basic_col)\n",
    "    basic_df = pd.concat([basic_df,basic]).fillna('none')\n",
    "    basic_df = basic_df[basic_col]\n",
    "    \n",
    "    d = pd.concat([d,basic_df], axis=1)\n",
    "    \n",
    "    d = d.explode('addresses')\n",
    "    \n",
    "    addresses = d.addresses.apply(pd.Series)\n",
    "    \n",
    "    address_df = pd.DataFrame(columns=address_col)\n",
    "    address_df = pd.concat([address_df,addresses]).fillna('none')\n",
    "    address_df = address_df[address_col]\n",
    "    address_df = address_df.rename(columns={'state':'address_state'})\n",
    "    \n",
    "    d = pd.concat([d,address_df], axis=1)\n",
    "    \n",
    "    d = d.explode('taxonomies')\n",
    "    taxonomies = d.taxonomies.apply(pd.Series)\n",
    "    \n",
    "    taxo_df = pd.DataFrame(columns=taxo_col)\n",
    "    taxo_df = pd.concat([taxo_df,taxonomies]).fillna('none')\n",
    "    taxo_df = taxo_df[taxo_col]\n",
    "    taxo_df = taxo_df.rename(columns={'state':'taxo_state'})\n",
    "    \n",
    "    d = pd.concat([d,taxo_df], axis=1) \n",
    "    d = d.drop(['basic', 'addresses','taxonomies'], axis=1)\n",
    "    d = d.drop_duplicates()\n",
    "    \n",
    "    d = d.rename(\n",
    "    columns={'number':'NPI', 'ein': 'Employer_Identification_Number_(EIN)', 'organization_name':'Provider_Organization_Name_(Legal_Business_Name)',\n",
    "             'last_name':'Provider_Last_Name_(Legal_Name)', 'first_name': 'Provider_First_Name', 'middle_name':'Provider_Middle_Name',\n",
    "             'name_prefix': 'Provider_Name_Prefix_Text', 'name_suffix': 'Provider_Name_Suffix_Text',\n",
    "             'credential': 'Provider_Credential_Text', 'last_updated': 'Last_Update_Date',\n",
    "             'deactivation_reason_code':'NPI_Deactivation_Reason_Code', 'deactivation_date': 'NPI_Deactivation_Date',\n",
    "             'reactivation_date': 'NPI_Reactivation_Date', 'gender':'Provider_Gender_Code',\n",
    "             'authorized_official_telephone_number':'Authorized_Official_Telephone_Number',\n",
    "             'address_1': 'Provider_First_Line_Business_Mailing_Address', 'address_2': 'Provider_Second_Line_Business_Mailing_Address',\n",
    "             'city': 'Provider_Business_Mailing_Address_City_Name',\n",
    "             'address_state': 'Provider_Business_Mailing_Address_State_Name',\n",
    "             'postal_code' : 'Provider_Business_Mailing_Address_Postal_Code', 'country_code' : 'Provider_Business_Mailing_Address_Country_Code_(If_outside_US)',\n",
    "             'telephone_number': 'Provider_Business_Mailing_Address_Telephone_Number', 'license': 'Provider_License_Number_1',\n",
    "             'taxo_state':'Provider_License_Number_State_Code_1'})\n",
    "    \n",
    "    npi_df = d.drop_duplicates('NPI', keep='first') \n",
    "      \n",
    "    df['joinkey'] = df['name']\n",
    "    df['joinkey'] = df['joinkey'].str.strip()\n",
    "    df['joinkey'] = df['joinkey'].str.upper()\n",
    "    df.head(10)\n",
    "    \n",
    "    npi_df['joinkey'] = npi_df['Provider_First_Name']+' '+npi_df['Provider_Last_Name_(Legal_Name)']\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.replace(' - ',' ')\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.strip()\n",
    "    npi_df['joinkey'] = npi_df['joinkey'].str.upper()\n",
    "    \n",
    "    HCP = df.merge(npi_df,how='left',on='joinkey')\n",
    "    \n",
    "    HCP_Not_Joined = HCP[HCP['NPI'].isnull()].filter(df.columns)\n",
    "    HCP = HCP[np.logical_not(HCP['NPI'].isnull())]\n",
    "    \n",
    "    HCP['key'] = 1\n",
    "    duplicates = HCP[['joinkey','key']].groupby(['joinkey']).sum()\n",
    "    HCP.drop(['key'],inplace=True,axis=1)\n",
    "    HCP = HCP.merge(duplicates,on='joinkey',how='inner')\n",
    "\n",
    "    HCP_Not_Joined['key'] = 0        \n",
    "    HCP = HCP.append(HCP_Not_Joined)\n",
    "    \n",
    "    HCP = HCP.filter(['name','NPI','key'])\n",
    "    HCP.reset_index(drop=True,inplace=True)\n",
    "    return HCP,npi_df\n",
    "\n",
    "\n",
    "def final_process(path,PM_CT_agg_Final):\n",
    "    HCP = pd.DataFrame()\n",
    "    npi_df = pd.DataFrame()\n",
    "    print(\"\\n\")\n",
    "    for i in range(1,math.ceil(len(PM_CT_agg_Final)/100)+1):\n",
    "        print(i,' fetching Npi for HCPs ',i*100-99,' to ',i*100)\n",
    "        df1,df2 = fetch_npi(pd.DataFrame(PM_CT_agg_Final.loc[i*100-100:i*100,]))\n",
    "        HCP = HCP.append(df1)\n",
    "        npi_df = npi_df.append(df2)\n",
    "        HCP.drop_duplicates(inplace=True)\n",
    "        npi_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    HCP_agg = HCP[['name','NPI']].groupby('name').agg({\"NPI\": pd.Series.nunique})\n",
    "    \n",
    "    HCP_agg.reset_index(inplace=True)\n",
    "    HCP_List = PM_CT_agg_Final.merge(HCP_agg,on='name',how='left')\n",
    "    \n",
    "    HCP_List = HCP_List.filter(['name', 'pmid', 'NCTId', 'NPI', 'fullname_PM', 'fullname_CT'])\n",
    "    \n",
    "    HCP_List['NPI'] = HCP_List['NPI'].fillna(0)\n",
    "    \n",
    "    HCP_List.rename(columns = {'name':'HCP_Name','pmid':'Count of Publications','NCTId':'Count of Clinical Trials','NPI':'Count of NPIs','fullname_PM':'Name(PubMed)','fullname_CT':'Name(ClinicalTrials)'}, inplace = True)\n",
    "    HCP.rename(columns = {'name':'HCP_Name','key':'Count of NPIs'}, inplace = True)\n",
    "    \n",
    "    HCP.to_csv(path+\"intermediate/hcptonpi.csv\")\n",
    "    HCP_List.to_csv(path+\"intermediate/hcp_list.csv\")\n",
    "    npi_df.to_csv(path+\"intermediate/npi_df.csv\")\n",
    "    print(\"\\n\")\n",
    "    print('Done Processing')\n",
    "    \n",
    "    return npi_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
