{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import scipy.spatial.distance as ssd\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy.interpolate\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Import environment tools\n",
    "import re\n",
    "import itertools\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "# Import keras tools\n",
    "from keras import regularizers\n",
    "from keras.callbacks import History \n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Import other tools\n",
    "from __future__ import print_function\n",
    "from pandas import read_excel\n",
    "from IPython.display import Image\n",
    "from collections import Counter\n",
    "from itertools import cycle\n",
    "from scipy import stats, integrate, interp\n",
    "from subprocess import check_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clean_cols(df):\n",
    "    import re\n",
    "    \n",
    "    cols=list(df.columns.values)\n",
    "    \n",
    "    # Lowercase everything\n",
    "    cols=list(map(lambda x: x.lower(), cols))\n",
    "    \n",
    "    # Remove special characters \n",
    "    cols = [re.sub(r'[^a-zA-Z0-9]','_',string) for string in cols]\n",
    "    \n",
    "    # Rename colums\n",
    "    df.columns = cols\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant machine learning models\n",
    "\n",
    "import sklearn\n",
    "# Gradient Boosters\n",
    "import xgboost as xgb # Accuracy\n",
    "import lightgbm as lgb # Speed\n",
    "\n",
    "from sklearn import decomposition, preprocessing, svm\n",
    "# Dimensionality Reduction\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "# Ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "# Guassian\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "# Regression\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# Bayesian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# Instance Based\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Nueral Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Import relevant machine learning analyis tools\n",
    "from sklearn import metrics\n",
    "#from sklearn.cross_validation import KFold, train_test_split\n",
    "# Imputation\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import mean_absolute_error,roc_curve,accuracy_score,auc,roc_auc_score,confusion_matrix,precision_score,recall_score,f1_score, classification_report\n",
    "from sklearn.metrics.cluster import fowlkes_mallows_score\n",
    "from sklearn.model_selection import BaseCrossValidator, GridSearchCV, train_test_split,cross_val_score,cross_validate,cross_val_predict, KFold, StratifiedKFold, learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Standardization\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, label_binarize\n",
    "\n",
    "# Create random state\n",
    "random_state=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df=pd.read_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df.csv\")\n",
    "\n",
    "cols=['interaction_id', 'id', 'rec_date', 'month_id', 'flag', 'value', 'dob', 'ethnicity', 'race', 'state', 'year', 'age', 'row', 'max','age_grp']\n",
    "df.columns = cols\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values='value'\n",
    "index=['interaction_id', 'id', 'rec_date', 'age', 'age_grp', 'race', 'state']\n",
    "columns='flag'\n",
    "aggfunc=max\n",
    "\n",
    "df_pivot = data_pivot(df,values,index,columns,aggfunc)\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=df_pivot[df_pivot['last_period']==1]\n",
    "q=q[['id','rec_date']]\n",
    "q=q.groupby(['id']).agg(['min']).reset_index()\n",
    "q.columns = ['id', 'min_last_period_date']\n",
    "\n",
    "w = pd.merge(df_pivot, q, how=\"left\", on=\"id\")\n",
    "w['post_meno']=np.where(w['rec_date']>= w['min_last_period_date'],1,0)\n",
    "w.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate to Quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate to quarter\n",
    "w['quarter'] = pd.PeriodIndex(w.rec_date, freq='Q').to_timestamp()\n",
    "# Write to csv\n",
    "w.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter.csv\")\n",
    "\n",
    "# Max to the quarter\n",
    "q=w.groupby(['id', 'quarter']).max().reset_index()\n",
    "q.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make there is certain number of interactions and BMI records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=pd.read_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg.csv\")\n",
    "w['max']=w['id'].groupby(w['id']).transform('count')\n",
    "\n",
    "# Get list of ids that meet threshold of interactions\n",
    "w.groupby(['max'])['id'].nunique()\n",
    "pts_int_thresh=w[w['max']>10]\n",
    "pts_int_thresh=pts_int_thresh[pts_int_thresh['max']<20]\n",
    "pts_int_thresh_list=set(pts_int_thresh['id'])\n",
    "pts_int_thresh.groupby(['max'])['id'].nunique()\n",
    "print(pts_int_thresh.shape)\n",
    "print(len(pts_int_thresh_list))\n",
    "\n",
    "# Make there is certain number of interactions\n",
    "w.columns\n",
    "e=w[w['id'].isin(pts_int_thresh_list)]\n",
    "print('Pts before filter ', w['id'].nunique())\n",
    "print('Pts that meet interaction threshold ', len(pts_int_thresh_list))\n",
    "print('Pts after filter ', e['id'].nunique())\n",
    "\n",
    "e.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BMI Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove BMI Outliers\n",
    "w=pd.read_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg2.csv\")\n",
    "\n",
    "#Replace any BMI values below 15 and above 50 with 0\n",
    "w1=w[(w['bmi']<15) | (w['bmi']>50)]\n",
    "w2=w[~w['interaction_id'].isin(w1['interaction_id'])]\n",
    "w1['bmi']=0\n",
    "\n",
    "# Add bmi data back\n",
    "w3 = pd.concat([w1, w2])\n",
    "\n",
    "print(w.shape[0], ' interactions in original df')\n",
    "print(w3.shape[0], ' interactions in cleansed df')\n",
    "print('BMI Range (original): ', max(w['bmi']),' -', min(w['bmi']))\n",
    "print('BMI Range (cleansed): ', max(w3['bmi']),' -', min(w3['bmi']))\n",
    "\n",
    "w3.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg2_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure there are atleast 2 BMI records\n",
    "w=pd.read_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg2_clean.csv\")\n",
    "\n",
    "#Replace any BMI values below 15 with 0\n",
    "\n",
    "\n",
    "# Get count of records for each id with bmi values that aren't 0\n",
    "yes_bmi=w[w['bmi']>0].groupby('id')['bmi'].count().reset_index()\n",
    "\n",
    "# Get ids that have mort than 2 records\n",
    "yes_bmi=yes_bmi[yes_bmi['bmi']>2]\n",
    "yes_bmi.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\crap.csv\")\n",
    "\n",
    "# Filter the dataset to only include these ids\n",
    "q=w[w['id'].isin(yes_bmi['id'])]\n",
    "print('# of patients with more than 1 good BMI record',len(yes_bmi['id']))\n",
    "print('# of patients to keep',q['id'].nunique())\n",
    "\n",
    "q.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg3.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolate BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://kanoki.org/2020/04/14/resample-and-interpolate-time-series-data/\n",
    "q=pd.read_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg3.csv\")\n",
    "\n",
    "q[ 'quarter' ] = pd.to_datetime(q['quarter'])\n",
    "\n",
    "# Replace 0 with NAN\n",
    "q.replace(0, np.nan, inplace=True)\n",
    "\n",
    "def interpolate_bmi(df):\n",
    "    # Interpolate BMI\n",
    "    q1=df[['quarter', 'bmi']].set_index('quarter').resample('Q', label='left').mean().interpolate('spline', order=1)\n",
    "    \n",
    "    # Replace BMI with nearest when unable to interpolate\n",
    "    mask = np.isnan(q1['bmi'])\n",
    "    q1['bmi'][mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), q1['bmi'][~mask])\n",
    "\n",
    "    # Reset Index\n",
    "    q1=q1.reset_index()\n",
    "    \n",
    "    # Fix date\n",
    "    q1['quarter']=pd.DatetimeIndex(q1['quarter']) + pd.DateOffset(1)\n",
    "    \n",
    "    # Merge back with dataset\n",
    "    del(df['bmi'])\n",
    "    q2=df.merge(q1, how='left', on='quarter')\n",
    "    return q2\n",
    "\n",
    "q1=q.groupby('id').apply(lambda x: interpolate_bmi(x))\n",
    "\n",
    "q1.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg3_bmi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Race, Remove Ineligible patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-138-dd198c2879f5>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  q['race']=q['race'].str.lower()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124092, 42)\n",
      "(124092, 27)\n",
      "(124092, 66)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>quarter</th>\n",
       "      <th>race</th>\n",
       "      <th>amenorrhea</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>bloating</th>\n",
       "      <th>dec_libido</th>\n",
       "      <th>depression</th>\n",
       "      <th>dizziness</th>\n",
       "      <th>...</th>\n",
       "      <th>bi_oophorectomy</th>\n",
       "      <th>birth_control</th>\n",
       "      <th>endometrial ablation</th>\n",
       "      <th>hrt</th>\n",
       "      <th>hyst_oophorectomy</th>\n",
       "      <th>hysterectomy</th>\n",
       "      <th>menopause</th>\n",
       "      <th>smoker</th>\n",
       "      <th>uni_oophorectomy</th>\n",
       "      <th>bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>612281</td>\n",
       "      <td>51</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>CAUCASIAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>612281</td>\n",
       "      <td>51</td>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>CAUCASIAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>612281</td>\n",
       "      <td>51</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>CAUCASIAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>612281</td>\n",
       "      <td>51</td>\n",
       "      <td>2011-10-01</td>\n",
       "      <td>CAUCASIAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>612281</td>\n",
       "      <td>52</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>CAUCASIAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.278615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  age     quarter       race  amenorrhea  anxiety  bloating  \\\n",
       "0  612281   51  2011-01-01  CAUCASIAN         0.0      0.0       0.0   \n",
       "1  612281   51  2011-04-01  CAUCASIAN         0.0      0.0       0.0   \n",
       "2  612281   51  2011-07-01  CAUCASIAN         0.0      0.0       0.0   \n",
       "3  612281   51  2011-10-01  CAUCASIAN         0.0      0.0       0.0   \n",
       "4  612281   52  2012-01-01  CAUCASIAN         0.0      0.0       0.0   \n",
       "\n",
       "   dec_libido  depression  dizziness  ...  bi_oophorectomy  birth_control  \\\n",
       "0         0.0         0.0        0.0  ...              0.0            0.0   \n",
       "1         0.0         1.0        0.0  ...              0.0            0.0   \n",
       "2         0.0         1.0        0.0  ...              0.0            0.0   \n",
       "3         0.0         1.0        0.0  ...              0.0            0.0   \n",
       "4         0.0         1.0        0.0  ...              0.0            0.0   \n",
       "\n",
       "   endometrial ablation  hrt  hyst_oophorectomy  hysterectomy  menopause  \\\n",
       "0                   0.0  0.0                0.0           0.0        0.0   \n",
       "1                   0.0  0.0                0.0           0.0        0.0   \n",
       "2                   0.0  0.0                0.0           0.0        0.0   \n",
       "3                   0.0  0.0                0.0           0.0        0.0   \n",
       "4                   0.0  0.0                0.0           0.0        0.0   \n",
       "\n",
       "   smoker  uni_oophorectomy        bmi  \n",
       "0     1.0               0.0  17.920000  \n",
       "1     1.0               0.0  18.840000  \n",
       "2     0.0               0.0  17.190000  \n",
       "3     0.0               0.0  19.020000  \n",
       "4     1.0               0.0  18.278615  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e=pd.read_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\data\\emr\\test\\df_quarter_agg3_bmi.csv\")\n",
    "e=e.fillna(0)\n",
    "\n",
    "# Convert race to categorical\n",
    "q=e[['race']]\n",
    "q['race']=q['race'].str.lower()\n",
    "q=pd.get_dummies(q)\n",
    "q['interaction_id']=e['interaction_id']\n",
    "\n",
    "# Add back new race columns\n",
    "e=e.merge(q, on='interaction_id')\n",
    "\n",
    "# Filter patients with surgical menopause, cancer\n",
    "w1=e[e['bi_oophorectomy']==1]\n",
    "w2=e[e['hysterectomy']==1]\n",
    "w3=e[e['uni_oophorectomy']==1]\n",
    "w4=e[(e['cancer']==1) | (e['breast_cancer']==1)]\n",
    "w5 = pd.concat([w1,w2,w3, w4],ignore_index=True)\n",
    "\n",
    "e=e[~e.id.isin(w5['id'])]\n",
    "\n",
    "# Combine fatigue and sleep_distrubance\n",
    "e['fatigue_sleep_disturbances']=e['fatigue']+e['sleep_disturbance']\n",
    "\n",
    "# Change dry_skin to skin_changes\n",
    "e['skin_changes']=e['dry_skin']\n",
    "\n",
    "symp_list=list(e.columns)\n",
    "unwanted = {'interaction_id','min_last_period_date', 'rec_date', \n",
    "            'Unnamed: 0', 'Unnamed: 1', 'Unnamed: 0', 'Unnamed: 0.1', \n",
    "            'Unnamed: 0.1.1', 'Unnamed: 0.1.1.1', 'id.1',\n",
    "            'age_grp', 'state', 'last_period', 'max', \n",
    "            'dry_skin','fatigue', 'sleep_disturbance'}\n",
    "cofactor_list=['race_african american','race_asian','race_caucasian',\n",
    "               'race_hispanic','race_other','race_unknown', \n",
    "               'breast_cancer','cancer','alcohol_consumption', \n",
    "               'bc_implant', 'bc_injection', 'bc_oral', 'bc_other','bc_patch', \n",
    "               'bi_oophorectomy', 'birth_control', 'endometrial ablation',\n",
    "               'hrt', 'hyst_oophorectomy', 'hysterectomy',\n",
    "               'menopause', 'smoker','uni_oophorectomy', 'bmi']\n",
    "\n",
    "symp_list = [e for e in symp_list if e not in unwanted]\n",
    "symp_list = [e for e in symp_list if e not in cofactor_list]\n",
    "\n",
    "train=e[symp_list]\n",
    "cofactors=e[cofactor_list+['id', 'age','quarter']]\n",
    "\n",
    "# Reduce sparsity in data\n",
    "# train['sym_count']=train.drop(['id','age'],axis=1).sum(1)\n",
    "# train = train[train['sym_count']>3]\n",
    "\n",
    "# Copy dataset, so changes won't happen to train df\n",
    "df1=train.copy()\n",
    "\n",
    "# Change column names and move to front\n",
    "df1.insert(0, 'age', df1.pop('age'))\n",
    "df1.insert(0, 'id', df1.pop('id'))\n",
    "cofactors.insert(0, 'age', cofactors.pop('age'))\n",
    "cofactors.insert(0, 'id', cofactors.pop('id'))\n",
    "\n",
    "# Make df distinct by id, age, and quarter\n",
    "df1=df1.groupby(['id', 'age', 'quarter']).first().reset_index()\n",
    "cofactors=cofactors.groupby(['id', 'age', 'quarter']).first().reset_index()\n",
    "\n",
    "# Keep certain features\n",
    "features=list(df1.columns)\n",
    "df1 = df1[features]\n",
    "\n",
    "# Merge symtoms and cofactors\n",
    "risk_pred=df1.merge(cofactors, on=['id', 'age', 'quarter'])\n",
    "\n",
    "print(df1.shape)\n",
    "print(cofactors.shape)\n",
    "print(risk_pred.shape)\n",
    "risk_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arguments For Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What variable are you assessing risk for?\n",
    "risk_param='hot_flash'\n",
    "\n",
    "# Risk at what time period (quarters)\n",
    "risk_time=1\n",
    "\n",
    "# What variables will be inputs to the model?\n",
    "cofactor_list=[\n",
    "# COFACTORS\n",
    "'race_african american',\n",
    " 'race_asian',\n",
    " 'race_caucasian',\n",
    " 'race_hispanic',\n",
    " 'race_other',\n",
    " 'race_unknown',\n",
    " # 'breast_cancer',\n",
    " # 'cancer',\n",
    " 'alcohol_consumption',\n",
    " 'bc_implant',\n",
    " 'bc_injection',\n",
    " 'bc_oral',\n",
    " 'bc_other',\n",
    " 'bc_patch',\n",
    " 'birth_control',\n",
    " 'bi_oophorectomy',\n",
    " # 'endometrial ablation',\n",
    " # 'hrt',\n",
    " # 'hyst_oophorectomy',\n",
    " 'hysterectomy',\n",
    " 'menopause',\n",
    " 'smoker',\n",
    " # 'uni_oophorectomy',\n",
    " # 'bmi'\n",
    "# SYMPTOMS\n",
    " # 'amenorrhea',\n",
    " 'anxiety',\n",
    " # 'bloating',\n",
    " 'dec_libido',\n",
    " 'depression',\n",
    " # 'dizziness',\n",
    " 'dyspareunia',\n",
    " 'fatigue_sleep_disturbances',\n",
    " 'hair_loss',\n",
    " 'headache_migraine',\n",
    " # 'headache_migraine_freq',\n",
    " # 'headache_migraine_rx',\n",
    " 'hot_flash',\n",
    " # 'hot_flash_freq',\n",
    " # 'hot_flash_rx',\n",
    " # 'hot_flash_sev',\n",
    " # 'incontinence',\n",
    " 'irritability',\n",
    " 'memory_lapse',\n",
    " # 'menstrual_changes',\n",
    " 'night_sweats',\n",
    " # 'night_sweats_freq',\n",
    " # 'night_sweats_rx',\n",
    " # 'night_sweats_sev',\n",
    " 'oab_incontinence',\n",
    " # 'oligomenorrhea',\n",
    " # 'osteoporosis',\n",
    " # 'sexual_dysfunction',\n",
    "'skin_changes',\n",
    " # 'sleep_disturbance',\n",
    " # 'stress_incontinence',\n",
    " 'urge_incontinence',\n",
    " 'uti',\n",
    " 'vaginal_dryness',\n",
    " # 'vaginal_dryness_freq',\n",
    " # 'vaginal_dryness_rx',\n",
    " # 'vaginal_dryness_sev',\n",
    " 'weight_gain',\n",
    " # 'post_meno'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Test Model for Selection and Deployment to API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dependant variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dependant variable\n",
    "grouped = risk_pred.groupby('id')\n",
    "L = []\n",
    "for id, id_df in grouped:\n",
    "    id_df['risk']=id_df[risk_param].shift(risk_time)\n",
    "    L.append(id_df)\n",
    "\n",
    "risk_pred=pd.concat(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Address Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: (113872, 67)\n",
      "class 1: (947, 67)\n",
      "total class of 1 and 0: 0.0    203082\n",
      "1.0     24662\n",
      "Name: hot_flash, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# class count\n",
    "class_count_0, class_count_1 = risk_pred['risk'].value_counts()\n",
    "\n",
    "# Separate class\n",
    "class_0 = risk_pred[risk_pred['risk'] == 0]\n",
    "class_1 = risk_pred[risk_pred['risk'] == 1]\n",
    "\n",
    "# print the shape of the class\n",
    "print('class 0:', class_0.shape)\n",
    "print('class 1:', class_1.shape)\n",
    "\n",
    "class_1_over = class_1.sample(class_count_0, replace=True)\n",
    "\n",
    "test_over = pd.concat([class_1_over, class_0], axis=0)\n",
    "\n",
    "print(\"total class of 1 and 0:\",test_over[risk_param].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cofactors: (227744, 34)\n",
      "Risk: (227744,)\n"
     ]
    }
   ],
   "source": [
    "X = test_over[cofactor_list]\n",
    "y = test_over['risk']\n",
    "\n",
    "print(\"Cofactors:\", X.shape)\n",
    "print(\"Risk:\",y.shape)\n",
    "\n",
    "# Create Train and Test Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=random_state, test_size=.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test Multiple Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.628345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1 Score\n",
       "Random Forest  0.628345"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\n",
    "        \"Random Forest\"\n",
    "        # ,\"k-Nearest Neighbors\"         \n",
    "         # ,\"Support Vector Machine\"\n",
    "         # ,\"Linear SVM\"\n",
    "         # ,\"RBF SVM\"\n",
    "         # ,\"Gaussian Process\"\n",
    "         # ,\"Decision Tree\"\n",
    "         # ,\"Extra Trees\"\n",
    "         # ,\"Extra Forest\"\n",
    "         # ,\"AdaBoost\"\n",
    "         # ,\"Gaussian Naive Bayes\"\n",
    "         # ,\"LDA\"\n",
    "         # ,\"QDA\"\n",
    "         # ,\"Logistic Regression\"\n",
    "         # ,\"SGD Classifier\"\n",
    "         # ,\"Multilayer Perceptron\"\n",
    "         # ,\"Voting Classifier\"\n",
    "        ]\n",
    "\n",
    "algorithms = [\n",
    "                RandomForestClassifier(random_state=random_state)\n",
    "                # ,KNeighborsClassifier(n_neighbors=3)\n",
    "               # ,SVC(random_state=random_state)\n",
    "               # ,SVC(kernel=\"linear\",random_state=random_state)\n",
    "               # ,SVC(kernel=\"rbf\",random_state=random_state)\n",
    "               # ,GaussianProcessClassifier()\n",
    "               # ,DecisionTreeClassifier(random_state=random_state)\n",
    "               # ,ExtraTreesClassifier(random_state=random_state)\n",
    "               # ,GradientBoostingClassifier(random_state=random_state)\n",
    "               # ,AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),n_estimators=10,learning_rate=0.1,random_state=random_state)\n",
    "               # ,GaussianNB()\n",
    "               # ,LinearDiscriminantAnalysis()\n",
    "               # ,QuadraticDiscriminantAnalysis()\n",
    "               # ,LogisticRegression(random_state=random_state)\n",
    "               # ,SGDClassifier()\n",
    "               # ,MLPClassifier(hidden_layer_sizes=(100,),momentum=0.9,solver='sgd',random_state=random_state)\n",
    "               # ,VotingClassifier(estimators=[('log', LogisticRegression()), ('SVM',SVC(C=1000)), ('MLP', MLPClassifier(hidden_layer_sizes=(100,)))], voting='hard')\n",
    "              ]\n",
    "#algorithms.append(SVC(random_state=random_state))\n",
    "\n",
    "classifiers = {\n",
    "                     \"Random Forest\" : RandomForestClassifier(random_state=random_state)\n",
    "                    # ,\"k-Nearest Neighbors\" : KNeighborsClassifier(n_neighbors=3)\n",
    "                 # ,\"Support Vector Machine\" :  SVC(random_state=random_state)\n",
    "                 # ,\"Linear SVM\" :  SVC(kernel=\"linear\",random_state=random_state)\n",
    "              #    ,\"RBF SVM\" :  SVC(kernel=\"rbf\",random_state=random_state)\n",
    "              #    ,\"Gaussian Process\" : GaussianProcessClassifier()\n",
    "              #    ,\"Decision Tree\" : DecisionTreeClassifier(random_state=random_state)\n",
    "              #    ,\"Extra Trees\" : ExtraTreesClassifier(random_state=random_state)\n",
    "                 # ,\"Extra Forest\" : GradientBoostingClassifier(random_state=random_state)\n",
    "                 # ,\"AdaBoost\" : AdaBoostClassifier(DecisionTreeClassifier(random_state=random_state),n_estimators=10,random_state=random_state,learning_rate=0.1)\n",
    "              #    ,\"Gaussian Naive Bayes\" : GaussianNB()\n",
    "              #    ,\"LDA\" : LinearDiscriminantAnalysis()\n",
    "              #    ,\"QDA\" :  QuadraticDiscriminantAnalysis()\n",
    "              #    ,\"Logistic Regression\" : LogisticRegression(random_state=random_state)\n",
    "              #    ,\"SGD Classifier\" : SGDClassifier()\n",
    "              #    ,\"Multilayer Perceptron\" :  MLPClassifier(hidden_layer_sizes=(100,),momentum=0.9,solver='sgd',random_state=random_state)\n",
    "              #    ,\"Voting Classifier\" : VotingClassifier(estimators=[('log', LogisticRegression()), ('SVM',SVC(C=1000)), ('MLP', MLPClassifier(hidden_layer_sizes=(100,)))], voting='hard')\n",
    "              }\n",
    "\n",
    "\n",
    "# Test different algorithms\n",
    "data_copy=[]\n",
    "for model in algorithms:\n",
    "    model.fit(X_train,y_train)\n",
    "    pred_test = model.predict(X_test)\n",
    "    data_copy.append(metrics.f1_score(pred_test, y_test))\n",
    "    \n",
    "models_df = pd.DataFrame(data_copy, index=names)   \n",
    "models_df.columns=['F1 Score']\n",
    "models_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select Model Winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winner is: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.628345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  F1 Score\n",
       "0  Random Forest  0.628345"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select Model Winner\n",
    "print('The winner is: ')\n",
    "\n",
    "winner=models_df[models_df['F1 Score']==max(models_df['F1 Score'])].reset_index()\n",
    "winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train the winner and output into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROCAUC score: 0.6754748716695069\n",
      "Accuracy score: 0.6747555763714068\n",
      "F1 score: 0.6283449290875033\n"
     ]
    }
   ],
   "source": [
    "winner_name=winner['index'][0]\n",
    "index = names.index(winner_name)\n",
    "\n",
    "srp = algorithms[index]\n",
    "\n",
    "# fit the predictor and target\n",
    "srp.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "srp_predict = srp.predict(X_test)# check performance\n",
    "print('ROCAUC score:',roc_auc_score(y_test, srp_predict))\n",
    "print('Accuracy score:',accuracy_score(y_test, srp_predict))\n",
    "print('F1 score:',f1_score(y_test, srp_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Simulate User Input into Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Survey Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your probability of hot_flash in the next 1 quarter, is: 0.995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Dataframe of survey inputs\n",
    "survey_inputs=[{'race_african american':0,\n",
    " 'race_asian':0,\n",
    " 'race_caucasian':1, \n",
    " 'race_hispanic':0, \n",
    " 'race_other':0, \n",
    " 'race_unknown':0, \n",
    " 'alcohol_consumption':0, \n",
    " 'bc_implant':0,\n",
    " 'bc_injection':0, \n",
    " 'bc_oral':0, \n",
    " 'bc_other':0, \n",
    " 'bc_patch':0, \n",
    " 'bi_oophorectomy':0, \n",
    " 'birth_control':0, \n",
    " 'hysterectomy':0, \n",
    " 'menopause':0, \n",
    " 'smoker':1, \n",
    " 'anxiety':0, \n",
    " 'dec_libido':0, \n",
    " 'depression':0,  \n",
    " 'dyspareunia':0, \n",
    " 'fatigue_sleep_disturbances':0, \n",
    " 'hair_loss':0, \n",
    " 'headache_migraine':0, \n",
    " 'hot_flash':1, \n",
    "'irritability':0,\n",
    " 'memory_lapse':0, \n",
    " 'night_sweats':0, \n",
    " 'oab_incontinence':0,\n",
    "'skin_changes':0,\n",
    " 'urge_incontinence':0, \n",
    " 'uti':0, \n",
    " 'vaginal_dryness':0, \n",
    " 'weight_gain':0}]\n",
    "survey_inputs = pd.DataFrame(survey_inputs)\n",
    "\n",
    "# Test Input\n",
    "print(\"Your probability of\", risk_param, 'in the next', \n",
    "      risk_time, 'quarter, is:', \n",
    "      round(float(srp.predict_proba(survey_inputs)[:,1]),3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
