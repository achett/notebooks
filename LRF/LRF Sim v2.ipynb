{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18491.32047982937\n",
      "7309.662391952652\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "######################\n",
    "# READ IN DATA\n",
    "######################\n",
    "sales_ci=pd.read_excel(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\Synchronization CSP & AP\\inputs.xlsx\", sheet_name='sales_ci')\n",
    "unc_p=pd.read_excel(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\Synchronization CSP & AP\\inputs.xlsx\", sheet_name='unc_p')\n",
    "unc_p_desc=pd.read_excel(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\Synchronization CSP & AP\\inputs.xlsx\", sheet_name='unc_p_desc')\n",
    "unc_pri=pd.read_excel(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\Synchronization CSP & AP\\inputs.xlsx\", sheet_name='unc_pri')\n",
    "unc_pri_desc=pd.read_excel(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\Synchronization CSP & AP\\inputs.xlsx\", sheet_name='unc_pri_desc')\n",
    "\n",
    "######################\n",
    "# PREP DATA\n",
    "######################\n",
    "sales_ci=sales_ci.drop_duplicates()\n",
    "sales_ci=sales_ci.melt(id_vars=['product', 'region', 'units', 'indication'], \n",
    "        var_name=\"year\", \n",
    "        value_name=\"sales\")\n",
    "sales_ci=sales_ci[(sales_ci['units'] =='¥')]\n",
    "\n",
    "# Exclude indications that are not needed\n",
    "exclude_ind = ['Adjustments', 'Central Adjustments', 'Total']\n",
    "sales_ci=sales_ci[(~sales_ci['indication'].isin(exclude_ind))]\n",
    "\n",
    "# Partition WW sales into 9 segments -> US, JP, CN, DE, FR, ES, IT, GB, WWex8\n",
    "sales_ci_WW=sales_ci[(sales_ci['region']=='WW')]\n",
    "ast8 = ['US','JP','CN', 'DE','FR','ES','IT','GB']\n",
    "sales_ci_ast8=sales_ci[(sales_ci['region'].isin(ast8))]\n",
    "\n",
    "sales_ci_WWex8=sales_ci_ast8.groupby(['product','units','indication','year']).sum().reset_index()\n",
    "sales_ci_WWex8=sales_ci_WW.merge(sales_ci_WWex8, how='right', on=['product', 'units', 'indication', 'year'])\n",
    "sales_ci_WWex8['sales']=sales_ci_WWex8['sales_x']-sales_ci_WWex8['sales_y']\n",
    "sales_ci_WWex8['region']='WWex8'\n",
    "sales_ci_WWex8 = sales_ci_WWex8[['product','region', 'units', 'indication', 'year', 'sales']]\n",
    "\n",
    "# Generate new sales table\n",
    "sales_ci_clean=pd.concat([sales_ci_ast8, sales_ci_WWex8])\n",
    "\n",
    "# Add back non-strategic products\n",
    "sales_ci_nsp=sales_ci[(sales_ci['indication']=='Non-Strategic')]\n",
    "sales_ci_clean=pd.concat([sales_ci_clean, sales_ci_nsp])\n",
    "\n",
    "# Create tag\n",
    "sales_ci_clean['tag'] = sales_ci_clean['product'] + sales_ci_clean['region'] + sales_ci_clean['units'] + sales_ci_clean['indication'].astype(str)+ sales_ci_clean['year'].astype(str)\n",
    "\n",
    "# Validation\n",
    "print(sum(sales_ci_clean[(sales_ci_clean['year']==2025)]['sales']))  #18426\n",
    "print(sum(sales_ci_clean[(sales_ci_clean['product']=='xtandi') & (sales_ci_clean['year']==2025)]['sales']))  #7309\n",
    "print(sales_ci_clean['tag'].nunique()) # 700\n",
    "\n",
    "# Save new sales data\n",
    "sales_ci_clean.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\Synchronization CSP & AP\\output\\sales_ci_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18491.320479829377\n",
      "7309.662391952652\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# PHASE 1: PTRS\n",
    "#############\n",
    "# Create output df\n",
    "output_df = pd.DataFrame(columns=['tag','product', 'region', 'units', 'indication', 'year', 'sales', 'sales_RA_10', 'sales_RA_50', 'sales_RA_90'])\n",
    "\n",
    "# Add PTRS values to sales data\n",
    "sales_ci_unc = sales_ci_clean.merge(unc_pri, how='right', on=['product','region', 'units', 'indication', 'year'])\n",
    "\n",
    "# Loop through rows\n",
    "for index, row in sales_ci_unc.iterrows():\n",
    "# for index, row in sales_ci_unc.iloc[29:30].iterrows():\n",
    "    n=500\n",
    "    sales_ra = []\n",
    "    for i in range(n):\n",
    "        \n",
    "        # Get sales (value)\n",
    "        sales = row.values[5]\n",
    "        \n",
    "        # Get PTRS Uncertainty Probability (value)\n",
    "        unc_ptrs_prob=np.random.binomial(size=1, n=1, p=row.values[7])\n",
    "        \n",
    "        # Get Uncertainty Value (value) for others\n",
    "        unc1=row.values[8]\n",
    "        unc2=row.values[9]\n",
    "        \n",
    "        if ((unc_ptrs_prob == 1) and ((~np.isnan(unc1)) or (~np.isnan(unc2)) )):\n",
    "            m=500\n",
    "            for j in range(m):\n",
    "\n",
    "                # Get Uncertainty Probability (value) for others\n",
    "                unc1_prob=np.random.randint(1,4)\n",
    "                \n",
    "                if ((unc1_prob == 1)):\n",
    "                    sales=unc1\n",
    "                \n",
    "                if ((unc1_prob == 2)):\n",
    "                    sales=unc2\n",
    "        \n",
    "        # Generate RA sales\n",
    "        unc_all=float(sales)*float(unc_ptrs_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "        \n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales = sales_ci_unc.iloc[index]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_RA_mean'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df = output_df.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "# Save outputs\n",
    "output_df = output_df[['tag','product','region', 'units', 'indication', 'year', 'sales', 'sales_RA_10', 'sales_RA_50', 'sales_RA_90', 'sales_RA_mean']]\n",
    "\n",
    "sales_exPTRS=sales_ci_clean[~(sales_ci_clean['tag'].isin(output_df['tag']))]\n",
    "sales_exPTRS['sales_RA_10']=sales_exPTRS['sales']\n",
    "sales_exPTRS['sales_RA_50']=sales_exPTRS['sales']\n",
    "sales_exPTRS['sales_RA_90']=sales_exPTRS['sales']\n",
    "sales_exPTRS['sales_RA_mean']=sales_exPTRS['sales']\n",
    "output_df=pd.concat([output_df, sales_exPTRS])\n",
    "\n",
    "# Validation\n",
    "print(sum(output_df[(output_df['year']==2025)]['sales']))  #18426\n",
    "print(sum(output_df[(output_df['product']=='xtandi') & (output_df['year']==2025)]['sales'])) #7309\n",
    "print(output_df['tag'].nunique()) # 700\n",
    "\n",
    "output_df.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\Synchronization CSP & AP\\output\\output_phase1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18491.320479829377\n",
      "7309.662391952652\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# PHASE 2: COMMERCIAL UNCERTAINTY\n",
    "#############\n",
    "# Convert PTRS results to sales df for next phase (Commercial Uncertainty)\n",
    "sales_ptrs=output_df[['tag','product','region', 'units', 'indication', 'year', 'sales', 'sales_RA_mean']]\n",
    "sales_ptrs.columns = ['tag','product','region', 'units', 'indication', 'year', 'sales', 'sales_p1_RA']\n",
    "\n",
    "# Sum sales at the WW level\n",
    "sales_ptrs_ww=sales_ptrs.groupby(['product','units','indication','year']).sum().reset_index()\n",
    "sales_ptrs_ww['region']='Total'\n",
    "sales_ptrs=pd.concat([sales_ptrs_ww, sales_ptrs])\n",
    "\n",
    "# Sum sales at the Product level, as commercial uncertainty is applied at a higher granularity\n",
    "sales_ptrs_prod=sales_ptrs.groupby(['product','units','region','year']).sum().reset_index()\n",
    "sales_ptrs_prod['indication']='Total'\n",
    "sales_ptrs=pd.concat([sales_ptrs_prod, sales_ptrs])\n",
    "\n",
    "# Validation\n",
    "print(sum(sales_ptrs[(sales_ptrs['year']==2025)& (sales_ptrs['region']!='Total') & (sales_ptrs['indication']!='Total')]['sales']))  #18426\n",
    "print(sum(sales_ptrs[(sales_ptrs['product']=='xtandi') & (sales_ptrs['year']==2025) & (sales_ptrs['region']!='Total') & (sales_ptrs['indication']!='Total')]['sales']))  #7309\n",
    "print(sales_ptrs[(sales_ptrs['region']!='Total') & (sales_ptrs['indication']!='Total')]['tag'].nunique()) # 700\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18491.320479829374\n",
      "7309.662391952652\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# CREATE INPUT & OUTPUT DF\n",
    "######################\n",
    "output_df2 = pd.DataFrame(columns=['tag','product', 'region', 'units', 'indication', 'year', 'sales', 'sales_RA_10', 'sales_RA_50', 'sales_RA_90'])\n",
    "\n",
    "# Create input df\n",
    "sales_p2=sales_ptrs[(sales_ptrs['region']=='Total') & (sales_ptrs['indication']=='Total')]\n",
    "\n",
    "# Validation\n",
    "print(sum(sales_p2[(sales_p2['year']==2025)]['sales']))  #18426\n",
    "print(sum(sales_p2[(sales_p2['product']=='xtandi') & (sales_p2['year']==2025)]['sales']))  #7309"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>product</th>\n",
       "      <th>region</th>\n",
       "      <th>units</th>\n",
       "      <th>indication</th>\n",
       "      <th>year</th>\n",
       "      <th>sales</th>\n",
       "      <th>sales_RA_10</th>\n",
       "      <th>sales_RA_50</th>\n",
       "      <th>sales_RA_90</th>\n",
       "      <th>sales_p1_RA</th>\n",
       "      <th>sales_p2_RA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>xtandi</td>\n",
       "      <td>Total</td>\n",
       "      <td>¥</td>\n",
       "      <td>Total</td>\n",
       "      <td>2022</td>\n",
       "      <td>6205.689687</td>\n",
       "      <td>5971.577664</td>\n",
       "      <td>6121.992532</td>\n",
       "      <td>6258.990215</td>\n",
       "      <td>6122.596922</td>\n",
       "      <td>6118.755404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>xtandi</td>\n",
       "      <td>Total</td>\n",
       "      <td>¥</td>\n",
       "      <td>Total</td>\n",
       "      <td>2023</td>\n",
       "      <td>6573.134521</td>\n",
       "      <td>6289.597046</td>\n",
       "      <td>6479.094374</td>\n",
       "      <td>6620.729822</td>\n",
       "      <td>6440.834647</td>\n",
       "      <td>6467.527601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>xtandi</td>\n",
       "      <td>Total</td>\n",
       "      <td>¥</td>\n",
       "      <td>Total</td>\n",
       "      <td>2024</td>\n",
       "      <td>6901.520169</td>\n",
       "      <td>6596.739487</td>\n",
       "      <td>6749.200812</td>\n",
       "      <td>6934.860753</td>\n",
       "      <td>6721.991031</td>\n",
       "      <td>6759.488861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>xtandi</td>\n",
       "      <td>Total</td>\n",
       "      <td>¥</td>\n",
       "      <td>Total</td>\n",
       "      <td>2025</td>\n",
       "      <td>7309.662392</td>\n",
       "      <td>6976.458287</td>\n",
       "      <td>7161.761481</td>\n",
       "      <td>7345.427952</td>\n",
       "      <td>7067.757350</td>\n",
       "      <td>7163.654841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tag product region units indication  year        sales  sales_RA_10  \\\n",
       "0    0  xtandi  Total     ¥      Total  2022  6205.689687  5971.577664   \n",
       "1    0  xtandi  Total     ¥      Total  2023  6573.134521  6289.597046   \n",
       "2    0  xtandi  Total     ¥      Total  2024  6901.520169  6596.739487   \n",
       "3    0  xtandi  Total     ¥      Total  2025  7309.662392  6976.458287   \n",
       "\n",
       "   sales_RA_50  sales_RA_90  sales_p1_RA  sales_p2_RA  \n",
       "0  6121.992532  6258.990215  6122.596922  6118.755404  \n",
       "1  6479.094374  6620.729822  6440.834647  6467.527601  \n",
       "2  6749.200812  6934.860753  6721.991031  6759.488861  \n",
       "3  7161.761481  7345.427952  7067.757350  7163.654841  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############\n",
    "# XTANDI\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'xtandi'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    n=500\n",
    "    sales_ra = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get Uncertainty Probability (value)\n",
    "        unc1_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc1')]['probability'], 1, 1)\n",
    "        unc2_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc2')]['probability'], 1, 1)\n",
    "        unc3_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc3')]['probability'], 1, 1)\n",
    "        \n",
    "        # Get Base Uncertainty\n",
    "        unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "        unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "        # Get Uncertainty Quant by year (series)\n",
    "        unc1=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc1']\n",
    "        unc2=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc2']\n",
    "        unc3=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc3']\n",
    "\n",
    "        # Generate RA sales\n",
    "        sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "        unc_all=float(sales['sales_p1_RA']) + float(sales['sales_p1_RA']*unc_base_prob) + float(unc1*unc1_prob) + float(unc2*unc2_prob) + float(unc3*unc3_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "\n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='xtandi')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='xtandi')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='xtandi')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='xtandi')]['sales_RA_90']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# XOSPATA\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'xospata'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    n=500\n",
    "    sales_ra = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get Uncertainty Probability (value)\n",
    "        unc4_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc4')]['probability'], 1, 1)\n",
    "        unc5_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc5')]['probability'], 1, 1)\n",
    "        unc6_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc6')]['probability'], 1, 1)\n",
    "        \n",
    "        # Get Base Uncertainty\n",
    "        unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "        unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "        \n",
    "        # Get relevant sales values for uncertainties\n",
    "        unc4_sales=sum(sales_ptrs[(sales_ptrs['product']==product) & (sales_ptrs['year'] ==year) & sales_ptrs['region'].isin(['US', 'JP', 'DE', 'FR', 'IT', 'ES', 'GB'])]['sales'])\n",
    "        unc5_sales=sum(sales_ptrs[(sales_ptrs['product']==product) & (sales_ptrs['year'] ==year) & sales_ptrs['region'].isin(['US', 'DE', 'FR', 'IT', 'ES', 'GB'])]['sales'])\n",
    "        unc6_sales=sum(sales_ptrs[(sales_ptrs['product']==product) & (sales_ptrs['year'] ==year) & sales_ptrs['region'].isin(['US', 'DE', 'FR', 'IT', 'ES', 'GB'])]['sales'])\n",
    "\n",
    "        # Get Uncertainty Quant by year (series)\n",
    "        unc4=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc4']*unc4_sales\n",
    "        unc5=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc5']*unc5_sales\n",
    "        unc6=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc6']*unc6_sales\n",
    "\n",
    "        # Generate RA sales\n",
    "        sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "        unc_all=float(sales['sales_p1_RA']) + float(sales['sales_p1_RA']*unc_base_prob) + float(unc4*unc4_prob) + float(unc5*unc5_prob) + float(unc6*unc6_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "\n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='xospata')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='xospata')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='xospata')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='xospata')]['sales_RA_90']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# PADCEV\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'padcev'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    n=500\n",
    "    sales_ra = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get Uncertainty Probability (value)\n",
    "        unc7_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc7')]['probability'], 1, 1)\n",
    "        unc8_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc8')]['probability'], 1, 1)\n",
    "        unc9_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc9')]['probability'], 1, 1)\n",
    "        unc10_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc10')]['probability'], 1, 1)\n",
    "        unc11_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc11')]['probability'], 1, 1)\n",
    "        unc12_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc12')]['probability'], 1, 1)\n",
    "        unc13_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc13')]['probability'], 1, 1)\n",
    "        unc14_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc14')]['probability'], 1, 1)\n",
    "        \n",
    "        # Get Base Uncertainty\n",
    "        unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "        unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "        # Get Uncertainty Quant by year (series)\n",
    "        unc7=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc7']\n",
    "        unc8=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc8']\n",
    "        unc9=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc9']\n",
    "        unc10=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc10']\n",
    "        unc11=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc11']\n",
    "        unc12=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc12']\n",
    "        unc13=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc13']\n",
    "        unc14=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc14']\n",
    "\n",
    "        # Generate RA sales\n",
    "        sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "        unc_all=float(sales['sales_p1_RA']) + float(sales['sales_p1_RA']*unc_base_prob) + float(unc7*unc7_prob) + float(unc8*unc8_prob) + float(unc9*unc9_prob) + float(unc10*unc10_prob) + float(unc11*unc11_prob) + float(unc12*unc12_prob) + float(unc13*unc13_prob) + float(unc14*unc14_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "\n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='padcev')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='padcev')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='padcev')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='padcev')]['sales_RA_90']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# EVRENZO\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'evrenzo'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    sales_ra = []\n",
    "    n=500\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get Uncertainty Probability (value)\n",
    "        unc15_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc15')]['probability'], 1, 1)\n",
    "        unc16_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc16')]['probability'], 1, 1)\n",
    "        unc17_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc17')]['probability'], 1, 1)\n",
    "        unc18_prob=np.random.triangular(0, unc_p_desc[(unc_p_desc['uncertainties'] == 'unc18')]['probability'], 1, 1)\n",
    "        \n",
    "        # Get Base Uncertainty\n",
    "        unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "        unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "        # Get Uncertainty Quant by year (series)\n",
    "        unc15=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc15']\n",
    "        unc16=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc16']\n",
    "        unc17=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc17']\n",
    "        unc18=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc18']\n",
    "\n",
    "        # Generate RA sales\n",
    "        sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "        unc_all=float(sales['sales_p1_RA']) + float(sales['sales_p1_RA']*unc_base_prob) + float(unc15*unc15_prob) + float(unc16*unc16_prob) + float(unc17*unc17_prob) + float(unc18*unc18_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "\n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='evrenzo')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='evrenzo')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='evrenzo')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='evrenzo')]['sales_RA_90']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# ZOLBE\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'zolbe'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    n=500\n",
    "    sales_ra = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get Base Uncertainty\n",
    "        unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "        unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "        # Generate RA sales\n",
    "        sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "        unc_all=float(sales['sales_p1_RA']) + float(sales['sales_p1_RA']*unc_base_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "\n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='zolbe')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='zolbe')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='zolbe')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='zolbe')]['sales_RA_90']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# FEZO\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'fezo'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "\n",
    "    fezo_base=sales_ptrs[(sales_ptrs['product']==product) & (sales_ptrs['region']=='US') & (sales_ptrs['year']==year)& (sales_ptrs['indication']=='Total')]['sales_p1_RA']\n",
    "    fezo_10 = float(unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc19'])\n",
    "    fezo_50 = float(unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc20'])\n",
    "    fezo_90 = float(unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc21'])\n",
    "\n",
    "    # Get Product Worldwide sales by year (series) \n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = float(fezo_10/fezo_base)*float(prod_ww_sales['sales_p1_RA'])\n",
    "    prod_ww_sales['sales_RA_50'] = float(fezo_50/fezo_base)*float(prod_ww_sales['sales_p1_RA'])\n",
    "    prod_ww_sales['sales_RA_90'] = float(fezo_90/fezo_base)*float(prod_ww_sales['sales_p1_RA'])\n",
    "    \n",
    "    prod_ww_sales['sales_p2_RA'] = prod_ww_sales['sales_RA_50']\n",
    "\n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='fezo')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='fezo')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='fezo')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='fezo')]['sales_RA_90']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#############\n",
    "# MIRABEGRON\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'mirabegron'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "n=500\n",
    "sales_ra22 = []\n",
    "sales_ra23 = []\n",
    "sales_ra24 = []\n",
    "sales_ra25 = []\n",
    "    \n",
    "for i in range(n):\n",
    "    # Get Base Uncertainty\n",
    "    unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "    unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "    # Get High,Base,Low Uncertainty\n",
    "    unc_hbl_prob=np.random.randint(1,4)\n",
    "    # unc_hbl_prob=1\n",
    "\n",
    "    # Generate RA sales - High\n",
    "    if (unc_hbl_prob==1):\n",
    "        sales22=float(1778.7)*float(1+unc_base_prob)\n",
    "        sales23=float(1769.2)*float(1+unc_base_prob)\n",
    "        sales24=float(1741.45)*float(1+unc_base_prob)\n",
    "        sales25=float(1726.98)*float(1+unc_base_prob)\n",
    "\n",
    "    # Generate RA sales - Med\n",
    "    if (unc_hbl_prob==2):\n",
    "        sales22=float(1778.7)*float(1+unc_base_prob)\n",
    "        sales23=float(1768.97)*float(1+unc_base_prob)\n",
    "        sales24=float(1741.21)*float(1+unc_base_prob)\n",
    "        sales25=float(1223.22)*float(1+unc_base_prob)\n",
    "        \n",
    "    # Generate RA sales - Low\n",
    "    if (unc_hbl_prob==3):\n",
    "        sales22=float(1778.7)*float(1+unc_base_prob)\n",
    "        sales23=float(1763.69)*float(1+unc_base_prob)\n",
    "        sales24=float(965.55)*float(1+unc_base_prob)\n",
    "        sales25=float(742.85)*float(1+unc_base_prob)\n",
    "        \n",
    "    sales_ra22.append(sales22)\n",
    "    sales_ra23.append(sales23)\n",
    "    sales_ra24.append(sales24)\n",
    "    sales_ra25.append(sales25)\n",
    " \n",
    " # Get Product Worldwide sales by year (series)\n",
    "prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==2022) ]\n",
    "prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra22, 10)\n",
    "prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra22, 50)\n",
    "prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra22, 90)\n",
    "prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra22)\n",
    "\n",
    "# Append to sales df\n",
    "output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "# Get Product Worldwide sales by year (series)\n",
    "prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==2023) ]\n",
    "prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra23, 10)\n",
    "prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra23, 50)\n",
    "prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra23, 90)\n",
    "prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra23)\n",
    "\n",
    "# Append to sales df\n",
    "output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "# Get Product Worldwide sales by year (series)\n",
    "prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==2024) ]\n",
    "prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra24, 10)\n",
    "prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra24, 50)\n",
    "prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra24, 90)\n",
    "prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra24)\n",
    "\n",
    "# Append to sales df\n",
    "output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "# Get Product Worldwide sales by year (series)\n",
    "prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==2025) ]\n",
    "prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra25, 10)\n",
    "prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra25, 50)\n",
    "prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra25, 90)\n",
    "prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra25)\n",
    "\n",
    "# Append to sales df\n",
    "output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='mirabegron')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='mirabegron')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='mirabegron')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='mirabegron')]['sales_RA_90']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# TACROLIMUS\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'tacrolimus'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    n=500\n",
    "    sales_ra = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get Base Uncertainty\n",
    "        unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "        unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "        # Generate RA sales\n",
    "        sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "        unc_all=float(sales['sales_p1_RA']) + float(sales['sales_p1_RA']*unc_base_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "\n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='tacrolimus')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='tacrolimus')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='tacrolimus')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='tacrolimus')]['sales_RA_90']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# LEXISCAN\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'lexiscan'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    n=500\n",
    "    sales_ra = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get Base Uncertainty\n",
    "        unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "        unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "        # Generate RA sales\n",
    "        sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "        unc_all=float(sales['sales_p1_RA']) + float(sales['sales_p1_RA']*unc_base_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "\n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='lexiscan')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='lexiscan')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='lexiscan')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='lexiscan')]['sales_RA_90']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# OTHERS\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025]\n",
    "product = 'others'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_df2=output_df2[(output_df2['product']!=product)]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    n=500\n",
    "    sales_ra = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Get Base Uncertainty\n",
    "        unc_base=unc_p[(unc_p['product'] ==product) & (unc_p['year'] ==year)]['unc_base']\n",
    "        unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "        # Generate RA sales\n",
    "        sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "        unc_all=float(sales['sales_p1_RA']) + float(sales['sales_p1_RA']*unc_base_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "\n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales=sales_p2[(sales_p2['product'] ==product) & (sales_p2['region']=='Total') & (sales_p2['year']==year) ]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_p2_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_df2 = output_df2.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "output_df2=output_df2.fillna(0)\n",
    "output_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_df2[(output_df2['product'] =='others')]['sales']))\n",
    "print(sum(output_df2[(output_df2['product'] =='others')]['sales_RA_10']))\n",
    "print(sum(output_df2[(output_df2['product'] =='others')]['sales_RA_50']))\n",
    "print(sum(output_df2[(output_df2['product'] =='others')]['sales_RA_90']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output\n",
    "output_df2.to_csv(r\"C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\Synchronization CSP & AP\\output\\output_phase2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis\n",
    "strategic_products = ['xtandi', 'xospata', 'padcev', 'evrenzo', 'fezo', 'zolbe']\n",
    "\n",
    "print('\\n')\n",
    "print('Sales 10th')\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='xtandi')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='xospata')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='padcev')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='evrenzo')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='fezo')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='zolbe')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product'].isin(strategic_products))]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='mirabegron')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='tacrolimus')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='lexiscan')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='others')]['sales_RA_10'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025)]['sales_RA_10'])))\n",
    "\n",
    "print('\\n')\n",
    "print('Sales 50th')\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='xtandi')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='xospata')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='padcev')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='evrenzo')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='fezo')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='zolbe')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product'].isin(strategic_products))]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='mirabegron')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='tacrolimus')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='lexiscan')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='others')]['sales_RA_50'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025)]['sales_RA_50'])))\n",
    "\n",
    "print('\\n')\n",
    "print('Sales 90th')\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='xtandi')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='xospata')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='padcev')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='evrenzo')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='fezo')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='zolbe')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product'].isin(strategic_products))]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='mirabegron')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='tacrolimus')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='lexiscan')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='others')]['sales_RA_90'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025)]['sales_RA_90'])))\n",
    "\n",
    "print('\\n')\n",
    "print('Sales')\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='xtandi')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='xospata')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='padcev')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='evrenzo')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='fezo')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='zolbe')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product'].isin(strategic_products))]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='mirabegron')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='tacrolimus')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='lexiscan')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025) & (output_df2['product']=='others')]['sales'])))\n",
    "print(round(sum(output_df2[(output_df2['year'] ==2025)]['sales'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
