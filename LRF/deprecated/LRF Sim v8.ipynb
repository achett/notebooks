{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18176.63205186673\n",
      "6963.730575326161\n",
      "1223.22\n",
      "2300\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "######################\n",
    "# METADATA\n",
    "######################\n",
    "sim_start = datetime.now()\n",
    "sims=3\n",
    "input_folder = r'C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\PS22\\inputs'\n",
    "output_folder = r'C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\LRF\\PS22\\outputs\\dev'\n",
    "\n",
    "######################\n",
    "# READ IN DATA\n",
    "######################\n",
    "input_file = 'inputs_v2.xlsx'\n",
    "path = os.path.join(input_folder, input_file)\n",
    "\n",
    "sales_ci=pd.read_excel(path, sheet_name='sales', engine='openpyxl')\n",
    "unc_pr=pd.read_excel(path, sheet_name='unc_pr', engine='openpyxl')\n",
    "unc_pr_desc=pd.read_excel(path, sheet_name='unc_pr_desc', engine='openpyxl')\n",
    "unc_pri=pd.read_excel(path, sheet_name='unc_pri', engine='openpyxl')\n",
    "unc_pri_desc=pd.read_excel(path, sheet_name='unc_pri_desc', engine='openpyxl')\n",
    "\n",
    "######################\n",
    "# PREP BASELINE DATA\n",
    "######################\n",
    "sales_ci=sales_ci.drop_duplicates()\n",
    "sales_ci=sales_ci.melt(id_vars=['product', 'region', 'units', 'indication'], \n",
    "        var_name=\"year\", \n",
    "        value_name=\"sales\")\n",
    "sales_ci=sales_ci[(sales_ci['units'] =='Â¥')]\n",
    "\n",
    "# Exclude indications that are not needed\n",
    "exclude_ind = ['Adjustments', 'Central Adjustments', 'Total', '0', 'mPC 1L']\n",
    "sales_ci=sales_ci[(~sales_ci['indication'].isin(exclude_ind))]\n",
    "\n",
    "# Partition WW sales into 9 segments -> US, JP, CN, DE, FR, ES, IT, GB, WWex8\n",
    "sales_ci_WW=sales_ci[(sales_ci['region']=='WW')]\n",
    "ast8 = ['US','JP','CN', 'DE','FR','ES','IT','GB']\n",
    "sales_ci_ast8=sales_ci[(sales_ci['region'].isin(ast8))]\n",
    "\n",
    "sales_ci_WWex8=sales_ci_ast8.groupby(['product','units','indication','year']).sum().reset_index()\n",
    "sales_ci_WWex8=sales_ci_WW.merge(sales_ci_WWex8, how='right', on=['product', 'units', 'indication', 'year'])\n",
    "sales_ci_WWex8['sales']=sales_ci_WWex8['sales_x']-sales_ci_WWex8['sales_y']\n",
    "sales_ci_WWex8['region']='WWex8'\n",
    "sales_ci_WWex8 = sales_ci_WWex8[['product','region', 'units', 'indication', 'year', 'sales']]\n",
    "\n",
    "# Generate new sales table\n",
    "sales_ci_clean=pd.concat([sales_ci_ast8, sales_ci_WWex8])\n",
    "\n",
    "# Add back non-strategic products\n",
    "sales_ci_nsp=sales_ci[(sales_ci['indication']=='Non-Strategic')]\n",
    "sales_ci_clean=pd.concat([sales_ci_clean, sales_ci_nsp])\n",
    "\n",
    "# Create tag\n",
    "sales_ci_clean['tag'] = sales_ci_clean['product'] + sales_ci_clean['region'] + sales_ci_clean['units'] + sales_ci_clean['indication'].astype(str)+ sales_ci_clean['year'].astype(str)\n",
    "\n",
    "# Validation\n",
    "print(sum(sales_ci_clean[(sales_ci_clean['year']==2025)]['sales']))  #18393\n",
    "print(sum(sales_ci_clean[(sales_ci_clean['product']=='xtandi') & (sales_ci_clean['year']==2025)]['sales']))  #6963\n",
    "print(sum(sales_ci_clean[(sales_ci_clean['product']=='mirabegron') & (sales_ci_clean['year']==2025)]['sales']))  #1223\n",
    "print(sales_ci_clean['tag'].nunique()) # 2390\n",
    "\n",
    "# Remove interim dfs from memory\n",
    "del sales_ci_WW\n",
    "del sales_ci_ast8\n",
    "del sales_ci_WWex8\n",
    "del sales_ci_nsp\n",
    "del sales_ci\n",
    "\n",
    "# Save new sales data\n",
    "output_file = 'sales_clean.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "sales_ci_clean.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable         Type         Data/Info\n",
      "---------------------------------------\n",
      "output_p1        DataFrame                          pro<...>\\n[4550 rows x 8 columns]\n",
      "output_p2        DataFrame          tag product region <...>n[9580 rows x 15 columns]\n",
      "output_unc_p2    DataFrame         product units indica<...>\\n[360 rows x 28 columns]\n",
      "sales_ci_clean   DataFrame                          pro<...>\\n[2310 rows x 7 columns]\n",
      "sales_exp1       DataFrame                             <...>\\n[1130 rows x 7 columns]\n",
      "scenarios_exp1   DataFrame          scenario           <...>\\n[3390 rows x 9 columns]\n",
      "scenarios_p1     DataFrame                          pro<...>n[10320 rows x 9 columns]\n",
      "scenarios_p2     DataFrame         scenario_p1  scenari<...>n[8631 rows x 11 columns]\n",
      "scenarios_p2a    DataFrame         product units region<...>\\n[1130 rows x 9 columns]\n",
      "scenarios_p2b    DataFrame       scenario_p1  scenario_<...>      0.0           0.0  \n",
      "unc_pr           DataFrame         product region  year<...>n[1210 rows x 34 columns]\n",
      "unc_pr_desc      DataFrame       uncertainties         <...>        CN         0.50  \n",
      "unc_pri          DataFrame         product region units<...>n[1170 rows x 24 columns]\n",
      "unc_pri_desc     DataFrame      uncertainties          <...>aint.  \\n2  HSCT-Maint.  \n"
     ]
    }
   ],
   "source": [
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Phase 1: PTRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18176.63205186673\n",
      "6963.730575326161\n",
      "6963.730575326161\n",
      "1223.22\n",
      "2300\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# CREATE OUTPUT DFS FOR PHASE 1\n",
    "#############\n",
    "output_p1 = pd.DataFrame(columns=['tag','product', 'region', 'units', 'indication', 'year', 'sales', 'sales_RA_10', 'sales_RA_25', 'sales_RA_50', 'sales_RA_75', 'sales_RA_90']) # Output of Phase 1\n",
    "scenarios_p1 = pd.DataFrame(columns=['scenario', 'tag', 'product', 'region', 'units', 'indication', 'year', 'sales', 'sim_sales']) # Scenarios of Phase 1\n",
    "\n",
    "#############\n",
    "# GENERATE SCENARIOS FOR TAGS IN P1\n",
    "#############\n",
    "# Add PTRS values to sales data\n",
    "sales_ci_unc = sales_ci_clean.merge(unc_pri, how='right', on=['product','region', 'units', 'indication', 'year'])\n",
    "\n",
    "scenario_sdf=[]\n",
    "product_sdf=[]\n",
    "region_sdf=[]\n",
    "units_sdf=[]\n",
    "ind_sdf=[]\n",
    "year_sdf=[]\n",
    "sales_sdf=[]\n",
    "tag_sdf=[]\n",
    "sim_sales_sdf=[]\n",
    "    \n",
    "# Loop through rows\n",
    "for index, row in sales_ci_unc.iterrows():\n",
    "# for index, row in sales_ci_unc.iloc[29:30].iterrows():\n",
    "    n=sims\n",
    "    sales_ra = []\n",
    "    unc_ptrs_ra = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        scenario_sdf.append((i+1))\n",
    "        product_sdf.append(row.values[0])\n",
    "        region_sdf.append(row.values[1])\n",
    "        units_sdf.append(row.values[2])\n",
    "        ind_sdf.append(row.values[3])\n",
    "        year_sdf.append(row.values[4])\n",
    "        sales_sdf.append(row.values[5])\n",
    "        tag_sdf.append(row.values[6])\n",
    "\n",
    "        # Get sales (value)\n",
    "        sales = row.values[5]\n",
    "\n",
    "        # Get PTRS Uncertainty Probability (value)\n",
    "        unc_ptrs_prob=np.random.binomial(size=1, n=1, p=row.values[7])\n",
    "        \n",
    "        # Get Uncertainty Value (value) for others\n",
    "        unc1=row.values[8]\n",
    "        unc2=row.values[9]\n",
    "        \n",
    "        if ((unc_ptrs_prob == 1) and ((~np.isnan(unc1)) or (~np.isnan(unc2)) )):\n",
    "            m=sims\n",
    "            for j in range(m):\n",
    "\n",
    "                # Get Uncertainty Probability (value) for others\n",
    "                unc1_prob=np.random.randint(1,4)\n",
    "                \n",
    "                if ((unc1_prob == 1)):\n",
    "                    sales=unc1\n",
    "                \n",
    "                if ((unc1_prob == 2)):\n",
    "                    sales=unc2\n",
    "                    \n",
    "        \n",
    "        # Generate RA sales\n",
    "        unc_all=float(sales)*float(unc_ptrs_prob)\n",
    "        sales_ra.append(unc_all)\n",
    "        sim_sales_sdf.append(unc_all)\n",
    "        \n",
    "    # Get Product Worldwide sales by year (series)\n",
    "    prod_ww_sales = sales_ci_unc.iloc[index]\n",
    "    prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "    prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "    prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "    prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "    prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "    prod_ww_sales['sales_P1_RA'] = np.mean(sales_ra)\n",
    "    \n",
    "    # Append to sales df\n",
    "    output_p1 = output_p1.append(prod_ww_sales, ignore_index=True)\n",
    "    \n",
    "    # Develop scenario_df\n",
    "    scenarios_p1= pd.DataFrame({'scenario': scenario_sdf,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales': sim_sales_sdf})\n",
    "    \n",
    "    \n",
    "#############\n",
    "# GENERATE SCENARIOS FOR TAGS NOT IN P1\n",
    "#############\n",
    "# Create df of tags without ptrs uncertainty\n",
    "sales_exp1=sales_ci_clean[~(sales_ci_clean['tag'].isin(sales_ci_unc['tag']))]\n",
    "sales_exp1 = sales_exp1[['tag', 'product', 'region', 'units', 'indication', 'year', 'sales']]\n",
    "\n",
    "scenario_sdf=[]\n",
    "product_sdf=[]\n",
    "region_sdf=[]\n",
    "units_sdf=[]\n",
    "ind_sdf=[]\n",
    "year_sdf=[]\n",
    "sales_sdf=[]\n",
    "tag_sdf=[]\n",
    "sim_sales_sdf=[]\n",
    "    \n",
    "# Loop through rows\n",
    "for index, row in sales_exp1.iterrows():\n",
    "    n=sims\n",
    "    \n",
    "    for i in range(n):\n",
    "        scenario_sdf.append((i+1))\n",
    "        tag_sdf.append(row.values[0])\n",
    "        product_sdf.append(row.values[1])\n",
    "        region_sdf.append(row.values[2])\n",
    "        units_sdf.append(row.values[3])\n",
    "        ind_sdf.append(row.values[4])\n",
    "        year_sdf.append(row.values[5])\n",
    "        sales_sdf.append(row.values[6])\n",
    "        sim_sales_sdf.append(row.values[6])\n",
    "        \n",
    "            \n",
    "    # Develop scenario_df\n",
    "    scenarios_exp1= pd.DataFrame({'scenario': scenario_sdf,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales': sim_sales_sdf})\n",
    "\n",
    "# Save outputs\n",
    "output_p1 = output_p1[['tag','product','region', 'units', 'indication', 'year', 'sales', 'sales_RA_10', 'sales_RA_25', 'sales_RA_50','sales_RA_75', 'sales_RA_90', 'sales_P1_RA']]\n",
    "\n",
    "# Add non-simulated tags to output df\n",
    "sales_exP1=sales_ci_clean[~(sales_ci_clean['tag'].isin(output_p1['tag']))]\n",
    "sales_exP1['sales_RA_10']=sales_exP1['sales']\n",
    "sales_exP1['sales_RA_25']=sales_exP1['sales']\n",
    "sales_exP1['sales_RA_50']=sales_exP1['sales']\n",
    "sales_exP1['sales_RA_75']=sales_exP1['sales']\n",
    "sales_exP1['sales_RA_90']=sales_exP1['sales']\n",
    "sales_exP1['sales_P1_RA']=sales_exP1['sales']\n",
    "output_p1=pd.concat([output_p1, sales_exP1])\n",
    "\n",
    "# Add non-simulated tags to scenario df\n",
    "scenarios_p1=pd.concat([scenarios_p1, scenarios_exp1])\n",
    "\n",
    "# Validation\n",
    "print(sum(output_p1[(output_p1['year']==2025)]['sales']))  #18393\n",
    "print(sum(output_p1[(output_p1['product']=='xtandi') & (output_p1['year']==2025)]['sales'])) #6963\n",
    "print(sum(scenarios_p1[(scenarios_p1['product']=='xtandi') & (scenarios_p1['year']==2025) & (scenarios_p1['indication']!='Total') & (scenarios_p1['scenario']==1)]['sales']))  #6963\n",
    "print(sum(output_p1[(output_p1['product']=='mirabegron') & (output_p1['year']==2025)]['sales']))  #1223\n",
    "print(output_p1['tag'].nunique()) # 2300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep Results for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18176.63205186673\n",
      "6963.730575326161\n",
      "1223.22\n",
      "2300\n"
     ]
    }
   ],
   "source": [
    "# Convert PTRS results to sales df for next phase (Commercial Uncertainty)\n",
    "output_p1=output_p1[['tag','product','region', 'units', 'indication', 'year', 'sales', 'sales_P1_RA']]\n",
    "\n",
    "# Sum sales at the WW level\n",
    "output_p1_ww=output_p1.groupby(['product','units','indication','year']).sum().reset_index()\n",
    "output_p1_ww['region']='Total'\n",
    "output_p1=pd.concat([output_p1_ww, output_p1])\n",
    "\n",
    "# Sum sales and scenarios at the Product level, as commercial uncertainty is applied at a higher granularity\n",
    "output_p1_prod=output_p1.groupby(['product','units','region','year']).sum().reset_index()\n",
    "output_p1_prod['indication']='Total'\n",
    "output_p1=pd.concat([output_p1_prod, output_p1])\n",
    "\n",
    "scenarios_p1_prod=scenarios_p1.groupby(['product','units','region','year', 'scenario']).sum().reset_index()\n",
    "scenarios_p1_prod['indication']='Total'\n",
    "scenarios_p1=pd.concat([scenarios_p1_prod, scenarios_p1])\n",
    "\n",
    "# Validation\n",
    "print(sum(output_p1[(output_p1['year']==2025)& (output_p1['region']!='Total') & (output_p1['indication']!='Total')]['sales']))  #18393\n",
    "print(sum(output_p1[(output_p1['product']=='xtandi') & (output_p1['year']==2025) & (output_p1['region']!='Total') & (output_p1['indication']!='Total')]['sales']))  #6963\n",
    "print(sum(output_p1[(output_p1['product']=='mirabegron') & (output_p1['year']==2025) & (output_p1['region']!='Total') & (output_p1['indication']!='Total')]['sales']))  #1223\n",
    "print(output_p1[(output_p1['region']!='Total') & (output_p1['indication']!='Total')]['tag'].nunique()) # 2390\n",
    "\n",
    "# Remove interim dfs from memory\n",
    "del sales_exP1\n",
    "del output_p1_ww\n",
    "del output_p1_prod\n",
    "del scenarios_p1_prod\n",
    "del sales_ci_unc\n",
    "\n",
    "output_file = 'output_p1.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "output_p1.to_csv(path)\n",
    "\n",
    "output_file = 'scenarios_p1.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "scenarios_p1.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Phase 2: Market Events / Commercial Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep for Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18176.632051866727\n",
      "6963.730575326162\n",
      "1223.22\n",
      "18176.632051866723\n",
      "6963.730575326161\n",
      "1223.2200000000003\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# CREATE OUTPUT DFS FOR PHASE 2\n",
    "#############\n",
    "output_p2 = pd.DataFrame(columns=['tag','product', 'region', 'units', 'indication', 'year', 'sales', 'sales_RA_10', 'sales_RA_25','sales_RA_50','sales_RA_75', 'sales_RA_90']) # Outputs of Phase 2\n",
    "scenarios_p2 = pd.DataFrame(columns=['scenario_p1', 'scenario_p2', 'tag', 'product', 'region', 'units', 'indication', 'year', 'sales', 'sim_sales_p1', 'sim_sales_p2']) # Scenarios of Phase 2\n",
    "output_unc_p2 = pd.DataFrame(columns=['tag','product', 'region', 'units', 'indication', 'year', 'sales']) # Uncertainties of Phase 2\n",
    "\n",
    "#############\n",
    "# PREP INPUTS DFS FOR PHASE 2\n",
    "#############\n",
    "# Create input df\n",
    "input_p2a=output_p1[(output_p1['region']=='Total') & (output_p1['indication']=='Total')] # These do not go thru phase2\n",
    "# input_p2b=output_p1[(output_p1['region']!='Total') & (output_p1['indication'].isin(['Total']))] # These go thru phase2\n",
    "\n",
    "# input_p2a=scenarios_p1[(scenarios_p1['region']=='Total') & (scenarios_p1['indication']=='Total')] # These do not go thru phase2\n",
    "input_p2b=scenarios_p1[(scenarios_p1['region']!='Total') & (scenarios_p1['indication'].isin(['Total']))] # These go thru phase2\n",
    "\n",
    "# Validation\n",
    "print(sum(input_p2a[(input_p2a['year']==2025)]['sales']))  #18393\n",
    "print(sum(input_p2a[(input_p2a['product']=='xtandi') & (input_p2a['year']==2025)]['sales']))  #6963\n",
    "print(sum(input_p2a[(input_p2a['product']=='mirabegron') & (input_p2a['year']==2025)]['sales']))  #1223\n",
    "\n",
    "print(sum(input_p2b[(input_p2b['year']==2025) & (input_p2b['scenario']==1)]['sales']))  #18393\n",
    "print(sum(input_p2b[(input_p2b['product']=='xtandi') & (input_p2b['year']==2025) & (input_p2b['scenario']==1)]['sales']))  #6963\n",
    "print(sum(input_p2b[(input_p2b['product']=='mirabegron') & (input_p2b['year']==2025) & (input_p2b['scenario']==1)]['sales']))  #1223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# XTANDI\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB', 'WWex8']\n",
    "product = 'xtandi'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "output_unc_p2=output_unc_p2[(output_unc_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "    for year in years:\n",
    "\n",
    "        for region in regions:\n",
    "            n=sims\n",
    "            scenario_sdf1=[]\n",
    "            scenario_sdf2=[]\n",
    "            product_sdf=[]\n",
    "            region_sdf=[]\n",
    "            units_sdf=[]\n",
    "            ind_sdf=[]\n",
    "            year_sdf=[]\n",
    "            sales_sdf=[]\n",
    "            sim_sales_sdf1=[]\n",
    "            tag_sdf=[]\n",
    "\n",
    "            sales_ra = []\n",
    "            unc1_ra = []\n",
    "            unc2_ra = []\n",
    "            unc3_ra = []\n",
    "            unc26_ra = []\n",
    "\n",
    "            for i in range(n):\n",
    "                # Get Uncertainty Probability (value)\n",
    "                unc1_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc1')]['probability'], 1, 1)\n",
    "                unc2_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc2')]['probability'], 1, 1)\n",
    "                unc3_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc3')]['probability'], 1, 1)\n",
    "                unc26_prob=np.random.binomial(size=1, n=1, p=unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc26')]['probability'])\n",
    "\n",
    "                # Get Base Uncertainty\n",
    "                unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_base']\n",
    "                unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "                \n",
    "                # Get relevant sales values for uncertainties\n",
    "                # unc26_sales=input_p2b[(input_p2b['product']==product) & (input_p2b['year'] ==year) & (input_p2b['region']==region)]\n",
    "                unc26_sales=scenarios_p2a[(scenarios_p2a['product']==product) & (scenarios_p2a['year'] ==year) & (scenarios_p2a['region']==region)]['sales']\n",
    "                \n",
    "                # Get Uncertainty Quant by year (series)\n",
    "                unc1=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc1']\n",
    "                unc2=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc2'])*float(unc26_sales)\n",
    "                unc3=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc3'])*float(unc26_sales)\n",
    "                unc26=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc26'])*float(unc26_sales)\n",
    "\n",
    "                # Generate RA sales\n",
    "                # sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "                sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==year) ]\n",
    "                \n",
    "                unc_all=float(sales['sim_sales']) + float(sales['sim_sales']*unc_base_prob) + float(unc1*unc1_prob) + float(unc2*unc2_prob) + float(unc3*unc3_prob) + float(unc26*unc26_prob)\n",
    "                sales_ra.append(unc_all)\n",
    "\n",
    "                # Generate uncertainty arrays\n",
    "                unc1_ra.append(float(unc1*unc1_prob))\n",
    "                unc2_ra.append(float(unc2*unc2_prob))\n",
    "                unc3_ra.append(float(unc3*unc3_prob))\n",
    "                unc26_ra.append(float(unc26*unc26_prob))\n",
    "\n",
    "                # Create scenario array\n",
    "                if nsim_p1==1: \n",
    "                    nsim_p2=0\n",
    "                else:\n",
    "                    nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "                    \n",
    "                scenario_sdf1.append(nsim_p1)\n",
    "                scenario_sdf2.append(nsim_p2+(i+1))\n",
    "                product_sdf.append(product)\n",
    "                region_sdf.append(region)\n",
    "                units_sdf.append(sales['units'].values[0])\n",
    "                ind_sdf.append(sales['indication'].values[0])\n",
    "                year_sdf.append(year)\n",
    "                sales_sdf.append(float(sales['sales']))\n",
    "                sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "                tag_sdf.append(sales['tag'].values[0])\n",
    "\n",
    "            # Develop interim scenario_df\n",
    "            scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                    'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "            # Append interim scenario_df to final scenario_df\n",
    "            scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "            # Get Product Region sales by year (series)\n",
    "            prod_ww_sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "            prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "            prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "            prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "            prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "            prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra)\n",
    "\n",
    "            # Add uncertainty arrays to output_unc\n",
    "            output_unc=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            output_unc['unc1_ra'] = np.mean(unc1_ra)\n",
    "            output_unc['unc2_ra'] = np.mean(unc2_ra)\n",
    "            output_unc['unc3_ra'] = np.mean(unc3_ra)\n",
    "            output_unc['unc26_ra'] = np.mean(unc26_ra)\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "            output_unc_p2 = output_unc_p2.append(output_unc, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "383903.60159499437\n",
      "357177.0074864362\n",
      "370791.4548815642\n",
      "377202.9553070945\n"
     ]
    }
   ],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='xtandi')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='xtandi')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='xtandi')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='xtandi')]['sales_RA_75']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "3\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# XOSPATA\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB', 'WWex8']\n",
    "product = 'xospata'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "output_unc_p2=output_unc_p2[(output_unc_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "\n",
    "    for year in years:\n",
    "        print(year)\n",
    "\n",
    "        for region in regions:\n",
    "            n=sims\n",
    "            scenario_sdf1=[]\n",
    "            scenario_sdf2=[]\n",
    "            product_sdf=[]\n",
    "            region_sdf=[]\n",
    "            units_sdf=[]\n",
    "            ind_sdf=[]\n",
    "            year_sdf=[]\n",
    "            sales_sdf=[]\n",
    "            sim_sales_sdf1=[]\n",
    "            tag_sdf=[]\n",
    "            \n",
    "            sales_ra = []\n",
    "            unc4_ra = []\n",
    "            unc5_ra = []\n",
    "            unc6_ra = []\n",
    "\n",
    "            for i in range(n):\n",
    "                # Get Uncertainty Probability (value)\n",
    "                unc4_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc4')]['probability'], 1, 1)\n",
    "                unc5_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc5')]['probability'], 1, 1)\n",
    "                unc6_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc6')]['probability'], 1, 1)\n",
    "\n",
    "                # Get Base Uncertainty\n",
    "                unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_base']\n",
    "                unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "                # Get relevant sales values for uncertainties\n",
    "                unc4_sales=scenarios_p2a[(scenarios_p2a['product']==product) & (scenarios_p2a['year'] ==year) & (scenarios_p2a['region']==region)]['sales']\n",
    "                unc5_sales=scenarios_p2a[(scenarios_p2a['product']==product) & (scenarios_p2a['year'] ==year) & (scenarios_p2a['region']==region)]['sales']\n",
    "                unc6_sales=scenarios_p2a[(scenarios_p2a['product']==product) & (scenarios_p2a['year'] ==year) & (scenarios_p2a['region']==region)]['sales']\n",
    "\n",
    "                # Get Uncertainty Quant by year (series)\n",
    "                unc4=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc4'])*float(unc4_sales)\n",
    "                unc5=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc5'])*float(unc5_sales)\n",
    "                unc6=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc6'])*float(unc6_sales)\n",
    "\n",
    "                # Generate RA sales\n",
    "                sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==year) ]\n",
    "                unc_all=float(sales['sim_sales']) + float(sales['sim_sales']*unc_base_prob) + float(unc4*unc4_prob) + float(unc5*unc5_prob) + float(unc6*unc6_prob)\n",
    "                sales_ra.append(unc_all)\n",
    "\n",
    "                # Generate uncertainty arrays\n",
    "                unc4_ra.append(float(unc4*unc4_prob))\n",
    "                unc5_ra.append(float(unc5*unc5_prob))\n",
    "                unc6_ra.append(float(unc6*unc6_prob))\n",
    "                \n",
    "                # Create scenario array\n",
    "                if nsim_p1==1: \n",
    "                    nsim_p2=0\n",
    "                else:\n",
    "                    nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "                    \n",
    "                scenario_sdf1.append(nsim_p1)\n",
    "                scenario_sdf2.append(nsim_p2+(i+1))\n",
    "                product_sdf.append(product)\n",
    "                region_sdf.append(region)\n",
    "                units_sdf.append(sales['units'].values[0])\n",
    "                ind_sdf.append(sales['indication'].values[0])\n",
    "                year_sdf.append(year)\n",
    "                sales_sdf.append(float(sales['sales']))\n",
    "                sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "                tag_sdf.append(sales['tag'].values[0])\n",
    "                \n",
    "            # Develop interim scenario_df\n",
    "            scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                    'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "            # Append interim scenario_df to final scenario_df\n",
    "            scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "            # Get Product Region sales by year (series)\n",
    "            prod_ww_sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "            prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "            prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "            prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "            prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "            prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra)\n",
    "\n",
    "            # Add uncertainty arrays to output_unc\n",
    "            output_unc=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            output_unc['unc4_ra'] = np.mean(unc4_ra)\n",
    "            output_unc['unc5_ra'] = np.mean(unc5_ra)\n",
    "            output_unc['unc6_ra'] = np.mean(unc6_ra)\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "            output_unc_p2 = output_unc_p2.append(output_unc, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6547.066058707576\n",
      "6473.010083769217\n",
      "6588.332482122582\n",
      "6690.289813605658\n"
     ]
    }
   ],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='xospata') & (output_p2['year'] ==2025) & (output_p2['region']!='ALL')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='xospata') & (output_p2['year'] ==2025) & (output_p2['region']!='ALL')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='xospata') & (output_p2['year'] ==2025) & (output_p2['region']!='ALL')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='xospata') & (output_p2['year'] ==2025) & (output_p2['region']!='ALL')]['sales_RA_75']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "3\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# PADCEV\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB', 'WWex8']\n",
    "product = 'padcev'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "output_unc_p2=output_unc_p2[(output_unc_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "\n",
    "    for year in years:\n",
    "        print(year)\n",
    "\n",
    "        for region in regions:\n",
    "            n=sims\n",
    "            scenario_sdf1=[]\n",
    "            scenario_sdf2=[]\n",
    "            product_sdf=[]\n",
    "            region_sdf=[]\n",
    "            units_sdf=[]\n",
    "            ind_sdf=[]\n",
    "            year_sdf=[]\n",
    "            sales_sdf=[]\n",
    "            sim_sales_sdf1=[]\n",
    "            tag_sdf=[]\n",
    "            \n",
    "            sales_ra = []\n",
    "            unc7_ra = []\n",
    "            unc8_ra = []\n",
    "            unc9_ra = []\n",
    "            unc10_ra = []\n",
    "            unc11_ra = []\n",
    "            unc12_ra = []\n",
    "            unc13_ra = []\n",
    "            unc14_ra = []\n",
    "\n",
    "            for i in range(n):\n",
    "                # Get Uncertainty Probability (value)\n",
    "                unc7_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc7')]['probability'], 1, 1)\n",
    "                unc8_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc8')]['probability'], 1, 1)\n",
    "                unc9_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc9')]['probability'], 1, 1)\n",
    "                unc10_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc10')]['probability'], 1, 1)\n",
    "                unc11_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc11')]['probability'], 1, 1)\n",
    "                unc12_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc12')]['probability'], 1, 1)\n",
    "                unc13_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc13')]['probability'], 1, 1)\n",
    "                unc14_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc14')]['probability'], 1, 1)\n",
    "\n",
    "                # Get Base Uncertainty\n",
    "                unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_base']\n",
    "                unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "                # Get Uncertainty Quant by year (series)\n",
    "                unc7=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc7']\n",
    "                unc8=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc8']\n",
    "                unc9=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc9']\n",
    "                unc10=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc10']\n",
    "                unc11=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc11']\n",
    "                unc12=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc12']\n",
    "                unc13=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc13']\n",
    "                unc14=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc14']\n",
    "\n",
    "                # Generate RA sales\n",
    "                sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==year) ]\n",
    "                unc_all=float(sales['sim_sales']) + float(sales['sim_sales']*unc_base_prob) + float(unc7*unc7_prob) + float(unc8*unc8_prob) + float(unc9*unc9_prob) + float(unc10*unc10_prob) + float(unc11*unc11_prob) + float(unc12*unc12_prob) + float(unc13*unc13_prob) + float(unc14*unc14_prob)\n",
    "                sales_ra.append(unc_all)\n",
    "\n",
    "                # Generate uncertainty arrays\n",
    "                unc7_ra.append(float(unc7*unc7_prob))\n",
    "                unc8_ra.append(float(unc8*unc8_prob))\n",
    "                unc9_ra.append(float(unc9*unc9_prob))\n",
    "                unc10_ra.append(float(unc10*unc10_prob))\n",
    "                unc11_ra.append(float(unc11*unc11_prob))\n",
    "                unc12_ra.append(float(unc12*unc12_prob))\n",
    "                unc13_ra.append(float(unc13*unc13_prob))\n",
    "                unc14_ra.append(float(unc14*unc14_prob))\n",
    "                \n",
    "                # Create scenario array\n",
    "                if nsim_p1==1: \n",
    "                    nsim_p2=0\n",
    "                else:\n",
    "                    nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "                    \n",
    "                scenario_sdf1.append(nsim_p1)\n",
    "                scenario_sdf2.append(nsim_p2+(i+1))\n",
    "                product_sdf.append(product)\n",
    "                region_sdf.append(region)\n",
    "                units_sdf.append(sales['units'].values[0])\n",
    "                ind_sdf.append(sales['indication'].values[0])\n",
    "                year_sdf.append(year)\n",
    "                sales_sdf.append(float(sales['sales']))\n",
    "                sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "                tag_sdf.append(sales['tag'].values[0])\n",
    "\n",
    "            # Develop interim scenario_df\n",
    "            scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                    'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "            # Append interim scenario_df to final scenario_df\n",
    "            scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "            prod_ww_sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "            prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "            prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "            prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "            prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "            prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra)\n",
    "\n",
    "            # Add uncertainty arrays to output_unc\n",
    "            output_unc=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            output_unc['unc7_ra'] = np.mean(unc7_ra)\n",
    "            output_unc['unc8_ra'] = np.mean(unc8_ra)\n",
    "            output_unc['unc9_ra'] = np.mean(unc9_ra)\n",
    "            output_unc['unc10_ra'] = np.mean(unc10_ra)\n",
    "            output_unc['unc11_ra'] = np.mean(unc11_ra)\n",
    "            output_unc['unc12_ra'] = np.mean(unc12_ra)\n",
    "            output_unc['unc13_ra'] = np.mean(unc13_ra)\n",
    "            output_unc['unc14_ra'] = np.mean(unc14_ra)\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "            output_unc_p2 = output_unc_p2.append(output_unc, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='padcev')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='padcev')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='padcev')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='padcev')]['sales_RA_75']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "3\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# EVRENZO\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB', 'WWex8']\n",
    "product = 'evrenzo'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "output_unc_p2=output_unc_p2[(output_unc_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "\n",
    "    for year in years:\n",
    "        print(year)\n",
    "\n",
    "        for region in regions:\n",
    "            n=sims\n",
    "            scenario_sdf1=[]\n",
    "            scenario_sdf2=[]\n",
    "            product_sdf=[]\n",
    "            region_sdf=[]\n",
    "            units_sdf=[]\n",
    "            ind_sdf=[]\n",
    "            year_sdf=[]\n",
    "            sales_sdf=[]\n",
    "            sim_sales_sdf1=[]\n",
    "            tag_sdf=[]\n",
    "            \n",
    "            sales_ra = []\n",
    "            unc15_ra = []\n",
    "            unc16_ra = []\n",
    "            unc17_ra = []\n",
    "            unc18_ra = []\n",
    "\n",
    "            for i in range(n):\n",
    "                # Get Uncertainty Probability (value)\n",
    "                unc15_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc15')]['probability'], 1, 1)\n",
    "                unc16_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc16')]['probability'], 1, 1)\n",
    "                unc17_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc17')]['probability'], 1, 1)\n",
    "                unc18_prob=np.random.triangular(0, unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc18')]['probability'], 1, 1)\n",
    "\n",
    "                # Get Base Uncertainty\n",
    "                unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_base']\n",
    "                unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "                # Get Uncertainty Quant by year (series)\n",
    "                unc15=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc15']\n",
    "                unc16=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc16']\n",
    "                unc17=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc17']\n",
    "                unc18=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc18']\n",
    "\n",
    "                # Generate RA sales\n",
    "                sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==year) ]\n",
    "                unc_all=float(sales['sim_sales']) + float(sales['sim_sales']*unc_base_prob) + float(unc15*unc15_prob) + float(unc16*unc16_prob) + float(unc17*unc17_prob) + float(unc18*unc18_prob)\n",
    "                sales_ra.append(unc_all)\n",
    "\n",
    "                # Generate uncertainty arrays\n",
    "                unc15_ra.append(float(unc15*unc15_prob))\n",
    "                unc16_ra.append(float(unc16*unc16_prob))\n",
    "                unc17_ra.append(float(unc17*unc17_prob))\n",
    "                unc18_ra.append(float(unc18*unc18_prob))\n",
    "                \n",
    "                # Create scenario array\n",
    "                if nsim_p1==1: \n",
    "                    nsim_p2=0\n",
    "                else:\n",
    "                    nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "                    \n",
    "                scenario_sdf1.append(nsim_p1)\n",
    "                scenario_sdf2.append(nsim_p2+(i+1))\n",
    "                product_sdf.append(product)\n",
    "                region_sdf.append(region)\n",
    "                units_sdf.append(sales['units'].values[0])\n",
    "                ind_sdf.append(sales['indication'].values[0])\n",
    "                year_sdf.append(year)\n",
    "                sales_sdf.append(float(sales['sales']))\n",
    "                sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "                tag_sdf.append(sales['tag'].values[0])\n",
    "\n",
    "            # Develop interim scenario_df\n",
    "            scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                    'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "            # Append interim scenario_df to final scenario_df\n",
    "            scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "            prod_ww_sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "            prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "            prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "            prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "            prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "            prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra)\n",
    "\n",
    "            # Add uncertainty arrays to output_unc\n",
    "            output_unc=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            output_unc['unc15_ra'] = np.mean(unc15_ra)\n",
    "            output_unc['unc16_ra'] = np.mean(unc16_ra)\n",
    "            output_unc['unc17_ra'] = np.mean(unc17_ra)\n",
    "            output_unc['unc18_ra'] = np.mean(unc18_ra)\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "            output_unc_p2 = output_unc_p2.append(output_unc, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40061.382759439744\n",
      "38288.10901317918\n",
      "39744.72898782903\n",
      "41367.87381850048\n"
     ]
    }
   ],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='evrenzo')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='evrenzo')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='evrenzo')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='evrenzo')]['sales_RA_75']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "3\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# ZOLBE\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB', 'WWex8']\n",
    "product = 'zolbe'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "output_unc_p2=output_unc_p2[(output_unc_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "\n",
    "    for year in years:\n",
    "        print(year)\n",
    "\n",
    "        for region in regions:\n",
    "            n=sims\n",
    "            scenario_sdf1=[]\n",
    "            scenario_sdf2=[]\n",
    "            product_sdf=[]\n",
    "            region_sdf=[]\n",
    "            units_sdf=[]\n",
    "            ind_sdf=[]\n",
    "            year_sdf=[]\n",
    "            sales_sdf=[]\n",
    "            sim_sales_sdf1=[]\n",
    "            tag_sdf=[]\n",
    "            \n",
    "            sales_ra = []\n",
    "\n",
    "            for i in range(n):\n",
    "                # Get Base Uncertainty\n",
    "                unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_base']\n",
    "                unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "                # Generate RA sales\n",
    "                sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==year) ]\n",
    "                unc_all=float(sales['sim_sales']) + float(sales['sim_sales']*unc_base_prob)\n",
    "                sales_ra.append(unc_all)\n",
    "                \n",
    "                # Create scenario array\n",
    "                if nsim_p1==1: \n",
    "                    nsim_p2=0\n",
    "                else:\n",
    "                    nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "                    \n",
    "                scenario_sdf1.append(nsim_p1)\n",
    "                scenario_sdf2.append(nsim_p2+(i+1))\n",
    "                product_sdf.append(product)\n",
    "                region_sdf.append(region)\n",
    "                units_sdf.append(sales['units'].values[0])\n",
    "                ind_sdf.append(sales['indication'].values[0])\n",
    "                year_sdf.append(year)\n",
    "                sales_sdf.append(float(sales['sales']))\n",
    "                sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "                tag_sdf.append(sales['tag'].values[0])\n",
    "\n",
    "            # Develop interim scenario_df\n",
    "            scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                    'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "            # Append interim scenario_df to final scenario_df\n",
    "            scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "            prod_ww_sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "            prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "            prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "            prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "            prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "            prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra)\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45416.447317750295\n",
      "40023.23947535404\n",
      "41674.14852216146\n",
      "43182.705413401185\n"
     ]
    }
   ],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='zolbe')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='zolbe')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='zolbe')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='zolbe')]['sales_RA_75']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'trash.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "scenarios_p2.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2022\n",
      "870    0.0\n",
      "Name: sim_sales, dtype: float64\n",
      "2023\n",
      "873    718.292302\n",
      "Name: sim_sales, dtype: float64\n",
      "2024\n",
      "876    1941.483198\n",
      "Name: sim_sales, dtype: float64\n",
      "2025\n",
      "879    2537.400264\n",
      "Name: sim_sales, dtype: float64\n",
      "2026\n",
      "882    2597.745765\n",
      "Name: sim_sales, dtype: float64\n",
      "2027\n",
      "885    2858.062566\n",
      "Name: sim_sales, dtype: float64\n",
      "2028\n",
      "888    2949.399033\n",
      "Name: sim_sales, dtype: float64\n",
      "2029\n",
      "891    2986.437575\n",
      "Name: sim_sales, dtype: float64\n",
      "2030\n",
      "894    3031.188746\n",
      "Name: sim_sales, dtype: float64\n",
      "2031\n",
      "897    3082.893351\n",
      "Name: sim_sales, dtype: float64\n",
      "2\n",
      "2022\n",
      "871    0.0\n",
      "Name: sim_sales, dtype: float64\n",
      "2023\n",
      "874    718.292302\n",
      "Name: sim_sales, dtype: float64\n",
      "2024\n",
      "877    1941.483198\n",
      "Name: sim_sales, dtype: float64\n",
      "2025\n",
      "880    2537.400264\n",
      "Name: sim_sales, dtype: float64\n",
      "2026\n",
      "883    2597.745765\n",
      "Name: sim_sales, dtype: float64\n",
      "2027\n",
      "886    2858.062566\n",
      "Name: sim_sales, dtype: float64\n",
      "2028\n",
      "889    2949.399033\n",
      "Name: sim_sales, dtype: float64\n",
      "2029\n",
      "892    2986.437575\n",
      "Name: sim_sales, dtype: float64\n",
      "2030\n",
      "895    3031.188746\n",
      "Name: sim_sales, dtype: float64\n",
      "2031\n",
      "898    3082.893351\n",
      "Name: sim_sales, dtype: float64\n",
      "3\n",
      "2022\n",
      "872    0.0\n",
      "Name: sim_sales, dtype: float64\n",
      "2023\n",
      "875    718.292302\n",
      "Name: sim_sales, dtype: float64\n",
      "2024\n",
      "878    1941.483198\n",
      "Name: sim_sales, dtype: float64\n",
      "2025\n",
      "881    2537.400264\n",
      "Name: sim_sales, dtype: float64\n",
      "2026\n",
      "884    2597.745765\n",
      "Name: sim_sales, dtype: float64\n",
      "2027\n",
      "887    2858.062566\n",
      "Name: sim_sales, dtype: float64\n",
      "2028\n",
      "890    2949.399033\n",
      "Name: sim_sales, dtype: float64\n",
      "2029\n",
      "893    2986.437575\n",
      "Name: sim_sales, dtype: float64\n",
      "2030\n",
      "896    3031.188746\n",
      "Name: sim_sales, dtype: float64\n",
      "2031\n",
      "899    3082.893351\n",
      "Name: sim_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# FEZO\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB', 'WWex8']\n",
    "product = 'fezo'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "output_unc_p2=output_unc_p2[(output_unc_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "\n",
    "    for year in years:\n",
    "        print(year)\n",
    "\n",
    "        # Get Fezo US values, to create proportion\n",
    "        fezo_base=scenarios_p2a[(scenarios_p2a['product']==product) & (scenarios_p2a['region']=='US') & (scenarios_p2a['year']==year)& (scenarios_p2a['indication']=='Total')]['sim_sales']\n",
    "        fezo_10 = float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region']=='US')]['unc19'])\n",
    "        fezo_25 = float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region']=='US')]['unc20'])\n",
    "        fezo_50 = float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region']=='US')]['unc21'])\n",
    "        fezo_75 = float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region']=='US')]['unc22'])\n",
    "        fezo_90 = float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region']=='US')]['unc23'])\n",
    "\n",
    "        for region in regions:\n",
    "            # Get Product Worldwide sales by year (series) \n",
    "            prod_ww_sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==year)]\n",
    "            \n",
    "            prod_ww_sales['sales_RA_10'] = float(fezo_10/fezo_base)*float(prod_ww_sales['sim_sales'])\n",
    "            prod_ww_sales['sales_RA_25'] = float(fezo_25/fezo_base)*float(prod_ww_sales['sim_sales'])\n",
    "            prod_ww_sales['sales_RA_50'] = float(fezo_50/fezo_base)*float(prod_ww_sales['sim_sales'])\n",
    "            prod_ww_sales['sales_RA_75'] = float(fezo_75/fezo_base)*float(prod_ww_sales['sim_sales'])\n",
    "            prod_ww_sales['sales_RA_90'] = float(fezo_90/fezo_base)*float(prod_ww_sales['sim_sales'])\n",
    "\n",
    "            prod_ww_sales['sales_P2_RA'] = prod_ww_sales['sales_RA_50']\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='fezo')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='fezo')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='fezo')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='fezo')]['sales_RA_75']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# MIRABEGRON\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB', 'WWex8']\n",
    "product = 'mirabegron'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "\n",
    "    for region in regions:\n",
    "        n=sims\n",
    "        scenario_sdf1=[]\n",
    "        scenario_sdf2=[]\n",
    "        product_sdf=[]\n",
    "        region_sdf=[]\n",
    "        units_sdf=[]\n",
    "        ind_sdf=[]\n",
    "        year_sdf=[]\n",
    "        sales_sdf=[]\n",
    "        sim_sales_sdf1=[]\n",
    "        tag_sdf=[]\n",
    "            \n",
    "        sales_ra22 = []\n",
    "        sales_ra23 = []\n",
    "        sales_ra24 = []\n",
    "        sales_ra25 = []\n",
    "\n",
    "        for i in range(n):\n",
    "            # Get Base Uncertainty\n",
    "            unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_base']\n",
    "            unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "            # Get High,Base,Low Uncertainty\n",
    "            unc_hbl_prob=np.random.randint(1,4)\n",
    "            # unc_hbl_prob=1\n",
    "\n",
    "            # Generate RA sales - High\n",
    "            if (unc_hbl_prob==1):\n",
    "                sales22=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==2022) & (unc_pr['region'] ==region)]['unc24'])*float(1+unc_base_prob)\n",
    "                sales23=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==2023) & (unc_pr['region'] ==region)]['unc24'])*float(1+unc_base_prob)\n",
    "                sales24=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==2024) & (unc_pr['region'] ==region)]['unc24'])*float(1+unc_base_prob)\n",
    "                sales25=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==2025) & (unc_pr['region'] ==region)]['unc24'])*float(1+unc_base_prob)\n",
    "\n",
    "            # Generate RA sales - Med\n",
    "            if (unc_hbl_prob==2):\n",
    "                sales22=float(scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2022) ]['sales'])*float(1+unc_base_prob)\n",
    "                sales23=float(scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2023) ]['sales'])*float(1+unc_base_prob)\n",
    "                sales24=float(scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2024) ]['sales'])*float(1+unc_base_prob)\n",
    "                sales25=float(scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2025) ]['sales'])*float(1+unc_base_prob)\n",
    "\n",
    "            # Generate RA sales - Low\n",
    "            if (unc_hbl_prob==3):\n",
    "                sales22=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==2022) & (unc_pr['region'] ==region)]['unc25'])*float(1+unc_base_prob)\n",
    "                sales23=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==2023) & (unc_pr['region'] ==region)]['unc25'])*float(1+unc_base_prob)\n",
    "                sales24=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==2024) & (unc_pr['region'] ==region)]['unc25'])*float(1+unc_base_prob)\n",
    "                sales25=float(unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==2025) & (unc_pr['region'] ==region)]['unc25'])*float(1+unc_base_prob)\n",
    "\n",
    "            sales_ra22.append(sales22)\n",
    "            sales_ra23.append(sales23)\n",
    "            sales_ra24.append(sales24)\n",
    "            sales_ra25.append(sales25)\n",
    "            \n",
    "            # Create scenario array\n",
    "            if nsim_p1==1: \n",
    "                nsim_p2=0\n",
    "            else:\n",
    "                nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "\n",
    "            scenario_sdf1.append(nsim_p1)\n",
    "            scenario_sdf2.append(nsim_p2+(i+1))\n",
    "            product_sdf.append(product)\n",
    "            region_sdf.append(region)\n",
    "            units_sdf.append(sales['units'].values[0])\n",
    "            ind_sdf.append(sales['indication'].values[0])\n",
    "            year_sdf.append(year)\n",
    "            sales_sdf.append(float(sales['sales']))\n",
    "            sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "            tag_sdf.append(sales['tag'].values[0])\n",
    "\n",
    "        # Develop interim scenario_df\n",
    "        scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "        # Append interim scenario_df to final scenario_df\n",
    "        scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "\n",
    "         # Get Product, Region sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2022) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra22, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra22, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra22, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra22, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra22, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra22)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "        # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2023) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra23, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra23, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra23, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra23, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra23, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra23)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "        # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2024) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra24, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra24, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra24, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra24, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra24, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra24)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "        # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(input_p2b['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2025) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra25, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra25, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra25, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra25, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra25, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra25)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2026) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra25, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra25, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra25, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra25, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra25, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra25)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2027) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra25, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra25, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra25, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra25, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra25, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra25)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(input_p2b['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2028) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra25, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra25, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra25, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra25, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra25, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra25)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2029) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra25, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra25, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra25, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra25, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra25, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra25)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(input_p2b['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2030) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra25, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra25, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra25, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra25, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra25, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra25)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==2031) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra25, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra25, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra25, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra25, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra25, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra25)\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26414.071553102636\n",
      "32978.164965658405\n",
      "37241.47405023195\n",
      "44764.3823539889\n"
     ]
    }
   ],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='mirabegron')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='mirabegron')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='mirabegron')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='mirabegron')]['sales_RA_75']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "3\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# TACROLIMUS\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB', 'WWex8']\n",
    "product = 'tacrolimus'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "\n",
    "    for year in years:\n",
    "        print(year)\n",
    "\n",
    "        for region in regions:\n",
    "            n=sims\n",
    "            scenario_sdf1=[]\n",
    "            scenario_sdf2=[]\n",
    "            product_sdf=[]\n",
    "            region_sdf=[]\n",
    "            units_sdf=[]\n",
    "            ind_sdf=[]\n",
    "            year_sdf=[]\n",
    "            sales_sdf=[]\n",
    "            sim_sales_sdf1=[]\n",
    "            tag_sdf=[]\n",
    "            \n",
    "            sales_ra = []\n",
    "\n",
    "            for i in range(n):\n",
    "                # Get Base Uncertainty\n",
    "                unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_base']\n",
    "                unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "                # Generate RA sales\n",
    "                sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==year) ]\n",
    "                unc_all=float(sales['sim_sales']) + float(sales['sim_sales']*unc_base_prob)\n",
    "                sales_ra.append(unc_all)\n",
    "                \n",
    "                # Create scenario array\n",
    "                if nsim_p1==1: \n",
    "                    nsim_p2=0\n",
    "                else:\n",
    "                    nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "                    \n",
    "                scenario_sdf1.append(nsim_p1)\n",
    "                scenario_sdf2.append(nsim_p2+(i+1))\n",
    "                product_sdf.append(product)\n",
    "                region_sdf.append(region)\n",
    "                units_sdf.append(sales['units'].values[0])\n",
    "                ind_sdf.append(sales['indication'].values[0])\n",
    "                year_sdf.append(year)\n",
    "                sales_sdf.append(float(sales['sales']))\n",
    "                sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "                tag_sdf.append(sales['tag'].values[0])\n",
    "\n",
    "            # Develop interim scenario_df\n",
    "            scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                    'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "            # Append interim scenario_df to final scenario_df\n",
    "            scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "            prod_ww_sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "            prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "            prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "            prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "            prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "            prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra)\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126916.01209541476\n",
      "125430.20137286757\n",
      "127023.1009150868\n",
      "128672.5087068835\n"
     ]
    }
   ],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='tacrolimus')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='tacrolimus')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='tacrolimus')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='tacrolimus')]['sales_RA_75']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "2\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n",
      "3\n",
      "2022\n",
      "2023\n",
      "2024\n",
      "2025\n",
      "2026\n",
      "2027\n",
      "2028\n",
      "2029\n",
      "2030\n",
      "2031\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# LEXISCAN\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "product = 'lexiscan'\n",
    "\n",
    "# Clear output for rerun\n",
    "output_p2=output_p2[(output_p2['product']!=product)]\n",
    "scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "\n",
    "# Filter scenarios df for scenario\n",
    "for sim in range(sims):\n",
    "    nsim_p1=(sim+1)\n",
    "    scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "    print(nsim_p1)\n",
    "\n",
    "    for year in years:\n",
    "        print(year)\n",
    "        n=sims\n",
    "        scenario_sdf1=[]\n",
    "        scenario_sdf2=[]\n",
    "        product_sdf=[]\n",
    "        region_sdf=[]\n",
    "        units_sdf=[]\n",
    "        ind_sdf=[]\n",
    "        year_sdf=[]\n",
    "        sales_sdf=[]\n",
    "        sim_sales_sdf1=[]\n",
    "        tag_sdf=[]\n",
    "            \n",
    "        sales_ra = []\n",
    "\n",
    "        for i in range(n):\n",
    "            # Get Base Uncertainty\n",
    "            unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year)& (unc_pr['region'] =='US')]['unc_base']\n",
    "            unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "            # Generate RA sales\n",
    "            sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['year']==year) ]\n",
    "            unc_all=float(sales['sim_sales']) + float(sales['sim_sales']*unc_base_prob)\n",
    "            sales_ra.append(unc_all)\n",
    "            \n",
    "            # Create scenario array\n",
    "            if nsim_p1==1: \n",
    "                nsim_p2=0\n",
    "            else:\n",
    "                nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "\n",
    "            scenario_sdf1.append(nsim_p1)\n",
    "            scenario_sdf2.append(nsim_p2+(i+1))\n",
    "            product_sdf.append(product)\n",
    "            region_sdf.append(region)\n",
    "            units_sdf.append(sales['units'].values[0])\n",
    "            ind_sdf.append(sales['indication'].values[0])\n",
    "            year_sdf.append(year)\n",
    "            sales_sdf.append(float(sales['sales']))\n",
    "            sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "            tag_sdf.append(sales['tag'].values[0])\n",
    "\n",
    "        # Develop interim scenario_df\n",
    "        scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "        # Append interim scenario_df to final scenario_df\n",
    "        scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "        # Get Product Worldwide sales by year (series)\n",
    "        prod_ww_sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['year']==year) ]\n",
    "        prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "        prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "        prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "        prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "        prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "        prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra)\n",
    "\n",
    "\n",
    "        # Append to sales df\n",
    "        output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10572.647387139801\n",
      "10354.238268239284\n",
      "10477.577013703425\n",
      "10634.978132859344\n"
     ]
    }
   ],
   "source": [
    "print(sum(output_p2[(output_p2['product'] =='lexiscan')]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'] =='lexiscan')]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'] =='lexiscan')]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'] =='lexiscan')]['sales_RA_75']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evenity\n",
      "1\n",
      "2\n",
      "3\n",
      "cresemba\n",
      "1\n",
      "2\n",
      "3\n",
      "tamsulosin\n",
      "1\n",
      "2\n",
      "3\n",
      "suglat\n",
      "1\n",
      "2\n",
      "3\n",
      "ambisome\n",
      "1\n",
      "2\n",
      "3\n",
      "vesicare\n",
      "1\n",
      "2\n",
      "3\n",
      "mycamine\n",
      "1\n",
      "2\n",
      "3\n",
      "sujanu\n",
      "1\n",
      "2\n",
      "3\n",
      "symraf\n",
      "1\n",
      "2\n",
      "3\n",
      "cimzia\n",
      "1\n",
      "2\n",
      "3\n",
      "blincyto\n",
      "1\n",
      "2\n",
      "3\n",
      "repatha\n",
      "1\n",
      "2\n",
      "3\n",
      "linzess\n",
      "1\n",
      "2\n",
      "3\n",
      "vesomni\n",
      "1\n",
      "2\n",
      "3\n",
      "myslee/stilnox\n",
      "1\n",
      "2\n",
      "3\n",
      "irribow\n",
      "1\n",
      "2\n",
      "3\n",
      "gonax\n",
      "1\n",
      "2\n",
      "3\n",
      "feburic\n",
      "1\n",
      "2\n",
      "3\n",
      "asamax\n",
      "1\n",
      "2\n",
      "3\n",
      "josamycin\n",
      "1\n",
      "2\n",
      "3\n",
      "non prod\n",
      "1\n",
      "2\n",
      "3\n",
      "istodax\n",
      "1\n",
      "2\n",
      "3\n",
      "other merchandise products\n",
      "1\n",
      "2\n",
      "3\n",
      "allelock\n",
      "1\n",
      "2\n",
      "3\n",
      "tr\n",
      "1\n",
      "2\n",
      "3\n",
      "acr\n",
      "1\n",
      "2\n",
      "3\n",
      "blz\n",
      "1\n",
      "2\n",
      "3\n",
      "bonoteo\n",
      "1\n",
      "2\n",
      "3\n",
      "seroquel\n",
      "1\n",
      "2\n",
      "3\n",
      "geninax\n",
      "1\n",
      "2\n",
      "3\n",
      "col\n",
      "1\n",
      "2\n",
      "3\n",
      "inf-v\n",
      "1\n",
      "2\n",
      "3\n",
      "kiklin\n",
      "1\n",
      "2\n",
      "3\n",
      "ofa\n",
      "1\n",
      "2\n",
      "3\n",
      "regnite\n",
      "1\n",
      "2\n",
      "3\n",
      "srs\n",
      "1\n",
      "2\n",
      "3\n",
      "st\n",
      "1\n",
      "2\n",
      "3\n",
      "dificlir\n",
      "1\n",
      "2\n",
      "3\n",
      "p_aco - acofide\n",
      "1\n",
      "2\n",
      "3\n",
      "other astellas products\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#############\n",
    "# OTHERS\n",
    "#############\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "region = 'WW'\n",
    "other_products = ['evenity','cresemba','tamsulosin','suglat','ambisome','vesicare','mycamine','sujanu','symraf','cimzia','blincyto','repatha','linzess',\n",
    "'vesomni','myslee/stilnox','irribow','gonax','feburic','asamax','josamycin','non prod','istodax','other merchandise products','allelock','tr','acr','blz','bonoteo','seroquel','geninax','col','inf-v','kiklin',\n",
    "'ofa','regnite','srs','st','dificlir','p_aco - acofide','other astellas products']\n",
    "\n",
    "for product in other_products:\n",
    "    # Clear output for rerun\n",
    "    output_p2=output_p2[(output_p2['product']!=product)]\n",
    "    scenarios_p2=scenarios_p2[(scenarios_p2['product']!=product)]\n",
    "    print(product)\n",
    "    \n",
    "    # Filter scenarios df for scenario\n",
    "    for sim in range(sims):\n",
    "        nsim_p1=(sim+1)\n",
    "        scenarios_p2a=input_p2b[(input_p2b['scenario']==nsim_p1)]\n",
    "        print(nsim_p1)\n",
    "\n",
    "        for year in years:\n",
    "            n=sims\n",
    "            scenario_sdf1=[]\n",
    "            scenario_sdf2=[]\n",
    "            product_sdf=[]\n",
    "            region_sdf=[]\n",
    "            units_sdf=[]\n",
    "            ind_sdf=[]\n",
    "            year_sdf=[]\n",
    "            sales_sdf=[]\n",
    "            sim_sales_sdf1=[]\n",
    "            tag_sdf=[]\n",
    "            \n",
    "            sales_ra = []\n",
    "\n",
    "            for i in range(n):\n",
    "                # Get Base Uncertainty\n",
    "                unc_base=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year)]['unc_base']\n",
    "                unc_base_prob=np.random.uniform(low=-unc_base, high=unc_base)\n",
    "\n",
    "                # Generate RA sales\n",
    "                sales=scenarios_p2a[(scenarios_p2a['product'] ==product) & (scenarios_p2a['region']==region) & (scenarios_p2a['year']==year) ]\n",
    "                unc_all=float(sales['sim_sales']) + float(sales['sim_sales']*unc_base_prob)\n",
    "                sales_ra.append(unc_all)\n",
    "                \n",
    "                # Create scenario array\n",
    "                if nsim_p1==1: \n",
    "                    nsim_p2=0\n",
    "                else:\n",
    "                    nsim_p2=((nsim_p1*nsim_p1)+nsim_p1)/2\n",
    "                    \n",
    "                scenario_sdf1.append(nsim_p1)\n",
    "                scenario_sdf2.append(nsim_p2+(i+1))\n",
    "                product_sdf.append(product)\n",
    "                region_sdf.append(region)\n",
    "                units_sdf.append(sales['units'].values[0])\n",
    "                ind_sdf.append(sales['indication'].values[0])\n",
    "                year_sdf.append(year)\n",
    "                sales_sdf.append(float(sales['sales']))\n",
    "                sim_sales_sdf1.append(float(sales['sim_sales']))\n",
    "                tag_sdf.append(sales['tag'].values[0])\n",
    "\n",
    "            # Develop interim scenario_df\n",
    "            scenarios_p2b= pd.DataFrame({'scenario_p1': scenario_sdf1,'scenario_p2': scenario_sdf2,'tag': tag_sdf,'product': product_sdf,'region': region_sdf, 'units': units_sdf, \n",
    "                                    'indication': ind_sdf, 'year': year_sdf, 'sales': sales_sdf, 'sim_sales_p1': sim_sales_sdf1, 'sim_sales_p2': sales_ra})\n",
    "\n",
    "            # Append interim scenario_df to final scenario_df\n",
    "            scenarios_p2=scenarios_p2.append(scenarios_p2b, ignore_index=True)\n",
    "\n",
    "            # Get Product Worldwide sales by year (series)\n",
    "            prod_ww_sales=input_p2b[(input_p2b['product'] ==product) & (input_p2b['region']==region) & (input_p2b['year']==year) ]\n",
    "            prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "            prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "            prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "            prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "            prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "            prod_ww_sales['sales_P2_RA'] = np.mean(sales_ra)\n",
    "\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p2 = output_p2.append(prod_ww_sales, ignore_index=True)\n",
    "\n",
    "    output_p2=output_p2.fillna(0)\n",
    "    output_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88176.5033101042\n",
      "86025.5114753956\n",
      "88320.49609295983\n",
      "90752.38229806589\n"
     ]
    }
   ],
   "source": [
    "print(sum(output_p2[(output_p2['product'].isin(other_products))]['sales']))\n",
    "print(sum(output_p2[(output_p2['product'].isin(other_products))]['sales_RA_25']))\n",
    "print(sum(output_p2[(output_p2['product'].isin(other_products))]['sales_RA_50']))\n",
    "print(sum(output_p2[(output_p2['product'].isin(other_products))]['sales_RA_75']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep Results for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add WW sales to output\n",
    "output_p2a=output_p2\n",
    "output_p2a=output_p2a.groupby(['product','units','indication','year']).sum().reset_index()\n",
    "output_p2a['region']='ALL'\n",
    "output_p2 = output_p2.append(output_p2a, ignore_index=True)\n",
    "\n",
    "# Consolidate uncertainty output\n",
    "output_unc_p2=output_unc_p2.groupby(['product','units','indication','year', 'region']).max().reset_index()\n",
    "\n",
    "# Remove interim dfs from memory\n",
    "del input_p2a \n",
    "del input_p2b \n",
    "del sales\n",
    "del prod_ww_sales\n",
    "del output_unc\n",
    "del output_p2a\n",
    "\n",
    "output_file = 'output_p2.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "output_p2.to_csv(path)\n",
    "\n",
    "output_file = 'output_unc_p2.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "output_unc_p2.to_csv(path)\n",
    "\n",
    "output_file = 'scenarios_p2.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "scenarios_p2.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Phase 3: Above Brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep for Phase 3 and Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create output dfs\n",
    "output_p3 = pd.DataFrame(columns=['tag','product', 'region', 'units', 'indication', 'year', 'sales', 'sales_RA_10', 'sales_RA_25','sales_RA_50','sales_RA_75', 'sales_RA_90', \n",
    "                                  'sales_P1_RA', 'sales_P2_RA', 'sales_P3_RA']) # Outputs of Phase 3\n",
    "\n",
    "scenarios_p3 = pd.DataFrame(columns=['scenario', 'tag', 'product', 'region', 'units', 'indication', 'year', 'sales', 'sim_sales']) # Scenarios of Phase 3\n",
    "output_unc_p3 = pd.DataFrame(columns=['tag','product', 'region', 'units', 'indication', 'year', 'sales', 'variable', 'value']) # Uncertainties of Phase 3\n",
    "\n",
    "# Inputs\n",
    "years = [2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031]\n",
    "regions = ['US', 'JP', 'CN', 'DE', 'FR', 'IT', 'ES', 'GB']\n",
    "products = ['evrenzo', 'fezo', 'mirabegron', 'padcev', 'tacrolimus', 'xospata', 'xtandi', 'zolbe']\n",
    "input_p3a=output_p2[~(output_p2['region'].isin(regions))] # These do not go thru phase3\n",
    "input_p3b=output_p2[(output_p2['region'].isin(regions))] # These go thru phase3\n",
    "\n",
    "for product in products:\n",
    "    print(product)\n",
    "\n",
    "    for year in years:\n",
    "\n",
    "        for region in regions:\n",
    "            n=sims\n",
    "            sales_ra = []\n",
    "            unc_ab1_ra = []\n",
    "            unc_ab2_ra = []\n",
    "            unc_ab3_ra = []\n",
    "            unc_ab4_ra = []\n",
    "\n",
    "            for i in range(n):\n",
    "                # Get Above Brand Uncertainty Probability (value)\n",
    "                unc_ab1_prob=np.random.binomial(size=1, n=1, p=unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc_ab1')]['probability'])\n",
    "                unc_ab2_prob=np.random.binomial(size=1, n=1, p=unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc_ab2')]['probability'])\n",
    "                unc_ab3_prob=np.random.binomial(size=1, n=1, p=unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc_ab3')]['probability'])\n",
    "                unc_ab4_prob=np.random.binomial(size=1, n=1, p=unc_pr_desc[(unc_pr_desc['uncertainties'] == 'unc_ab4')]['probability'])\n",
    "                \n",
    "                # Get sales from phase 2\n",
    "                sales=input_p3b[(input_p3b['product'] ==product) & (input_p3b['region']==region) & (input_p3b['year']==year) ]\n",
    "\n",
    "                # Get Uncertainty Quant by year (series)\n",
    "                unc_ab1=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_ab1']*float(sales['sales_P2_RA'])*unc_ab1_prob\n",
    "                unc_ab2=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_ab2']*float(sales['sales_P2_RA'])*unc_ab2_prob\n",
    "                unc_ab3=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_ab3']*float(sales['sales_P2_RA'])*unc_ab3_prob\n",
    "                unc_ab4=unc_pr[(unc_pr['product'] ==product) & (unc_pr['year'] ==year) & (unc_pr['region'] ==region)]['unc_ab4']*float(sales['sales_P2_RA'])*unc_ab4_prob\n",
    "                \n",
    "                # Generate RA sales\n",
    "                unc_all=float(sales['sales_P2_RA']) + unc_ab1 + unc_ab2 + unc_ab3 + unc_ab4\n",
    "                sales_ra.append(unc_all)\n",
    "                \n",
    "                # Generate uncertainty arrays\n",
    "                unc_ab1_ra.append(float(unc_ab1))\n",
    "                unc_ab2_ra.append(float(unc_ab2))\n",
    "                unc_ab3_ra.append(float(unc_ab3))\n",
    "                unc_ab4_ra.append(float(unc_ab4))\n",
    "            \n",
    "            # Get Product Worldwide sales by year (series)\n",
    "            prod_ww_sales=input_p3b[(input_p3b['product'] ==product) & (input_p3b['region']==region) & (input_p3b['year']==year) ]\n",
    "            prod_ww_sales['sales_RA_10'] = np.percentile(sales_ra, 10)\n",
    "            prod_ww_sales['sales_RA_25'] = np.percentile(sales_ra, 25)\n",
    "            prod_ww_sales['sales_RA_50'] = np.percentile(sales_ra, 50)\n",
    "            prod_ww_sales['sales_RA_75'] = np.percentile(sales_ra, 75)\n",
    "            prod_ww_sales['sales_RA_90'] = np.percentile(sales_ra, 90)\n",
    "            prod_ww_sales['sales_P3_RA'] = np.mean(sales_ra)\n",
    "            \n",
    "            # Add uncertainty arrays to output_unc\n",
    "            output_unc=input_p3b[(input_p3b['product'] ==product) & (input_p3b['region']==region) & (input_p3b['year']==year) ][['tag', 'product', 'region', 'units', 'indication', 'year', 'sales','sales_P1_RA', 'sales_P2_RA']]\n",
    "            output_unc['unc_ab1_ra'] = np.mean(unc_ab1_ra)\n",
    "            output_unc['unc_ab2_ra'] = np.mean(unc_ab2_ra)\n",
    "            output_unc['unc_ab3_ra'] = np.mean(unc_ab3_ra)\n",
    "            output_unc['unc_ab4_ra'] = np.mean(unc_ab4_ra)\n",
    "\n",
    "            # Append to sales df\n",
    "            output_p3 = output_p3.append(prod_ww_sales, ignore_index=True)\n",
    "            output_unc_p2 = output_unc_p2.append(output_unc, ignore_index=True)\n",
    "            \n",
    "output_p3=output_p3.fillna(0)\n",
    "output_p3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prep Results for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update output uncertainty df for PTRS\n",
    "output_unc_p2=output_unc_p2.groupby(['product','units','indication','year', 'region']).max().reset_index()\n",
    "output_unc_p2['unc_ptrs'] = output_unc_p2['sales_P1_RA'] - output_unc_p2['sales']\n",
    "\n",
    "# Update output uncertainty df for PTRS\n",
    "output_unc_p2=output_unc_p2.fillna(0)\n",
    "\n",
    "# Select columns needed\n",
    "output_unc_p3=output_unc_p2[['tag', 'product', 'region', 'units', 'indication', 'year', 'sales',\n",
    "                             'unc_ptrs','unc1_ra', 'unc2_ra', 'unc3_ra', 'unc4_ra',\n",
    "                             'unc5_ra', 'unc6_ra', 'unc7_ra', 'unc8_ra', 'unc9_ra', 'unc10_ra',\n",
    "                             'unc11_ra', 'unc12_ra', 'unc13_ra', 'unc14_ra', 'unc15_ra', 'unc16_ra',\n",
    "                             'unc17_ra', 'unc18_ra', 'unc26_ra', \n",
    "                             'unc_ab1_ra', 'unc_ab2_ra','unc_ab3_ra', 'unc_ab4_ra']]\n",
    "\n",
    "# Pivot table\n",
    "id_vars=['tag', 'product', 'region', 'units', 'indication', 'year', 'sales']\n",
    "value_vars=['unc_ptrs','unc1_ra', 'unc2_ra', 'unc3_ra', 'unc4_ra',\n",
    "            'unc5_ra', 'unc6_ra', 'unc7_ra', 'unc8_ra', 'unc9_ra', 'unc10_ra',\n",
    "            'unc11_ra', 'unc12_ra', 'unc13_ra', 'unc14_ra', 'unc15_ra', 'unc16_ra',\n",
    "            'unc17_ra', 'unc18_ra', 'unc26_ra', \n",
    "            'unc_ab1_ra', 'unc_ab2_ra','unc_ab3_ra', 'unc_ab4_ra']\n",
    "\n",
    "output_unc_p3=pd.melt(output_unc_p3, id_vars=id_vars, value_vars=value_vars)\n",
    "\n",
    "# # Merge uncertainty name to output_unc_p22\n",
    "# output_unc_p22=output_unc_p22.merge(unc_pr_desc, how='left', left_on='lkey', right_on='rkey')\n",
    "\n",
    "# Add back tags that did not go through phase 3\n",
    "input_p3a['sales_P3_RA']=input_p3a['sales_P2_RA']\n",
    "output_p3=pd.concat([output_p3, input_p3a[input_p3a['region']!='ALL']], ignore_index=True, axis=0)\n",
    "\n",
    "# Add WW sales to output\n",
    "output_phase3_agg=output_p3\n",
    "output_phase3_agg=output_phase3_agg.groupby(['product','units','indication','year']).sum().reset_index()\n",
    "output_phase3_agg['region']='ALL'\n",
    "output_p3 = output_p3.append(output_phase3_agg, ignore_index=True)\n",
    "\n",
    "# Remove interim dfs from memory\n",
    "del prod_ww_sales\n",
    "del sales\n",
    "del input_p3a \n",
    "del input_p3b \n",
    "del output_phase3_agg\n",
    "\n",
    "output_file = 'output_p3.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "output_p3.to_csv(path)\n",
    "\n",
    "output_file = 'output_unc_p3.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "output_unc_p3.to_csv(path)\n",
    "\n",
    "output_file = 'scenarios_p3.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "scenarios_p3.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%whos DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_end = datetime.now()\n",
    "td =  sim_end - sim_start\n",
    "td_mins = int(round(td.total_seconds() / 60))\n",
    "metatdata = {'sim_start': sim_start, 'sim_end': sim_end, 'sims_run': sims, 'sim_time': td_mins}\n",
    "metatdata_df=pd.DataFrame.from_dict(metatdata, orient='index')\n",
    "\n",
    "output_file = 'metatdata.csv'\n",
    "path = os.path.join(output_folder, output_file)\n",
    "metatdata_df.to_csv(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
