{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Libraries and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from PIL import Image\n",
    "import io\n",
    "import re\n",
    "import dateutil.relativedelta\n",
    "import os\n",
    "import math\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import functools\n",
    "import statistics\n",
    "import functools\n",
    "\n",
    "def folder_create(wd, lev_2_folder, folder):\n",
    "    # Create the string path\n",
    "    path = os.path.join(wd, lev_2_folder)\n",
    "    path = os.path.join(path, folder)\n",
    "    try: \n",
    "        # Create the directory stored in 'path'\n",
    "        os.mkdir(path)\n",
    "    except OSError as error: \n",
    "        print('Folder already exists!') \n",
    "\n",
    "def data_prep(wd, folder, df, data_type):\n",
    "    # Drop NaN rows & reset index\n",
    "    df = df.dropna(how='all').reset_index(drop=True)\n",
    "    # Slice 'df' from the first valid index row to all remaining rows to all columns then reset the index\n",
    "    df = df.iloc[df.iloc[:,3].first_valid_index():,:].reset_index(drop=True)\n",
    "    # Replace column headers with an index\n",
    "    df.columns = np.arange(len(df.columns))\n",
    "    # Assign new values to the first 3 cells in row zero\n",
    "    df.iloc[0, 0:3] = [0, 1, 2]\n",
    "    # Make row zero the column names\n",
    "    df.columns = df.iloc[0]\n",
    "    # Slice out row zero & reset the index again\n",
    "    df = df.iloc[1:, :].reset_index(drop=True)\n",
    "    # Replace zeros with 'NaN'\n",
    "    df = df.replace(0, np.nan)\n",
    "    # Replace 'LC - LC' with 'JPY - Japan Yen' for all 'D_INTL_LEGACY - International Legacy'\n",
    "    if data_type == 'units':\n",
    "        conds = [df[1] != 'D_INTL_LEGACY - International Legacy',\n",
    "                 df[1] == 'D_INTL_LEGACY - International Legacy']\n",
    "        choices = ['LC - LC', 'JPY - Japan Yen']\n",
    "        rslt = np.select(conds, choices).tolist()\n",
    "        df[0] = rslt\n",
    "\n",
    "        \n",
    "    # Create a list of the currency\n",
    "    currency_list = list(df[0])\n",
    "    # Create a list of the costobjects\n",
    "    costobject_list = list(df[1])\n",
    "    # Create a list of the products\n",
    "    product_list = list(df[2])\n",
    "    # Drop columns '0', '1', & '2'\n",
    "    df.drop([0, 1, 2], inplace=True, axis=1)\n",
    "    # Concatenate the currency, costobject & product to create the tag then append it to 'tags'\n",
    "    tags = list()\n",
    "    i = 0\n",
    "    while i < len(df):\n",
    "        x = currency_list[i] + '_' + costobject_list[i] + '_' + product_list[i]\n",
    "        tags.append(x)\n",
    "        i += 1\n",
    "    # Add the tags to 'df'\n",
    "    df_tags = pd.DataFrame(tags, columns=['tag'])\n",
    "    df = pd.concat([df_tags, df], axis=1, ignore_index=False)\n",
    "    \n",
    "    \n",
    "    # Convert all the column headers to a list\n",
    "    df_header_list = list(df)\n",
    "    # Covert all the dates in 'df_header_list' to %Y-%m-%d format & store them in 'converted_dates_list'\n",
    "    converted_dates_list = list()\n",
    "    for x in df_header_list:\n",
    "        if x == 'tag':\n",
    "            pass\n",
    "        else:\n",
    "            try:\n",
    "                z = re.search('[A-Z][a-z]+', x)\n",
    "                z = z.group(0)\n",
    "                y = re.search('[0-9][0-9]', x)\n",
    "                y = y.group(0)\n",
    "                if z in ['January', 'February', 'March']:\n",
    "                    y = str(int(y) + 1)\n",
    "                year = '20' + y\n",
    "                date = z + '01' + year\n",
    "                d = datetime.strptime(date, '%B%d%Y').strftime('%Y-%m-%d')\n",
    "                converted_dates_list.append(d)\n",
    "            except:\n",
    "                pass\n",
    "    # Transpose & reset the index to get rid of the old dates\n",
    "    df_T = df.T.reset_index(drop=True)\n",
    "    # Make row 0 the column headers\n",
    "    df_T.columns = df_T.iloc[0]\n",
    "    # Drop the now duplicate row 0 & reset the index again\n",
    "    df_T = df_T.drop(0).reset_index(drop=True)\n",
    "    # Convert the entire dataframe to numeric data types\n",
    "    df_T = df_T.apply(pd.to_numeric)\n",
    "    # Add the months back to the data\n",
    "    df_months = pd.DataFrame(converted_dates_list, columns=['ds'])\n",
    "    df_concat = pd.concat([df_months, df_T], axis=1, ignore_index=False)\n",
    "    # Add '-01' to create 'accrual_month'\n",
    "    accrual_month = folder + '-01'\n",
    "    accrual_month = datetime.strptime(accrual_month, '%Y%m-%d')\n",
    "    accrual_month = str(accrual_month.date())\n",
    "\n",
    "    # Identify the row index number of the accrual month\n",
    "    idx_num = df_concat.index[df_concat['ds'] == accrual_month].tolist()\n",
    "    # Create a list of row index numbers\n",
    "    idx_rng = list(range(idx_num[0], len(df_concat)))\n",
    "    # Drop rows\n",
    "    df_concat.drop(idx_rng, inplace=True, axis=0)\n",
    "    # Drop elements\n",
    "    converted_dates_list = converted_dates_list[:-1*len(idx_rng)]\n",
    "    \n",
    "    \n",
    "    # Create a copy of 'df_concat'\n",
    "    df_export = df_concat.copy()\n",
    "    # Reformat 'df_export'\n",
    "    df_export.set_index('ds', inplace=True)\n",
    "    # Transpose & reset the index\n",
    "    df_export = df_export.T.reset_index(drop=True)\n",
    "    # Add the tags column because at this point the tags are the index, which will get lost when exported\n",
    "    df_export = pd.concat([df_tags, df_export], axis=1, ignore_index=False)\n",
    "    \n",
    "    \n",
    "    # Restructure the data into the format needed for ForecastAI. To do this, create a list of dataframes\n",
    "    i = 0\n",
    "    df_list = list()\n",
    "    while i < len(costobject_list):\n",
    "        # Subset 'df_concat' so it only contains 2 columns of data: a specific tag & the dates column\n",
    "        df_subset = df_concat[[tags[i], 'ds']]\n",
    "        # Rename the columns\n",
    "        df_subset.columns = ['value', 'ds']\n",
    "        # Create a list of the repeated tag (repeated for each month of data)\n",
    "        repeated_tag = [tags[i] for x in range(len(df_subset))]\n",
    "        # Create a list of the repeated costobject (repeated for each month of data)\n",
    "        repeated_costobject = [costobject_list[i] for x in range(len(df_subset))]\n",
    "        # Create a list of the repeated product (repeated for each month of data)\n",
    "        repeated_product = [product_list[i] for x in range(len(df_subset))]\n",
    "        # Add the lists to 'df_subset'\n",
    "        df_subset['tag'], df_subset['Cost Objects'],df_subset['Products'] = repeated_tag, repeated_costobject, repeated_product\n",
    "        # Reorder the columns\n",
    "        df_subset = df_subset[['tag', 'Cost Objects', 'Products', 'value', 'ds']]\n",
    "        # Add 'df_subset' to 'df_list'\n",
    "        df_list.append(df_subset)\n",
    "        i += 1\n",
    "        \n",
    "      \n",
    "    # Convert the string dates to datetime objects\n",
    "    datetime_objects = list()\n",
    "    for x in converted_dates_list:\n",
    "        y = datetime.strptime(x, '%Y-%m-%d')\n",
    "        datetime_objects.append(y)\n",
    "    # Pull the last date in 'datetime_objects'\n",
    "    last_date = datetime_objects[-1]\n",
    "    \n",
    "    \n",
    "    ######\n",
    "    # TAG1\n",
    "    ######\n",
    "    # Modified. The net sales TAG1 doesn't eliminate time series if there isn't enough data in the most \n",
    "    # recent 6 months. It assigns it a '1' in the 'noSalesLastYear' column if there isn't enough data\n",
    "\n",
    "    # Subtract 6 months from 'last_date'\n",
    "    ld6 = last_date - dateutil.relativedelta.relativedelta(months=6)\n",
    "    # Create a list of all the dates > 'ld6' (dates more recent than 'ld6')\n",
    "    selected_dates = list()\n",
    "    for x in datetime_objects:\n",
    "        if x > ld6:\n",
    "            # Extract only the %Y-%m-%d\n",
    "            y = str(x)[:10]\n",
    "            selected_dates.append(y)\n",
    "\n",
    "    # Filter out time series with less than the minimum number of months of data in the most recent 6 \n",
    "    # months & add the 'no_sales' column to the dataframes\n",
    "    i = 0\n",
    "    df_list2 = list()   \n",
    "    elim_via_TAG1 = list()\n",
    "    while i < len(df_list):\n",
    "        df_copy = df_list[i].copy()\n",
    "        # Filter 'df_copy' by rows with dates in 'selected_dates'\n",
    "        result_df = df_copy.loc[df_copy['ds'].isin(selected_dates)]\n",
    "        # Drop all rows with 'NaN' in the 'value' column\n",
    "        result_df.dropna(subset=['value'], inplace=True)\n",
    "        if len(result_df) >= 4:\n",
    "            # Create a list of zeros\n",
    "            repeated_zeros = [0 for x in range(len(df_copy))]\n",
    "            # Add the 'no_sales' column\n",
    "            df_copy['no_sales'] = repeated_zeros\n",
    "            # Append\n",
    "            df_list2.append(df_copy)\n",
    "        else:\n",
    "            elim_via_TAG1.append(df_copy.iloc[0, 1])\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    ######\n",
    "    # TAG2\n",
    "    ######\n",
    "    \n",
    "    # Subtract 14 months from 'last_date'\n",
    "    ld14 = last_date - dateutil.relativedelta.relativedelta(months=14)\n",
    "    # Create a list of all the dates <= 'ld14' (dates equal to or older than 'ld14')\n",
    "    selected_dates2 = list()\n",
    "    for x in datetime_objects:\n",
    "        if x <= ld14:\n",
    "            # Extract only the %Y-%m-%d\n",
    "            y = str(x)[:10]\n",
    "            selected_dates2.append(y)\n",
    "\n",
    "    # Add the 'short_history' column to the dataframes. Assign a '0' if there is at least 2 months of \n",
    "    # data in the months preceding or equal to 'ld14' & a '1' if there isn't\n",
    "    i = 0\n",
    "    df_list3 = list()\n",
    "    while i < len(df_list2):\n",
    "        df_copy = df_list2[i].copy()\n",
    "        # Filter 'df_copy' by rows with dates in 'selected_dates2'\n",
    "        result_df = df_copy.loc[df_copy['ds'].isin(selected_dates2)]\n",
    "        # Drop all rows with 'NaN' in the 'value' column\n",
    "        result_df.dropna(subset=['value'], inplace=True)\n",
    "        if len(result_df) >= 2:\n",
    "            # Create a list of zeros\n",
    "            repeated_zeros = [0 for x in range(len(df_copy))]\n",
    "            # Add the 'short_history' column\n",
    "            df_copy['short_history'] = repeated_zeros\n",
    "            # Append\n",
    "            df_list3.append(df_copy)\n",
    "        else:\n",
    "            # Create a list of ones\n",
    "            repeated_ones = [1 for x in range(len(df_copy))]\n",
    "            # Add the 'short_history' column\n",
    "            df_copy['short_history'] = repeated_ones\n",
    "            # Append\n",
    "            df_list3.append(df_copy)\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    ######\n",
    "    # TAG3\n",
    "    ######\n",
    "\n",
    "    # Add the 'theta_check' column to the dataframes. Assign a '1' if there is at least 12 months of \n",
    "    # data in the months preceding or equal to 'ld14' & a '0' if there isn't\n",
    "    i = 0\n",
    "    df_list4 = list()\n",
    "    while i < len(df_list3):\n",
    "        df_copy = df_list3[i].copy()\n",
    "        # Filter 'df_copy' by rows with dates in 'selected_dates2'\n",
    "        result_df = df_copy.loc[df_copy['ds'].isin(selected_dates2)]\n",
    "        # Drop all rows with 'NaN' in the 'value' column\n",
    "        result_df.dropna(subset=['value'], inplace=True)\n",
    "        if len(result_df) >= 12:\n",
    "            # Create a list of ones\n",
    "            repeated_ones = [1 for x in range(len(df_copy))]\n",
    "            # Add the 'theta_check' column\n",
    "            df_copy['theta_check'] = repeated_ones\n",
    "            # Append\n",
    "            df_list4.append(df_copy)\n",
    "        else:\n",
    "            # Create a list of zeros\n",
    "            repeated_zeros = [0 for x in range(len(df_copy))]\n",
    "            # Add the 'theta_check' column\n",
    "            df_copy['theta_check'] = repeated_zeros\n",
    "            # Append\n",
    "            df_list4.append(df_copy)\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    ######\n",
    "    # TAG4\n",
    "    ######\n",
    "    # Modified. The net sales TAG4 filters out time series that don't have at least 2 months of data. \n",
    "    # The remaining time series from this data prep all have at least 4 months of data due to TAG1. This \n",
    "    # TAG4 filters out time series that don't have the minimum number of months of data in the 6 months \n",
    "    # preceding the 12 month holdout period\n",
    "    \n",
    "    # Subtract 12 months from 'last_date'\n",
    "    ld12 = last_date - dateutil.relativedelta.relativedelta(months=12)\n",
    "    # Subtract 18 months from 'last_date'\n",
    "    ld18 = last_date - dateutil.relativedelta.relativedelta(months=18)\n",
    "    # Create a list of all the dates <= 'ld12' (dates equal to or older than 'ld12') & > 'ld18' (dates \n",
    "    # more recent than 'ld18')\n",
    "    selected_dates3 = list()\n",
    "    for x in datetime_objects:\n",
    "        if x <= ld12 and x > ld18:\n",
    "            # Extract only the %Y-%m-%d\n",
    "            y = str(x)[:10]\n",
    "            selected_dates3.append(y)\n",
    "\n",
    "    # Filter the time series and add the 'data_periods' column to the dataframes. 'data_periods' contains \n",
    "    # the total number of non-NaN months of data \n",
    "    i = 0\n",
    "    df_list5 = list()\n",
    "    elim_via_TAG4 = list()\n",
    "    while i < len(df_list4):\n",
    "        df_copy = df_list4[i].copy()\n",
    "        # Filter 'df_copy' by rows with dates in 'selected_dates3'\n",
    "        result_df = df_copy.loc[df_copy['ds'].isin(selected_dates3)]\n",
    "        # Drop all rows with 'NaN' in the 'value' column\n",
    "        result_df.dropna(subset=['value'], inplace=True)\n",
    "        if len(result_df) >= 4:\n",
    "            # Temporarily drop all rows with 'NaN' in the 'value' column to get the data period count\n",
    "            d_periods = len(df_copy.dropna(subset=['value']))\n",
    "            # Create a list of the number of data periods\n",
    "            repeated_periods = [d_periods for x in range(len(df_copy))]\n",
    "            # Add the 'data_periods' column\n",
    "            df_copy['data_periods'] = repeated_periods\n",
    "            # Append\n",
    "            df_list5.append(df_copy)\n",
    "        else:\n",
    "            elim_via_TAG4.append(df_copy.iloc[0, 1])\n",
    "        i += 1\n",
    "        \n",
    "        \n",
    "    # Concatenate    \n",
    "    df_final = pd.concat(df_list5)\n",
    "    # Replace all NaNs with zeros & reset the index\n",
    "    df_final = df_final.fillna(0).reset_index(drop=True)\n",
    "    # Create dataframes\n",
    "    df_elim_via_TAG1 = pd.DataFrame(elim_via_TAG1, columns=['tag'])\n",
    "    df_elim_via_TAG4 = pd.DataFrame(elim_via_TAG4, columns=['tag'])\n",
    "    \n",
    "    return df_final, df_export, df_elim_via_TAG1, df_elim_via_TAG4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "input_folder = r'C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\Forecasting Product\\price_model\\inputs\\v1'\n",
    "inputs_p = 'inputs_p.xlsx'\n",
    "units = 'equiv_units.xlsx'\n",
    "sales = 'net_sales.xlsx'\n",
    "\n",
    "input_path = os.path.join(input_folder, inputs_p)\n",
    "inputFile=os.path.join(input_folder, units)\n",
    "inputFile2=os.path.join(input_folder, sales)\n",
    "\n",
    "# Read input file\n",
    "inputs = pd.read_excel(input_path, engine='openpyxl')\n",
    "\n",
    "# Read in inputs\n",
    "run_id=inputs[inputs['key']=='run_id']['value'].to_string(index=False).strip()\n",
    "run_time=inputs[inputs['key']=='run_time']['value'].to_string(index=False).strip()\n",
    "deployment=inputs[inputs['key']=='deployment']['value'].to_string(index=False).strip()\n",
    "\n",
    "wd=inputs[inputs['key']=='wd']['value'].to_string(index=False).strip()\n",
    "input_path=inputs[inputs['key']=='Input Path']['value'].to_string(index=False).strip()\n",
    "output_path=inputs[inputs['key']=='Output Path']['value'].to_string(index=False).strip()\n",
    "supp_folder=inputs[inputs['key']=='Supplementary Folder']['value'].to_string(index=False).strip()\n",
    "output_folder_run=inputs[inputs['key']=='Output Folder Run']['value'].to_string(index=False).strip()\n",
    "month_folder=inputs[inputs['key']=='Month Folder']['value'].to_string(index=False).strip()\n",
    "id_cols=inputs[inputs['key']=='ID Columns']['value'].to_string(index=False).strip()\n",
    "\n",
    "id_col_no=int(inputs[inputs['key']=='ID Column #']['value'].to_string(index=False).strip())\n",
    "sub_cores=int(inputs[inputs['key']=='Subtracted Cores']['value'].to_string(index=False).strip())\n",
    "minMonths=int(inputs[inputs['key']=='Minimum Months']['value'].to_string(index=False).strip())\n",
    "dis_months=int(inputs[inputs['key']=='Discontinued Months']['value'].to_string(index=False).strip())\n",
    "fct_months=int(inputs[inputs['key']=='Forecast Months']['value'].to_string(index=False).strip())\n",
    "hdt_months=int(inputs[inputs['key']=='Holdout Months']['value'].to_string(index=False).strip())\n",
    "\n",
    "\n",
    "actual_start_dt=datetime.strptime(inputs[inputs['key']=='Actuals Start']['value'].to_string(index=False).strip(), '%Y-%m-%d %X')\n",
    "actual_end_dt=datetime.strptime(inputs[inputs['key']=='Actuals End']['value'].to_string(index=False).strip(), '%Y-%m-%d %X')\n",
    "date1=datetime.strptime(inputs[inputs['key']=='Holdout ACT End']['value'].to_string(index=False).strip(), '%Y-%m-%d %X')\n",
    "date2=datetime.strptime(inputs[inputs['key']=='Holdout FCT Start']['value'].to_string(index=False).strip(), '%Y-%m-%d %X')\n",
    "date3=datetime.strptime(inputs[inputs['key']=='Forecast ACT End']['value'].to_string(index=False).strip(), '%Y-%m-%d %X')\n",
    "date4=datetime.strptime(inputs[inputs['key']=='Forecast FCT Start']['value'].to_string(index=False).strip(), '%Y-%m-%d %X')\n",
    "dvbl_start_dt=datetime.strptime(inputs[inputs['key']=='DVBL Start']['value'].to_string(index=False).strip(), '%Y-%m-%d %X')\n",
    "dvbl_end_dt=datetime.strptime(inputs[inputs['key']=='DVBL End']['value'].to_string(index=False).strip(), '%Y-%m-%d %X')\n",
    "\n",
    "# Read in data\n",
    "df_u = pd.read_excel(inputFile, engine='openpyxl')\n",
    "df_s = pd.read_excel(inputFile2, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute 'data_prep' function\n",
    "units_format, units_acts_df, units_elim_via_TAG1_df, units_elim_via_TAG4_df = data_prep(wd, month_folder, df_u, 'units')\n",
    "rev_format, rev_lc_acts_df, rev_lc_elim_via_TAG1_df, rev_lc_elim_via_TAG4_df = data_prep(wd, month_folder, df_s, 'rev')\n",
    "\n",
    "df_units = units_format.rename(columns={'value': 'value.units'})\n",
    "df_units = df_units.reset_index(drop=True)\n",
    "\n",
    "df_rev = rev_format.rename(columns={'value': 'value.rev'})\n",
    "df_rev = df_rev.reset_index(drop=True)\n",
    "\n",
    "# Filter & sort\n",
    "df_units = df_units.sort_values('tag')\n",
    "df_rev = df_rev.sort_values('tag')\n",
    "\n",
    "# df_units=df_units[df_units['tag']=='LC - LC_D_US - US_P_XTD_TOT - Xtandi Total']\n",
    "# df_rev=df_rev[df_rev['tag']=='LC - LC_D_US - US_P_XTD_TOT - Xtandi Total']\n",
    "\n",
    "df_price=df_units[['tag','Cost Objects','Products','ds', 'value.units', 'no_sales', 'short_history', 'theta_check', 'data_periods']].merge(df_rev[['tag','ds', 'value.rev']], how='left', on=['tag','ds'])\n",
    "df_price['value.price']=df_price['value.rev'] / df_price['value.units']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !curl -L https://github.com/unit8co/amld2022-forecasting-and-metalearning/blob/main/data/m3_dataset.xls\\?raw\\=true -o m3_dataset.xls\n",
    "# !curl -L https://github.com/unit8co/amld2022-forecasting-and-metalearning/blob/main/data/passengers.pkl\\?raw\\=true -o passengers.pkl\n",
    "# !curl -L https://github.com/unit8co/amld2022-forecasting-and-metalearning/blob/main/data/m4_monthly_scaled.pkl\\?raw\\=true -o m4_monthly_scaled.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading M4 TimeSeries...\n",
      "done. There are 47992 series, with average training length 216.32901316886148\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "import torch\n",
    "from torch import nn\n",
    "from typing import List, Tuple, Dict\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.losses import SmapeLoss\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import smape\n",
    "from darts.utils.utils import SeasonalityMode, TrendMode, ModelMode\n",
    "from darts.models import *\n",
    "\n",
    "def load_m4() -> Tuple[List[TimeSeries], List[TimeSeries]]:\n",
    "    # load TimeSeries - the splitting and scaling has already been done\n",
    "    print(\"loading M4 TimeSeries...\")\n",
    "    with open(\"m4_monthly_scaled.pkl\", \"rb\") as f:\n",
    "        m4_series = pickle.load(f)\n",
    "\n",
    "    # filter and keep only series that contain at least 48 training points\n",
    "    m4_series = list(filter(lambda t: len(t[0]) >= 48, m4_series))\n",
    "\n",
    "    m4_train_scaled, m4_test_scaled = zip(*m4_series)\n",
    "\n",
    "    print(\n",
    "        \"done. There are {} series, with average training length {}\".format(\n",
    "            len(m4_train_scaled), np.mean([len(s) for s in m4_train_scaled])\n",
    "        )\n",
    "    )\n",
    "    return m4_train_scaled, m4_test_scaled\n",
    "\n",
    "m4_train, m4_test = load_m4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing hyper-params:\n",
    "IN_LEN = 36\n",
    "OUT_LEN = 4\n",
    "\n",
    "# Architecture hyper-params:\n",
    "NUM_STACKS = 20\n",
    "NUM_BLOCKS = 1\n",
    "NUM_LAYERS = 2\n",
    "LAYER_WIDTH = 136\n",
    "COEFFS_DIM = 11\n",
    "\n",
    "# Training settings:\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 1024\n",
    "MAX_SAMPLES_PER_TS = (\n",
    "    10  # <-- new parameter, limiting the number of training samples per series\n",
    ")\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 15:45:59 pytorch_lightning.utilities.rank_zero INFO: GPU available: False, used: False\n",
      "2022-09-18 15:45:59 pytorch_lightning.utilities.rank_zero INFO: TPU available: False, using: 0 TPU cores\n",
      "2022-09-18 15:45:59 pytorch_lightning.utilities.rank_zero INFO: IPU available: False, using: 0 IPUs\n",
      "2022-09-18 15:45:59 pytorch_lightning.utilities.rank_zero INFO: HPU available: False, using: 0 HPUs\n",
      "2022-09-18 15:46:00 pytorch_lightning.callbacks.model_summary INFO: \n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | SmapeLoss        | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | stacks        | ModuleList       | 543 K \n",
      "---------------------------------------------------\n",
      "541 K     Trainable params\n",
      "1.9 K     Non-trainable params\n",
      "543 K     Total params\n",
      "2.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb6909bb602421d9e5f97782e99d9ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-18 16:21:06 pytorch_lightning.utilities.rank_zero INFO: `Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<darts.models.forecasting.nbeats.NBEATSModel at 0x226d1199e80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "nbeats_model_m4 = NBEATSModel(\n",
    "    input_chunk_length=IN_LEN,\n",
    "    output_chunk_length=OUT_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_stacks=NUM_STACKS,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    layer_widths=LAYER_WIDTH,\n",
    "    expansion_coefficient_dim=COEFFS_DIM,\n",
    "    loss_fn=SmapeLoss(),\n",
    "    optimizer_kwargs={\"lr\": LR},\n",
    "    pl_trainer_kwargs={\n",
    "        \"enable_progress_bar\": True,\n",
    "        \"accelerator\": \"cpu\",\n",
    "    },\n",
    ")\n",
    "\n",
    "# Train\n",
    "nbeats_model_m4.fit(\n",
    "    m4_train,\n",
    "    num_loader_workers=4,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    max_samples_per_ts=MAX_SAMPLES_PER_TS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a4cc30c66f64483bd731ecdd42178db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 469it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-44dee22fda1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# df_price['value.price']=df_price['value.price'].float()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mseries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTimeSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_price\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_price\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cost Objects'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'D_DE - Germany'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_price\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Products'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'P_XTD_TOT - Xtandi Total'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ds'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'value.price'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnbeats_model_m4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mHORIZON\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# get forecasts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# nbeats_m4_elapsed_time = time.time() - start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\utils\\torch.py\u001b[0m in \u001b[0;36mdecorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mfork_rng\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_TORCH_SEED_VALUE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\models\\forecasting\\torch_forecasting_model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, n, series, past_covariates, future_covariates, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, num_loader_workers, mc_dropout)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         )\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         predictions = self.predict_from_dataset(\n\u001b[0m\u001b[0;32m   1125\u001b[0m             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\utils\\torch.py\u001b[0m in \u001b[0;36mdecorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mfork_rng\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_TORCH_SEED_VALUE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\models\\forecasting\\torch_forecasting_model.py\u001b[0m in \u001b[0;36mpredict_from_dataset\u001b[1;34m(self, n, input_series_dataset, trainer, batch_size, verbose, n_jobs, roll_size, num_samples, num_loader_workers, mc_dropout)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m         \u001b[1;31m# prediction output comes as nested list: list of predicted `TimeSeries` for each batch.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;31m# flatten and return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mts\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mts\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    947\u001b[0m         \"\"\"\n\u001b[0;32m    948\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m         return self._call_and_handle_interrupt(\n\u001b[0m\u001b[0;32m    950\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_impl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    648\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m         \u001b[1;31m# TODO(awaelchli): Unify both exceptions below, where `KeyboardError` doesn't re-raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_predict_impl\u001b[1;34m(self, model, dataloaders, datamodule, return_predictions, ckpt_path)\u001b[0m\n\u001b[0;32m    994\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predicted_ckpt_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mckpt_path\u001b[0m  \u001b[1;31m# TODO: remove in v1.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 996\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    998\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_checkpoint_connector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresume_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{self.__class__.__name__}: trainer tearing down\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1252\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_predict\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1309\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_evaluation_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_sanity_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\loops\\loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\loops\\dataloader\\prediction_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[0mdl_max_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_dataloader_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         dl_predictions, dl_batch_indices = self.epoch_loop.run(\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mdataloader_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_dataloader_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_max_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_dataloaders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\loops\\loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_restarting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\loops\\epoch\\prediction_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, dataloader_iter, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mincrement_ready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_run_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\loops\\epoch\\prediction_epoch_loop.py\u001b[0m in \u001b[0;36m_predict_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mincrement_started\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"predict_step\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1703\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1704\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[1;31m# restore current_fx when nested context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pytorch_lightning\\strategies\\strategy.py\u001b[0m in \u001b[0;36mpredict_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_step_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPredictStep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtraining_step_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSTEP_OUTPUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\models\\forecasting\\pl_forecasting_module.py\u001b[0m in \u001b[0;36mpredict_step\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;31m# get predictions for 1 whole batch (can include predictions of multiple series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[1;31m# and for multiple samples if a probabilistic forecast is produced)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             batch_prediction = self._get_batch_prediction(\n\u001b[0m\u001b[0;32m    210\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data_tuple_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_roll_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\models\\forecasting\\pl_forecasting_module.py\u001b[0m in \u001b[0;36m_get_batch_prediction\u001b[1;34m(self, n, input_batch, roll_size)\u001b[0m\n\u001b[0;32m    457\u001b[0m         )\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         out = self._produce_predict_output((input_past, static_covariates))[\n\u001b[0m\u001b[0;32m    460\u001b[0m             \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst_prediction_index\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m         ]\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\models\\forecasting\\pl_forecasting_module.py\u001b[0m in \u001b[0;36m_produce_predict_output\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_save_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\models\\forecasting\\nbeats.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x_in)\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstack\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstacks_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m             \u001b[1;31m# compute stack output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 513\u001b[1;33m             \u001b[0mstack_residual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_forecast\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;31m# add stack forecast to final output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\models\\forecasting\\nbeats.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[1;31m# pass input through block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mx_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;31m# add block forecast to stack forecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\darts\\models\\forecasting\\nbeats.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[1;31m# fully connected layer stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_layer_stack_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;31m# forked linear layers producing waveform generator parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "HORIZON=18\n",
    "# df_price['value.price']=df_price['value.price'].float()\n",
    "series = TimeSeries.from_dataframe(df_price[(df_price['Cost Objects']=='D_DE - Germany') & (df_price['Products']=='P_XTD_TOT - Xtandi Total')], 'ds', 'value.price')\n",
    "preds = nbeats_model_m4.predict(series=series, n=HORIZON)  # get forecasts\n",
    "# nbeats_m4_elapsed_time = time.time() - start_time\n",
    "\n",
    "# nbeats_m4_smapes = eval_forecasts(preds, air_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15376    2018-12-01\n",
       "15377    2018-09-01\n",
       "15378    2018-10-01\n",
       "15379    2018-11-01\n",
       "15380    2019-01-01\n",
       "            ...    \n",
       "15433    2020-01-01\n",
       "15434    2019-11-01\n",
       "15435    2022-04-01\n",
       "15436    2017-04-01\n",
       "15437    2017-05-01\n",
       "Name: ds, Length: 62, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_price[(df_price['Cost Objects']=='D_DE - Germany') & (df_price['Products']=='P_XTD_TOT - Xtandi Total')]['ds']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
