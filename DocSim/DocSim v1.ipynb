{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\A4023862\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\A4023862\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\A4023862\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import docx2txt\n",
    "from docx import Document\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, paired_cosine_distances\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# PARAMS\n",
    "######################\n",
    "wd = r'C:\\Users\\A4023862\\OneDrive - Astellas Pharma Inc\\SOP\\DocSim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# SEARCH QUERY\n",
    "######################\n",
    "query = 'job descriptions'\n",
    "\n",
    "document = Document()\n",
    "document.add_paragraph(query)\n",
    "\n",
    "output_file = 'data/AIA/search.docx'\n",
    "path = os.path.join(wd, output_file)\n",
    "document.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# DOC2VEC MODEL\n",
    "######################\n",
    "input_file = 'models/enwiki_dbow/doc2vec.bin'\n",
    "path = os.path.join(wd, input_file)\n",
    "d2v_wiki= Doc2Vec.load(path)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# FUNCTIONS\n",
    "######################\n",
    "\n",
    "def preprocess(text):\n",
    "    # Steps:\n",
    "    # 1. lowercase\n",
    "    # 2. Lammetize. (It does not stem. Try to preserve structure not to overwrap with potential acronym).\n",
    "    # 3. Remove stop words.\n",
    "    # 4. Remove punctuations.\n",
    "    # 5. Remove character with the length size of 1.\n",
    "\n",
    "    lowered = str.lower(text)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(lowered)\n",
    "\n",
    "    words = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            if w not in string.punctuation:\n",
    "                if len(w) > 1:\n",
    "                    lemmatized = lemmatizer.lemmatize(w)\n",
    "                    words.append(lemmatized)\n",
    "\n",
    "    return words\n",
    "\n",
    "def process_doc2vec_similarity(model):\n",
    "\n",
    "    # Both pretrained models are publicly available at public repo of jhlau.\n",
    "    # URL: https://github.com/jhlau/doc2vec\n",
    "\n",
    "    filename = './models/apnews_dbow/doc2vec.bin'\n",
    "    filename = './models/enwiki_dbow/doc2vec.bin' \n",
    "\n",
    "    model= Doc2Vec.load(filename)\n",
    "\n",
    "    tokens = preprocess(base_document)\n",
    "\n",
    "    # Only handle words that appear in the doc2vec pretrained vectors. enwiki_ebow model contains 669549 vocabulary size.\n",
    "    tokens = list(filter(lambda x: x in model.wv.vocab.keys(), tokens))\n",
    "\n",
    "    base_vector = model.infer_vector(tokens)\n",
    "\n",
    "    vectors = []\n",
    "    for i, document in enumerate(documents):\n",
    "\n",
    "        tokens = preprocess(document)\n",
    "        tokens = list(filter(lambda x: x in model.wv.vocab.keys(), tokens))\n",
    "        vector = model.infer_vector(tokens)\n",
    "        vectors.append(vector)\n",
    "\n",
    "        print(\"making vector at index:\", i)\n",
    "\n",
    "    scores = cosine_similarity([base_vector], vectors).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for i, score in enumerate(scores):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = i\n",
    "\n",
    "    most_similar_document = documents[highest_score_index]\n",
    "    print(\"Most similar document by Doc2vec with the score:\", most_similar_document, highest_score)\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# DATA\n",
    "######################\n",
    "# doc_names = ['POL-169 v5_Clean','SOP-1464 v2.0', 'SOP-1465 v4.0', 'SOP-1466 v3.0', 'Technical Writer JD']\n",
    "path = os.path.join(wd, 'data/AIA/')\n",
    "doc_names = os.listdir(path)\n",
    "\n",
    "comp_docs=[]\n",
    "for name in doc_names:\n",
    "    input_file='data/AIA/'+ name\n",
    "    path = os.path.join(wd, input_file)\n",
    "    doc = docx2txt.process(path)\n",
    "    comp_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Most similar document to: POL-169 v5_Clean.docx  =  POL-169 v5_Clean.docx  with the score: 0.98000354\n",
      "1\n",
      "Most similar document to: search.docx  =  search.docx  with the score: 0.8031055\n",
      "2\n",
      "Most similar document to: SOP-1464 v2.0.docx  =  SOP-1464 v2.0.docx  with the score: 0.98572546\n",
      "3\n",
      "Most similar document to: SOP-1465 v4.0.docx  =  SOP-1465 v4.0.docx  with the score: 0.9839408\n",
      "4\n",
      "Most similar document to: SOP-1466 v3.0.docx  =  SOP-1466 v3.0.docx  with the score: 0.98164463\n",
      "5\n",
      "Most similar document to: Technical Writer JD.docx  =  Technical Writer JD.docx  with the score: 0.9764682\n",
      "6\n",
      "Most similar document to: WPD-622 v3.0.docx  =  WPD-622 v3.0.docx  with the score: 0.982273\n",
      "7\n",
      "Most similar document to: WPD-623 v2.0.docx  =  WPD-623 v2.0.docx  with the score: 0.9693717\n",
      "8\n",
      "Most similar document to: WPD-624 v4.0.docx  =  WPD-624 v4.0.docx  with the score: 0.9773649\n",
      "9\n",
      "Most similar document to: WPD-625 v3.0.docx  =  WPD-625 v3.0.docx  with the score: 0.98112965\n",
      "10\n",
      "Most similar document to: WPD-626 v2.0.docx  =  WPD-626 v2.0.docx  with the score: 0.98472357\n",
      "11\n",
      "Most similar document to: WPD-628 v2.0.docx  =  WPD-628 v2.0.docx  with the score: 0.9779583\n",
      "12\n",
      "Most similar document to: WPD-630 v2.0.docx  =  WPD-630 v2.0.docx  with the score: 0.9863459\n",
      "13\n",
      "Most similar document to: WPD-631 v2.0.docx  =  WPD-631 v2.0.docx  with the score: 0.9859325\n",
      "14\n",
      "Most similar document to: WPD-632 v2.0.docx  =  WPD-632 v2.0.docx  with the score: 0.9802623\n",
      "15\n",
      "Most similar document to: WPD-634 v2.0.docx  =  WPD-634 v2.0.docx  with the score: 0.9855435\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">&lt;ipython-input-86-14c8331c6728&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">67</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">211</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">208 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(msg)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">209 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 │   │   │   │   │   </span>kwargs[new_arg_name] = new_arg_value                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>211 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, wrapper)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3720</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to_csv</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3717 │   │   │   </span>decimal=decimal,                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3718 │   │   </span>)                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3719 │   │   </span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 3720 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> DataFrameRenderer(formatter).to_csv(                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3721 │   │   │   </span>path_or_buf,                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3722 │   │   │   </span>lineterminator=lineterminator,                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3723 │   │   │   </span>sep=sep,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">211</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">208 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>(msg)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">209 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">210 │   │   │   │   │   </span>kwargs[new_arg_name] = new_arg_value                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>211 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> func(*args, **kwargs)                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">212 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">213 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> cast(F, wrapper)                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">214 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1189</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to_csv</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1186 │   │   │   </span>storage_options=storage_options,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1187 │   │   │   </span>formatter=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fmt,                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1188 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1189 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>csv_formatter.save()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1190 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> created_buffer:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(path_or_buf, StringIO)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">241</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">save</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">238 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">Create the writer &amp; save.</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">239 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">240 │   │   # apply compression and byte/text conversion</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>241 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> get_handle(                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">242 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.filepath_or_buffer,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">243 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mode,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">244 │   │   │   </span>encoding=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.encoding,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">856</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_handle</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 853 │   │   # Binary mode does not support 'encoding' and 'newline'.</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 854 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> ioargs.encoding <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"b\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> ioargs.mode:                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 855 │   │   │   # Encoding</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 856 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>handle = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 857 │   │   │   │   </span>handle,                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 858 │   │   │   │   </span>ioargs.mode,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 859 │   │   │   │   </span>encoding=ioargs.encoding,                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">PermissionError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">]</span> Permission denied: <span style=\"color: #008000; text-decoration-color: #008000\">'C:\\\\Users\\\\A4023862\\\\OneDrive - Astellas Pharma </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Inc\\\\SOP\\\\DocSim\\\\outputs/results_doc2vec_model.csv'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m<ipython-input-86-14c8331c6728>\u001b[0m:\u001b[94m67\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m:\u001b[94m211\u001b[0m in \u001b[92mwrapper\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m208 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(msg)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m209 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mkwargs[new_arg_name] = new_arg_value                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m211 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m212 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m213 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cast(F, wrapper)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m:\u001b[94m3720\u001b[0m in \u001b[92mto_csv\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3717 \u001b[0m\u001b[2m│   │   │   \u001b[0mdecimal=decimal,                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3718 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3719 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 3720 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m DataFrameRenderer(formatter).to_csv(                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3721 \u001b[0m\u001b[2m│   │   │   \u001b[0mpath_or_buf,                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3722 \u001b[0m\u001b[2m│   │   │   \u001b[0mlineterminator=lineterminator,                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3723 \u001b[0m\u001b[2m│   │   │   \u001b[0msep=sep,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m:\u001b[94m211\u001b[0m in \u001b[92mwrapper\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m208 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mTypeError\u001b[0m(msg)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m209 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m210 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mkwargs[new_arg_name] = new_arg_value                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m211 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m func(*args, **kwargs)                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m212 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m213 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m cast(F, wrapper)                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m214 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m:\u001b[94m1189\u001b[0m in \u001b[92mto_csv\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1186 \u001b[0m\u001b[2m│   │   │   \u001b[0mstorage_options=storage_options,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1187 \u001b[0m\u001b[2m│   │   │   \u001b[0mformatter=\u001b[96mself\u001b[0m.fmt,                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1188 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1189 \u001b[2m│   │   \u001b[0mcsv_formatter.save()                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1190 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m created_buffer:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96misinstance\u001b[0m(path_or_buf, StringIO)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m:\u001b[94m241\u001b[0m in \u001b[92msave\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m238 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mCreate the writer & save.\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m239 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m240 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# apply compression and byte/text conversion\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m241 \u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m get_handle(                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m242 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.filepath_or_buffer,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m243 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.mode,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m244 \u001b[0m\u001b[2m│   │   │   \u001b[0mencoding=\u001b[96mself\u001b[0m.encoding,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\A4023862\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m:\u001b[94m856\u001b[0m in \u001b[92mget_handle\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 853 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Binary mode does not support 'encoding' and 'newline'.\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 854 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m ioargs.encoding \u001b[95mand\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mb\u001b[0m\u001b[33m\"\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m ioargs.mode:                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 855 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Encoding\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 856 \u001b[2m│   │   │   \u001b[0mhandle = \u001b[96mopen\u001b[0m(                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 857 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mhandle,                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 858 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mioargs.mode,                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 859 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mencoding=ioargs.encoding,                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mPermissionError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m13\u001b[0m\u001b[1m]\u001b[0m Permission denied: \u001b[32m'C:\\\\Users\\\\A4023862\\\\OneDrive - Astellas Pharma \u001b[0m\n",
       "\u001b[32mInc\\\\SOP\\\\DocSim\\\\outputs/results_doc2vec_model.csv'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "######################\n",
    "# DOC2VEC ALGORITHM\n",
    "######################\n",
    "output = pd.DataFrame()\n",
    "base_docs_arr = []\n",
    "comp_docs_arr = []\n",
    "cos_sim_arr=[]\n",
    "most_sim_arr=[]\n",
    "most_score_arr=[]\n",
    "\n",
    "for i in range(0,len(doc_names)):\n",
    "    # Get base doc\n",
    "    print(i)\n",
    "    input_file='data/AIA/'+ doc_names[i]\n",
    "    path = os.path.join(wd, input_file)\n",
    "    base_document = docx2txt.process(path)\n",
    "\n",
    "    # Set model to use\n",
    "    model = d2v_wiki\n",
    "\n",
    "    # Preprocess document\n",
    "    tokens = preprocess(base_document)\n",
    "\n",
    "    # Only handle words that appear in the doc2vec pretrained vectors. enwiki_ebow model contains 669549 vocabulary size.\n",
    "    tokens = list(filter(lambda x: x in model.wv.vocab.keys(), tokens))\n",
    "\n",
    "    # Develop paragraph vector for base document\n",
    "    base_vector = model.infer_vector(tokens)\n",
    "\n",
    "    # Develop paragraph vector for comparison documents\n",
    "    vectors = []\n",
    "    for j, document in enumerate(comp_docs):\n",
    "        \n",
    "        tokens = preprocess(document)\n",
    "        tokens = list(filter(lambda x: x in model.wv.vocab.keys(), tokens))\n",
    "        vector = model.infer_vector(tokens)\n",
    "        vectors.append(vector)\n",
    "\n",
    "    # Get cosine similarity score for each document compared to the base document\n",
    "    scores = cosine_similarity([base_vector], vectors).flatten()\n",
    "\n",
    "    # Find document with highest similarity score\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for j, score in enumerate(scores):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = j\n",
    "\n",
    "    most_similar_document = comp_docs[highest_score_index]\n",
    "    most_similar_doc_name = doc_names[highest_score_index]\n",
    "\n",
    "    print(\"Most similar document to:\",  doc_names[i] ,\" = \", most_similar_doc_name, \" with the score:\", highest_score)\n",
    "    \n",
    "    # Append to results\n",
    "    base_docs_arr.append(doc_names[i])\n",
    "    comp_docs_arr.append(doc_names)\n",
    "    cos_sim_arr.append(scores)\n",
    "    most_sim_arr.append(most_similar_doc_name)\n",
    "    most_score_arr.append(highest_score)\n",
    "    \n",
    "output = pd.DataFrame({'base_doc': base_docs_arr, 'comp_doc': comp_docs_arr, 'cosine_similarity': cos_sim_arr, 'most_sim_doc': most_sim_arr, 'most_sim_cosine_similarity': most_score_arr})\n",
    "output2 = output.set_index(['base_doc', 'most_sim_doc', 'most_sim_cosine_similarity']).apply(pd.Series.explode).reset_index()\n",
    "\n",
    "output_file = 'outputs/results_doc2vec_model.csv'\n",
    "path = os.path.join(wd, output_file)\n",
    "output2.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_doc</th>\n",
       "      <th>most_sim_doc</th>\n",
       "      <th>most_sim_cosine_similarity</th>\n",
       "      <th>comp_doc</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>Technical Writer JD.docx</td>\n",
       "      <td>0.506337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-624 v4.0.docx</td>\n",
       "      <td>0.40201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-625 v3.0.docx</td>\n",
       "      <td>0.389121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>SOP-1466 v3.0.docx</td>\n",
       "      <td>0.383464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-634 v2.0.docx</td>\n",
       "      <td>0.376299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-632 v2.0.docx</td>\n",
       "      <td>0.37566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-628 v2.0.docx</td>\n",
       "      <td>0.375575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-622 v3.0.docx</td>\n",
       "      <td>0.373572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-631 v2.0.docx</td>\n",
       "      <td>0.37206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>SOP-1464 v2.0.docx</td>\n",
       "      <td>0.366586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-626 v2.0.docx</td>\n",
       "      <td>0.358507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>SOP-1465 v4.0.docx</td>\n",
       "      <td>0.354811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>POL-169 v5_Clean.docx</td>\n",
       "      <td>0.353884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-630 v2.0.docx</td>\n",
       "      <td>0.337306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>search.docx</td>\n",
       "      <td>search.docx</td>\n",
       "      <td>0.954555</td>\n",
       "      <td>WPD-623 v2.0.docx</td>\n",
       "      <td>0.325764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       base_doc most_sim_doc  most_sim_cosine_similarity  \\\n",
       "21  search.docx  search.docx                    0.954555   \n",
       "24  search.docx  search.docx                    0.954555   \n",
       "25  search.docx  search.docx                    0.954555   \n",
       "20  search.docx  search.docx                    0.954555   \n",
       "31  search.docx  search.docx                    0.954555   \n",
       "30  search.docx  search.docx                    0.954555   \n",
       "27  search.docx  search.docx                    0.954555   \n",
       "22  search.docx  search.docx                    0.954555   \n",
       "29  search.docx  search.docx                    0.954555   \n",
       "18  search.docx  search.docx                    0.954555   \n",
       "26  search.docx  search.docx                    0.954555   \n",
       "19  search.docx  search.docx                    0.954555   \n",
       "16  search.docx  search.docx                    0.954555   \n",
       "28  search.docx  search.docx                    0.954555   \n",
       "23  search.docx  search.docx                    0.954555   \n",
       "\n",
       "                    comp_doc cosine_similarity  \n",
       "21  Technical Writer JD.docx          0.506337  \n",
       "24         WPD-624 v4.0.docx           0.40201  \n",
       "25         WPD-625 v3.0.docx          0.389121  \n",
       "20        SOP-1466 v3.0.docx          0.383464  \n",
       "31         WPD-634 v2.0.docx          0.376299  \n",
       "30         WPD-632 v2.0.docx           0.37566  \n",
       "27         WPD-628 v2.0.docx          0.375575  \n",
       "22         WPD-622 v3.0.docx          0.373572  \n",
       "29         WPD-631 v2.0.docx           0.37206  \n",
       "18        SOP-1464 v2.0.docx          0.366586  \n",
       "26         WPD-626 v2.0.docx          0.358507  \n",
       "19        SOP-1465 v4.0.docx          0.354811  \n",
       "16     POL-169 v5_Clean.docx          0.353884  \n",
       "28         WPD-630 v2.0.docx          0.337306  \n",
       "23         WPD-623 v2.0.docx          0.325764  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_sim=output2[(output2['base_doc']=='search.docx') & (output2['comp_doc']!='search.docx')]\n",
    "most_sim.sort_values(by=['cosine_similarity'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# USE MODEL\n",
    "######################\n",
    "input_file = 'models/universal-sentence-encoder_4'\n",
    "path = os.path.join(wd, input_file)\n",
    "use_model = hub.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# FUNCTIONS\n",
    "######################\n",
    "def process_use_similarity(model):\n",
    "\n",
    "    base_embeddings = model([base_document])\n",
    "\n",
    "    embeddings = model(documents)\n",
    "\n",
    "    scores = cosine_similarity(base_embeddings, embeddings).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for i, score in enumerate(scores):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = i\n",
    "\n",
    "    most_similar_document = documents[highest_score_index]\n",
    "    print(\"Most similar document by USE with the score:\", most_similar_document, highest_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# DATA\n",
    "######################\n",
    "# doc_names = ['POL-169 v5_Clean','SOP-1464 v2.0', 'SOP-1465 v4.0', 'SOP-1466 v3.0', 'Technical Writer JD']\n",
    "path = os.path.join(wd, 'data/AIA/')\n",
    "doc_names = os.listdir(path)\n",
    "\n",
    "comp_docs=[]\n",
    "for name in doc_names:\n",
    "    input_file='data/AIA/'+ name\n",
    "    path = os.path.join(wd, input_file)\n",
    "    doc = docx2txt.process(path)\n",
    "    comp_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar document to: POL-169 v5_Clean.docx  =  POL-169 v5_Clean.docx  with the score: 1.0\n",
      "Most similar document to: search.docx  =  search.docx  with the score: 1.0\n",
      "Most similar document to: SOP-1464 v2.0.docx  =  SOP-1464 v2.0.docx  with the score: 1.0000002\n",
      "Most similar document to: SOP-1465 v4.0.docx  =  SOP-1465 v4.0.docx  with the score: 1.0\n",
      "Most similar document to: SOP-1466 v3.0.docx  =  SOP-1466 v3.0.docx  with the score: 0.99999994\n",
      "Most similar document to: Technical Writer JD.docx  =  Technical Writer JD.docx  with the score: 1.0\n",
      "Most similar document to: WPD-622 v3.0.docx  =  WPD-622 v3.0.docx  with the score: 1.0\n",
      "Most similar document to: WPD-623 v2.0.docx  =  WPD-623 v2.0.docx  with the score: 1.0000002\n",
      "Most similar document to: WPD-624 v4.0.docx  =  WPD-624 v4.0.docx  with the score: 0.9999999\n",
      "Most similar document to: WPD-625 v3.0.docx  =  WPD-625 v3.0.docx  with the score: 1.0000001\n",
      "Most similar document to: WPD-626 v2.0.docx  =  WPD-626 v2.0.docx  with the score: 1.0\n",
      "Most similar document to: WPD-628 v2.0.docx  =  WPD-628 v2.0.docx  with the score: 1.0000002\n",
      "Most similar document to: WPD-630 v2.0.docx  =  WPD-630 v2.0.docx  with the score: 1.0000001\n",
      "Most similar document to: WPD-631 v2.0.docx  =  WPD-631 v2.0.docx  with the score: 1.0000001\n",
      "Most similar document to: WPD-632 v2.0.docx  =  WPD-632 v2.0.docx  with the score: 1.0\n",
      "Most similar document to: WPD-634 v2.0.docx  =  WPD-634 v2.0.docx  with the score: 0.99999994\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# USE ALGORITHM\n",
    "######################\n",
    "output = pd.DataFrame()\n",
    "base_docs_arr = []\n",
    "comp_docs_arr = []\n",
    "cos_sim_arr=[]\n",
    "most_sim_arr=[]\n",
    "most_score_arr=[]\n",
    "\n",
    "for i in range(0,len(doc_names)):\n",
    "    # Get base doc\n",
    "    input_file='data/AIA/'+ doc_names[i]\n",
    "    path = os.path.join(wd, input_file)\n",
    "    base_document = docx2txt.process(path)\n",
    "    \n",
    "    # Set model to use\n",
    "    model = use_model\n",
    "\n",
    "    # Get embeddings for base document\n",
    "    base_embeddings = model([base_document])\n",
    "\n",
    "    # Get embeddings for comp documents\n",
    "    embeddings = model(comp_docs)\n",
    "\n",
    "    scores = cosine_similarity(base_embeddings, embeddings).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for j, score in enumerate(scores):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = j\n",
    "        \n",
    "    most_similar_document = comp_docs[highest_score_index]\n",
    "    most_similar_doc_name = doc_names[highest_score_index]\n",
    "\n",
    "    print(\"Most similar document to:\",  doc_names[i] ,\" = \", most_similar_doc_name, \" with the score:\", highest_score)\n",
    "    \n",
    "        # Append to results\n",
    "    base_docs_arr.append(doc_names[i])\n",
    "    comp_docs_arr.append(doc_names)\n",
    "    cos_sim_arr.append(scores)\n",
    "    most_sim_arr.append(most_similar_doc_name)\n",
    "    most_score_arr.append(highest_score)\n",
    "    \n",
    "output = pd.DataFrame({'base_doc': base_docs_arr, 'comp_doc': comp_docs_arr, 'cosine_similarity': cos_sim_arr, 'most_sim_doc': most_sim_arr, 'most_sim_cosine_similarity': most_score_arr})\n",
    "output2 = output.set_index(['base_doc', 'most_sim_doc', 'most_sim_cosine_similarity']).apply(pd.Series.explode).reset_index()\n",
    "\n",
    "output_file = 'outputs/results_use_model.csv'\n",
    "path = os.path.join(wd, output_file)\n",
    "output2.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# BERT MODEL\n",
    "######################\n",
    "input_file = 'models/all-MiniLM-L6-v2'\n",
    "path = os.path.join(wd, input_file)\n",
    "bert_model = SentenceTransformer(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "######################\n",
    "# FUNCTIONS\n",
    "######################\n",
    "def process_bert_similarity():\n",
    "    # This will download and load the pretrained model offered by UKPLab.\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "    # Although it is not explicitly stated in the official document of sentence transformer, the original BERT is meant for a shorter sentence. We will feed the model by sentences instead of the whole documents.\n",
    "    sentences = sent_tokenize(base_document)\n",
    "    base_embeddings_sentences = model.encode(sentences)\n",
    "    base_embeddings = np.mean(np.array(base_embeddings_sentences), axis=0)\n",
    "\n",
    "    vectors = []\n",
    "    for i, document in enumerate(documents):\n",
    "\n",
    "        sentences = sent_tokenize(document)\n",
    "        embeddings_sentences = model.encode(sentences)\n",
    "        embeddings = np.mean(np.array(embeddings_sentences), axis=0)\n",
    "\n",
    "        vectors.append(embeddings)\n",
    "\n",
    "        print(\"making vector at index:\", i)\n",
    "\n",
    "    scores = cosine_similarity([base_embeddings], vectors).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for i, score in enumerate(scores):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = i\n",
    "\n",
    "    most_similar_document = documents[highest_score_index]\n",
    "    print(\"Most similar document by BERT with the score:\", most_similar_document, highest_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# DATA\n",
    "######################\n",
    "# doc_names = ['POL-169 v5_Clean','SOP-1464 v2.0', 'SOP-1465 v4.0', 'SOP-1466 v3.0', 'Technical Writer JD']\n",
    "path = os.path.join(wd, 'data/AIA/')\n",
    "doc_names = os.listdir(path)\n",
    "doc_names = doc_names[1:6]\n",
    "\n",
    "comp_docs=[]\n",
    "for name in doc_names:\n",
    "    input_file='data/AIA/'+ name\n",
    "    path = os.path.join(wd, input_file)\n",
    "    doc = docx2txt.process(path)\n",
    "    comp_docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making vector at index: 0\n",
      "making vector at index: 1\n",
      "making vector at index: 2\n",
      "making vector at index: 3\n",
      "making vector at index: 4\n",
      "Most similar document to: search.docx  =  search.docx  with the score: 1.0000001\n",
      "Most similar document to: SOP-1464 v2.0.docx  =  SOP-1464 v2.0.docx  with the score: 0.9999999\n",
      "Most similar document to: SOP-1465 v4.0.docx  =  SOP-1465 v4.0.docx  with the score: 1.0000001\n",
      "Most similar document to: SOP-1466 v3.0.docx  =  SOP-1466 v3.0.docx  with the score: 1.0\n",
      "Most similar document to: Technical Writer JD.docx  =  Technical Writer JD.docx  with the score: 0.9999999\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# BERT ALGORITHM\n",
    "######################\n",
    "# Set model to use\n",
    "model = bert_model\n",
    "\n",
    "output = pd.DataFrame()\n",
    "base_docs_arr = []\n",
    "comp_docs_arr = []\n",
    "cos_sim_arr=[]\n",
    "most_sim_arr=[]\n",
    "most_score_arr=[]\n",
    "\n",
    "# Get embeddings for all documents and append to vector\n",
    "vectors = []\n",
    "for i, doc in enumerate(comp_docs):\n",
    "\n",
    "    sentences = sent_tokenize(doc)\n",
    "    embeddings_sentences = model.encode(sentences)\n",
    "    embeddings = np.mean(np.array(embeddings_sentences), axis=0)\n",
    "\n",
    "    vectors.append(embeddings)\n",
    "\n",
    "    print(\"making vector at index:\", i)\n",
    "\n",
    "for i in range(0,len(doc_names)):\n",
    "    # Get base doc\n",
    "    input_file='data/AIA/'+ doc_names[i]\n",
    "    path = os.path.join(wd, input_file)\n",
    "    base_document = docx2txt.process(path)\n",
    "    \n",
    "    # Although it is not explicitly stated in the official document of sentence transformer, the original BERT is meant for a shorter sentence. We will feed the model by sentences instead of the whole documents.\n",
    "    sentences = sent_tokenize(base_document)\n",
    "    base_embeddings_sentences = model.encode(sentences)\n",
    "    base_embeddings = np.mean(np.array(base_embeddings_sentences), axis=0)\n",
    "    scores = cosine_similarity([base_embeddings], vectors).flatten()\n",
    "\n",
    "    highest_score = 0\n",
    "    highest_score_index = 0\n",
    "    for j, score in enumerate(scores):\n",
    "        if highest_score < score:\n",
    "            highest_score = score\n",
    "            highest_score_index = j\n",
    "        \n",
    "    most_similar_document = comp_docs[highest_score_index]\n",
    "    most_similar_doc_name = doc_names[highest_score_index]\n",
    "    \n",
    "    print(\"Most similar document to:\",  doc_names[i] ,\" = \", most_similar_doc_name, \" with the score:\", highest_score)\n",
    "    \n",
    "    # Append to results\n",
    "    base_docs_arr.append(doc_names[i])\n",
    "    comp_docs_arr.append(doc_names)\n",
    "    cos_sim_arr.append(scores)\n",
    "    most_sim_arr.append(most_similar_doc_name)\n",
    "    most_score_arr.append(highest_score)\n",
    "    \n",
    "output = pd.DataFrame({'base_doc': base_docs_arr, 'comp_doc': comp_docs_arr, 'cosine_similarity': cos_sim_arr, 'most_sim_doc': most_sim_arr, 'most_sim_cosine_similarity': most_score_arr})\n",
    "output2 = output.set_index(['base_doc', 'most_sim_doc', 'most_sim_cosine_similarity']).apply(pd.Series.explode).reset_index()\n",
    "\n",
    "output_file = 'outputs/results_bert_model.csv'\n",
    "path = os.path.join(wd, output_file)\n",
    "output2.to_csv(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
